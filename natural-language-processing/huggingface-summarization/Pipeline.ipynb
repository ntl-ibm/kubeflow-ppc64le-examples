{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753ae334-3fdc-41df-90ea-adc3c36275ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.components import InputPath, OutputPath\n",
    "from kfp import dsl\n",
    "from typing import List, Tuple\n",
    "from kfp.dsl import ContainerOp\n",
    "from kubernetes.client.models import V1EnvVar,V1EnvVarSource, V1SecretKeySelector,V1ConfigMapKeySelector\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425f3a27-aed5-425f-b6b8-05dbb57615ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_IMAGE=\"quay.io/ntlawrence/summary:1.0.15\"\n",
    "PREDICTOR_IMAGE=\"quay.io/ntlawrence/summary-predictor:1.0.17\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "534509db-fba4-42bd-87b3-c77d42c27db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_commands(commands: List[str], cwd: str):\n",
    "    import subprocess\n",
    "\n",
    "    for command in commands:\n",
    "        print(command)\n",
    "        subprocess.run(command, shell=True, cwd=cwd, check=True)\n",
    "\n",
    "\n",
    "run_commands_comp = kfp.components.create_component_from_func(\n",
    "    run_commands, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7008869-cdda-4a9d-940f-1a3cd49c76a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model_dir: str,\n",
    "                   dataset_dir: str,\n",
    "                   cwd: str) -> NamedTuple(\"EvaluationOutput\", [(\"mlpipeline_metrics\", \"Metrics\")]):\n",
    "    import subprocess\n",
    "    import json\n",
    "    from collections import namedtuple\n",
    "\n",
    "    subprocess.run((\"python eval.py \"\n",
    "                    f\"--prepared_dataset_dir={dataset_dir} \"\n",
    "                    f\"--model_dir={model_dir} \"\n",
    "                    f\"--results_json=/tmp/results.json \"\n",
    "                   ),\n",
    "                   shell=True,\n",
    "                   cwd=cwd,\n",
    "                   check=True)\n",
    "    \n",
    "    with open(\"/tmp/results.json\", \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "        \n",
    "    metrics = {\n",
    "        \"metrics\": [\n",
    "            {\"name\": \"rougeL\", \n",
    "             \"numberValue\": metrics[\"eval_rougeL\"],\n",
    "             \"format\": \"RAW\"},\n",
    "            {\"name\": \"rouge2\", \n",
    "             \"numberValue\": metrics[\"eval_rouge2\"],\n",
    "             \"format\": \"RAW\"},\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    out_tuple = namedtuple(\"EvaluationOutput\", [\"mlpipeline_metrics\"])\n",
    "    return out_tuple(json.dumps(metrics))\n",
    "    \n",
    "evaluate_model_comp = kfp.components.create_component_from_func(\n",
    "    func=evaluate_model, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f19facd-394f-43df-8f10-51c0e3e8fad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_archive(model_dir: str,\n",
    "                         archive: OutputPath(str),\n",
    "                         model_name: str = \"billsum\",\n",
    "                         version: str = \"1\"):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import tarfile\n",
    "\n",
    "    os.makedirs(Path(archive).parent.absolute(), exist_ok=True)\n",
    "\n",
    "    with tarfile.open(name=archive, mode=\"w:gz\") as f:\n",
    "        for file in Path(model_dir).rglob(\"*\"):\n",
    "            if not file.is_dir():\n",
    "                f.add(file.absolute(), arcname=f\"{version}/{model_name}/{file.relative_to(model_dir)}\")\n",
    "                \n",
    "create_model_archive_comp = kfp.components.create_component_from_func(\n",
    "    func=create_model_archive, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41258d64-0a20-46cd-aa95-0a87623ddc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_archive(\n",
    "    archive: InputPath(str),\n",
    "    archive_name: str,\n",
    "    minio_url: str = \"minio-service.kubeflow:9000\",\n",
    "    version: str = \"1\"\n",
    ") -> NamedTuple(\"UploadOutput\", [(\"s3_address\", str)]):\n",
    "    \"\"\"Uploads a model file to MinIO artifact store.\"\"\"\n",
    "\n",
    "    from collections import namedtuple\n",
    "    import logging\n",
    "    from minio import Minio\n",
    "    import sys\n",
    "    import tarfile\n",
    "    import os\n",
    "\n",
    "    logging.basicConfig(\n",
    "        stream=sys.stdout,\n",
    "        level=logging.INFO,\n",
    "        format=\"%(levelname)s %(asctime)s: %(message)s\",\n",
    "    )\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "\n",
    "    minio_client = Minio(\n",
    "            minio_url, \n",
    "            access_key=os.environ[\"MINIO_ID\"], \n",
    "            secret_key=os.environ[\"MINIO_PWD\"], secure=False\n",
    "        )\n",
    "\n",
    "    # Create export bucket if it does not yet exist\n",
    "    export_bucket=\"{{workflow.namespace}}\"\n",
    "    existing_bucket = next(filter(lambda bucket: bucket.name == export_bucket, minio_client.list_buckets()), None)\n",
    "\n",
    "    if not existing_bucket:\n",
    "        logger.info(f\"Creating bucket '{export_bucket}'...\")\n",
    "        minio_client.make_bucket(bucket_name=export_bucket)\n",
    "\n",
    "    path = f\"tar/{version}/{archive_name}\"\n",
    "    s3_address = f\"s3://{export_bucket}/tar\"\n",
    "\n",
    "    logger.info(f\"Saving tar file to MinIO (s3 address: {s3_address})...\")\n",
    "    minio_client.fput_object(\n",
    "        bucket_name=export_bucket,  # bucket name in Minio\n",
    "        object_name=path,  # file name in bucket of Minio \n",
    "        file_path=archive,  # file path / name in local system\n",
    "    )\n",
    "\n",
    "    logger.info(\"Finished.\")\n",
    "    out_tuple = namedtuple(\"UploadOutput\", [\"s3_address\"])\n",
    "    return out_tuple(s3_address)\n",
    "\n",
    "\n",
    "upload_archive_comp = kfp.components.create_component_from_func(\n",
    "    func=upload_archive, base_image=BASE_IMAGE, packages_to_install=[\"minio==7.1.13\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436e4f8a-b2cc-417c-908a-54d42788ec6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deploy_inference_service(name: str,\n",
    "                             version: int,\n",
    "                             model_archive_s3: str,\n",
    "                             predictor_image: str,\n",
    "                             predictor_max_replicas: int = 1,\n",
    "                             predictor_min_replicas: int = 1,\n",
    "                             predictor_concurrency_target: int = None,\n",
    "                             prefix: str = \"\",\n",
    "                             suffix: str = \"\"\n",
    "                            ):\n",
    "    import kserve\n",
    "    from kubernetes import client, config\n",
    "    from kubernetes.client import (V1ServiceAccount, \n",
    "                                   V1Container, \n",
    "                                   V1EnvVar, \n",
    "                                   V1ObjectMeta, \n",
    "                                   V1ContainerPort, \n",
    "                                   V1ObjectReference,\n",
    "                                   V1ResourceRequirements\n",
    "                                  )\n",
    "    from kserve import KServeClient\n",
    "    from kserve import constants\n",
    "    from kserve import V1beta1PredictorSpec\n",
    "    from kserve import V1beta1ExplainerSpec\n",
    "    from kserve import V1beta1TransformerSpec\n",
    "    from kserve import V1beta1InferenceServiceSpec\n",
    "    from kserve import V1beta1InferenceService\n",
    "    import json\n",
    "    from http import HTTPStatus\n",
    "    import logging\n",
    "    import yaml\n",
    "    from time import sleep\n",
    "\n",
    "\n",
    "    config.load_incluster_config()\n",
    "    \n",
    "    \n",
    "    SERVICE_ACCOUNT = \"summary-inference-sa\"\n",
    "\n",
    "    sa = V1ServiceAccount(\n",
    "        api_version=\"v1\",\n",
    "        kind=\"ServiceAccount\",\n",
    "        metadata=V1ObjectMeta(name=SERVICE_ACCOUNT, \n",
    "                              namespace=\"{{workflow.namespace}}\"),\n",
    "        secrets=[V1ObjectReference(name=\"minio-credentials\")]\n",
    "    )\n",
    "    corev1 = client.CoreV1Api()\n",
    "    \n",
    "    try:\n",
    "        corev1.create_namespaced_service_account(namespace=\"{{workflow.namespace}}\",\n",
    "                                                 body=sa)\n",
    "    except client.exceptions.ApiException as e:\n",
    "        if e.status == HTTPStatus.CONFLICT:\n",
    "            corev1.patch_namespaced_service_account(name=SERVICE_ACCOUNT,\n",
    "                                                    namespace=\"{{workflow.namespace}}\",\n",
    "                                                    body=sa)\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    if prefix:\n",
    "        prefix = prefix + \" \"\n",
    "    if suffix:\n",
    "        suffix = \" \" + suffix\n",
    "        \n",
    "    predictor_spec = V1beta1PredictorSpec(\n",
    "        max_replicas=predictor_max_replicas,\n",
    "        min_replicas=predictor_min_replicas,\n",
    "        scale_target=predictor_concurrency_target,\n",
    "        scale_metric=\"concurrency\",\n",
    "        containers=[\n",
    "            V1Container(\n",
    "                name=\"kserve-container\",\n",
    "                image=predictor_image,\n",
    "                args=[\"python\", \n",
    "                      \"inference_service.py\", \n",
    "                      f\"--model_name={name}\", \n",
    "                      f\"--model_version={version}\", \n",
    "                      \"--num_replicas=1\"],\n",
    "\n",
    "                resources=V1ResourceRequirements(\n",
    "                    limits={\"memory\": \"50Gi\"},\n",
    "                    requests={\"memory\": \"2Gi\"},\n",
    "                ),\n",
    "                env=[\n",
    "                 V1EnvVar(\n",
    "                     name=\"STORAGE_URI\", value=model_archive_s3\n",
    "                 ),\n",
    "                 V1EnvVar(\n",
    "                     name=\"PREFIX\", value=prefix\n",
    "                 ),\n",
    "                 V1EnvVar(\n",
    "                     name=\"SUFFIX\", value=suffix\n",
    "                 )\n",
    "                ],\n",
    "            )\n",
    "        ],\n",
    "        service_account_name=SERVICE_ACCOUNT\n",
    "    )\n",
    "\n",
    "    inference_service = V1beta1InferenceService(\n",
    "        api_version=constants.KSERVE_V1BETA1,\n",
    "        kind=constants.KSERVE_KIND,\n",
    "        metadata=V1ObjectMeta(name=name, \n",
    "                              namespace=\"{{workflow.namespace}}\",\n",
    "                              annotations={\"sidecar.istio.io/inject\": \"false\",\n",
    "                                           \"serving.kserve.io/enable-prometheus-scraping\" : \"true\"}),\n",
    "        spec=V1beta1InferenceServiceSpec(predictor=predictor_spec)\n",
    "    )\n",
    "    # serving.kserve.io/inferenceservice: credit-risk\n",
    "    logging.info(\n",
    "        yaml.dump(\n",
    "            client.ApiClient().sanitize_for_serialization(inference_service)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # KServeClient doesn't throw ApiException for CONFLICT\n",
    "    # Using the k8s API directly for the create\n",
    "    api_instance = client.CustomObjectsApi()\n",
    "        \n",
    "    while True:\n",
    "        try:\n",
    "            api_instance.create_namespaced_custom_object(\n",
    "                    group=constants.KSERVE_GROUP,\n",
    "                    version=inference_service.api_version.split(\"/\")[1],\n",
    "                    namespace=\"{{workflow.namespace}}\",\n",
    "                    plural=constants.KSERVE_PLURAL,\n",
    "                    body=inference_service)\n",
    "            break\n",
    "        except client.exceptions.ApiException as api_exception:\n",
    "            if api_exception.status==HTTPStatus.CONFLICT:\n",
    "                try:\n",
    "                    api_instance.delete_namespaced_custom_object(\n",
    "                        group=constants.KSERVE_GROUP,\n",
    "                        version=inference_service.api_version.split(\"/\")[1],\n",
    "                        namespace=\"{{workflow.namespace}}\",\n",
    "                        plural=constants.KSERVE_PLURAL,\n",
    "                        name=name)\n",
    "                    sleep(15)\n",
    "                except client.exceptions.ApiException as api_exception2:\n",
    "                    if api_exception2.status in {HTTPStatus.NOT_FOUND, HTTPStatus.GONE}:\n",
    "                        pass\n",
    "                    else:\n",
    "                        raise\n",
    "\n",
    "            else:\n",
    "                raise\n",
    "            \n",
    "    kclient = KServeClient()\n",
    "    kclient.wait_isvc_ready(name=name, namespace=\"{{workflow.namespace}}\")\n",
    "    \n",
    "    if not kclient.is_isvc_ready(name=name, namespace=\"{{workflow.namespace}}\"):\n",
    "        raise RuntimeError(f\"The inference service {name} is not ready!\")\n",
    "\n",
    "deploy_inference_service_comp = kfp.components.create_component_from_func(\n",
    "    func=deploy_inference_service, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8b9d085-8742-46a9-9288-a86781e737b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"summarize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97a3c990-1c35-405b-bd3e-ed2a63ef3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=PIPELINE_NAME)\n",
    "def summarize_pipeline(\n",
    "    source_repo: str = \"https://github.com/ntl-ibm/kubeflow-ppc64le-examples.git\",\n",
    "    source_branch: str = \"3.0.0\",\n",
    "    source_context: str = \"natural-language-processing/huggingface-summarization/src\",\n",
    "    minio_endpoint=\"minio-service.kubeflow:9000\",\n",
    "    checkpoint: str=\"t5-small\",\n",
    "    model_max_length: int = 512,\n",
    "    model_version: int = 1,\n",
    "    epochs: int = 3,\n",
    "    model_name: str = \"billsum\",\n",
    "    prefix: str = \"summarize: \",\n",
    "    suffix: str = \"\"\n",
    "):\n",
    "    def mount_volume(task, pvc_name, mount_path, volume_subpath, read_only=False):\n",
    "        task.add_volume(\n",
    "            V1Volume(\n",
    "                name=pvc_name,\n",
    "                persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(pvc_name),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        task.add_volume_mount(\n",
    "            V1VolumeMount(\n",
    "                name=pvc_name,\n",
    "                mount_path=mount_path,\n",
    "                sub_path=volume_subpath,\n",
    "                read_only=read_only,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def env_var_from_secret(env_var_name: str, secret_name: str, secret_key: str) -> V1EnvVar:\n",
    "        return V1EnvVar(name=env_var_name,\n",
    "                                     value_from=V1EnvVarSource(\n",
    "                                         secret_key_ref=V1SecretKeySelector(\n",
    "                                             name=secret_name,\n",
    "                                             key=secret_key\n",
    "                                         )\n",
    "                                     )\n",
    "                                    )\n",
    "\n",
    "    workspace_volume_volop = dsl.VolumeOp(\n",
    "        name=\"Create workspace\",\n",
    "        resource_name=\"shared-workspace-pvc\",\n",
    "        modes=dsl.VOLUME_MODE_RWM,\n",
    "        size=\"4Gi\",\n",
    "        set_owner_reference=True,\n",
    "    )\n",
    "\n",
    "    clone_repo_task = run_commands_comp(\n",
    "        [\n",
    "            f\"git clone {source_repo}  /workspace/repo -b {source_branch} || true\"\n",
    "        ],\n",
    "        \"/workspace\",\n",
    "    )\n",
    "    clone_repo_task.add_pvolumes({\"/workspace\": workspace_volume_volop.volume})\n",
    "    clone_repo_task.set_display_name(\"Clone Repo\")\n",
    "    \n",
    "    \n",
    "    preprocess_data_task = run_commands_comp(\n",
    "        [(\"python prepare.py \" +\n",
    "           f\"--checkpoint={checkpoint} \" +\n",
    "            \"--prepared_dataset_dir=/workspace/dataset \" +\n",
    "           f\"--model_max_len={model_max_length} \" +\n",
    "           (f\"--prefix={prefix} \" if prefix else \"\") +\n",
    "           (f\"--suffix={suffix} \" if suffix else \"\")\n",
    "         )\n",
    "        ],\n",
    "        f\"/workspace/repo/{source_context}\"\n",
    "    )\n",
    "    preprocess_data_task.add_pvolumes({\"/workspace\": workspace_volume_volop.volume})\n",
    "    preprocess_data_task.after(clone_repo_task)\n",
    "    preprocess_data_task.set_display_name(\"Load and Preprocess data\")\n",
    "    \n",
    "    train_model_task = run_commands_comp(\n",
    "        [(\"python train.py \"\n",
    "           f\"--checkpoint={checkpoint} \"\n",
    "            \"--prepared_dataset_dir=/workspace/dataset \"\n",
    "            \"--model_dir=/workspace/billsum \"\n",
    "            f\"--epochs={epochs}\"\n",
    "         )\n",
    "        ],\n",
    "        f\"/workspace/repo/{source_context}\"\n",
    "    )\n",
    "    train_model_task.add_pvolumes({\"/workspace\": workspace_volume_volop.volume})\n",
    "    train_model_task.after(preprocess_data_task)\n",
    "    train_model_task.set_display_name(\"Train Model\")\n",
    "    train_model_task.set_gpu_limit(1)\n",
    "    train_model_task.set_cpu_limit('1')\n",
    "    train_model_task.set_memory_request('40G')\n",
    "    train_model_task.set_memory_limit('1024G')\n",
    "\n",
    "    evaluate_model_task = evaluate_model_comp(model_dir=\"/workspace/billsum\",\n",
    "                                              dataset_dir=\"/workspace/dataset\",\n",
    "                                              cwd=f\"/workspace/repo/{source_context}\")\n",
    "    evaluate_model_task.add_pvolumes({\"/workspace\": workspace_volume_volop.volume})\n",
    "    evaluate_model_task.after(train_model_task)\n",
    "    evaluate_model_task.set_display_name(\"Evaluate Model\")\n",
    "    evaluate_model_task.set_gpu_limit(1)\n",
    "\n",
    "    create_archive_task = create_model_archive_comp(model_dir=f\"/workspace/{model_name}\")\n",
    "    create_archive_task.add_pvolumes({\"/workspace\": workspace_volume_volop.volume})\n",
    "    create_archive_task.after(evaluate_model_task)\n",
    "    create_archive_task.set_display_name(\"create archive\")\n",
    "    \n",
    "    upload_archive_task = upload_archive_comp(\n",
    "        archive = create_archive_task.outputs[\"archive\"],\n",
    "        archive_name = f\"{model_name}.tar\"\n",
    "    )\n",
    "    upload_archive_task.container.add_env_variable(env_var_from_secret(\"MINIO_ID\", \"mlpipeline-minio-artifact\", \"accesskey\"))\n",
    "    upload_archive_task.container.add_env_variable(env_var_from_secret(\"MINIO_PWD\", \"mlpipeline-minio-artifact\", \"secretkey\"))\n",
    "    upload_archive_task.after(create_archive_task)\n",
    "\n",
    "    deploy_model_task = deploy_inference_service_comp(name=model_name,\n",
    "                                                           version=1,\n",
    "                                                           model_archive_s3=upload_archive_task.outputs[\"s3_address\"],\n",
    "                                                           predictor_image=PREDICTOR_IMAGE,\n",
    "                                                          prefix = prefix,\n",
    "                                                          suffix = suffix,\n",
    "                                                          predictor_min_replicas=0\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41c21543-2987-486d-ae1e-608bbc737b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_conf = kfp.dsl.PipelineConf()\n",
    "\n",
    "# Disable Caching\n",
    "def disable_cache_transformer(op: dsl.ContainerOp):\n",
    "    if isinstance(op, dsl.ContainerOp):\n",
    "        op.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    else:\n",
    "        op.add_pod_annotation(\n",
    "            name=\"pipelines.kubeflow.org/max_cache_staleness\", value=\"P0D\"\n",
    "        )\n",
    "    return op\n",
    "\n",
    "\n",
    "pipeline_conf.add_op_transformer(disable_cache_transformer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d30eea98-851a-43fd-8117-c2f97114b13f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_pipeline(pipeline_name: str):\n",
    "    \"\"\"Delete's a pipeline with the specified name\"\"\"\n",
    "\n",
    "    client = kfp.Client()\n",
    "    existing_pipelines = client.list_pipelines(page_size=999).pipelines\n",
    "    matches = (\n",
    "        [ep.id for ep in existing_pipelines if ep.name == pipeline_name]\n",
    "        if existing_pipelines\n",
    "        else []\n",
    "    )\n",
    "    for id in matches:\n",
    "        client.delete_pipeline(id)\n",
    "\n",
    "\n",
    "def get_experiment_id(experiment_name: str) -> str:\n",
    "    \"\"\"Returns the id for the experiment, creating the experiment if needed\"\"\"\n",
    "    client = kfp.Client()\n",
    "    existing_experiments = client.list_experiments(page_size=999).experiments\n",
    "    matches = (\n",
    "        [ex.id for ex in existing_experiments if ex.name == experiment_name]\n",
    "        if existing_experiments\n",
    "        else []\n",
    "    )\n",
    "\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "\n",
    "    exp = client.create_experiment(experiment_name)\n",
    "    return exp.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c2c9cff-452e-4255-a8c5-122055aa7f15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=/pipeline/#/pipelines/details/b133ef27-a122-49d4-bdac-09faf1899190>Pipeline details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/91d0b9aa-16e8-4b4c-a048-7f9b73aaabae\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PIPELINE_NAME = \"summarize\"\n",
    "\n",
    "client = kfp.Client()\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=summarize_pipeline,\n",
    "    package_path=f\"{PIPELINE_NAME}.yaml\",\n",
    "    pipeline_conf=pipeline_conf,\n",
    ")\n",
    "\n",
    "delete_pipeline(PIPELINE_NAME)\n",
    "uploaded_pipeline = client.upload_pipeline(f\"{PIPELINE_NAME}.yaml\", PIPELINE_NAME)\n",
    "run = client.run_pipeline(\n",
    "    experiment_id=get_experiment_id(\"summarize-exp\"),\n",
    "    job_name=\"summarize\",\n",
    "    pipeline_id=uploaded_pipeline.id,\n",
    "    params={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecc10906-cb91-42ad-afc2-b43f9484c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4069abb3-aeb1-47a5-80cd-92570f5c3e91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Inflation Reduction Act lowers prescription drug costs, health\n",
      "care costs, and energy costs.  It's the most aggressive action on\n",
      "tackling the climate crisis in American history, which will lift up\n",
      "American workers and create good-paying, union jobs across the\n",
      "country. It'll lower the deficit and ask the ultra-wealthy and\n",
      "corporations to pay their fair share. And no one making under $400,000\n",
      "per year will pay a penny more in taxes.\n"
     ]
    }
   ],
   "source": [
    "text = \"The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs.  It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. And no one making under $400,000 per year will pay a penny more in taxes.\"\n",
    "  \n",
    "import textwrap\n",
    "\n",
    "for line in textwrap.wrap(text, width=70):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e20e7652-8449-41cc-b852-f115111e2407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = requests.post(\"http://billsum.ntl-us-ibm-com.svc.cluster.local/v1/models/billsum:predict\",\n",
    "              json=\n",
    "                  {\"instances\" : [\"summarize: \" + text]}\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0669dd0-b55a-4de1-a202-4965335a0c89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'operate case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case case'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c66560ea-2e7b-4767-bbd5-cb16394c75f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operate case case case case case case case case case case case case\n",
      "case case case case case case case case case case case case case case\n",
      "case case case case case case case case case case case case case case\n",
      "case case case case case case case case case case case case case case\n",
      "case case case case case case case case case case case case case case\n",
      "case case case case case case case case case case case case case case\n",
      "case case case case case case case case case case case case case case\n",
      "case case case case case case case case case case case case case case\n",
      "case case case case case case case case case case case case case case\n",
      "case case case\n"
     ]
    }
   ],
   "source": [
    "for line in textwrap.wrap(r.json()[\"summary\"], width=70):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063963e8-beba-451f-91f0-a074ea697f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
