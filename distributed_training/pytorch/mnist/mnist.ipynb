{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841ff471-215d-4984-a0f5-b88fd13a5b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038e527-8023-445d-849d-123cae61e46c",
   "metadata": {},
   "source": [
    "# Distributed training example using PyTorch\n",
    "\n",
    "This notebook trains and evaluates a classifier of handwritten digits (Using the MNIST dataset). The training is distributed across multiple GPUs.\n",
    "\n",
    "There are important features and differences in this flow than other examples in this repo, such as the MPI/Tensorflow example.\n",
    "\n",
    "Author: Nick Lawrence ntl@us.ibm.com\n",
    "License: [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "## Container Image\n",
    "The components of this pipeline use a custom built container image as their base image. The Dockerfile is included in GitHub. The container image does *not* include a notebook server, meaning you cannot use it to launch a notebook. The notebook container images from https://quay.io/repository/ibm/kubeflow-notebook-image-ppc64le have a wide range of packages installed in them, and these can be used to start an interactive notebook server. The base image used in this example has installed a much smaller set of newer packages, including Python 3.10 and PyTorch 1.13 from RocketCE. Also included is pytorch-lightning, which makes it easier to code up models for distributed training.\n",
    "\n",
    "Since your notebook image and pipeline images are not the same you may be able to run code in the pipeline that does not run interactivly in the notebook. And you may be able to run code interactivly that does not run in the pipeline.\n",
    "\n",
    "The custom image also includes the pytorch_distributed_kf_tools, which simplifies the creation and deployment of the PyTorch Job. The source code for this package is in the GitHub Repo.\n",
    "\n",
    "You can see how the custom image was built and that packages that are included by looking at the Dockerfile.\n",
    "\n",
    "## Model Training Script\n",
    "When using distributed training with GPUs, most PyTorch models are trained within a script that is called from the command line, as opposed to a cell in a interactive notebook.\n",
    "\n",
    "The script to run the model is stored in the GitHub Repo.\n",
    "\n",
    "The Kubeflow train_and_test_model component will create a PyTorch job that runs the script across a pre-defined number of worker pods. The component will then monitor the job and wait for the job's completion.\n",
    "\n",
    "This script is downloaded by the pipeline, rather than being built into the container image. This allows the script to be changed without rebuilding the container image.\n",
    "\n",
    "## Shared Storage\n",
    "The Kubeflow component needs to make the Python script and training data available to the PytorchJob, and it needs to be able to obtain the trained model after training is completed.\n",
    "\n",
    "The pipeline will create a Volume as the first step in the pipeline.\n",
    "The pipeline will copy the training data and training script onto this storage so that the workers can access it.\n",
    "After training, the pipeline will copy the model from the shared storage to storage that is accessible outside the pipeline. (The notebook's volume in this example).\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd2949a-1204-45aa-bbe7-aa354eafcbb1",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3deb0460-f169-4bed-8d16-cba226a651bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.components import InputPath, OutputPath\n",
    "import kfp.dsl as dsl\n",
    "from kfp.dsl import PipelineConf, data_passing_methods\n",
    "from kubernetes.client import (\n",
    "    V1Volume,\n",
    "    V1PersistentVolumeClaimVolumeSource,\n",
    "    V1VolumeMount,\n",
    ")\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import List, NamedTuple\n",
    "\n",
    "BASE_IMAGE = \"quay.io/ntlawrence/mnist-dist-pytorch:1.0.6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b552cf95-1480-4b5e-a3d7-88ce6153b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_workspace():\n",
    "    from torchvision.datasets import MNIST\n",
    "    import subprocess\n",
    "\n",
    "    # Download data\n",
    "    _ = MNIST(\"/workspace/data\", download=True, train=True)\n",
    "\n",
    "    # Clone git repo\n",
    "    subprocess.run(\"mamba install --override-channels -c main git\", shell=True)\n",
    "    subprocess.run(\n",
    "        \"git clone https://github.com/ntl-ibm/kubeflow-ppc64le-examples.git  /workspace/kubeflow-ppc64le-examples -b pytorch_example_improvements\",\n",
    "        shell=True,\n",
    "    )\n",
    "\n",
    "\n",
    "prepare_workspace_comp = kfp.components.create_component_from_func(\n",
    "    prepare_workspace, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87c120ff-ef8a-4b09-b823-ae743bb867c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(shared_pvc_name: str, worker_image: str, model_ckpt: OutputPath(str)):\n",
    "\n",
    "    import json\n",
    "    import distributed_kf_tools.deploy as deploy\n",
    "    from distributed_kf_tools.template import OwningWorkFlow, PvcMount\n",
    "    from collections import namedtuple\n",
    "\n",
    "    for retries in range(5):\n",
    "        try:\n",
    "            ## Start the PyTorch job for distributed training\n",
    "            job_name = \"{{workflow.name}}\" + (f\"-{retries:03d}\" if retries else \"\")\n",
    "            deploy.run_pytorch_job(\n",
    "                # owning_workflow setups it up so that when the pipeline is deleted,\n",
    "                # the training job is cleaned up\n",
    "                owning_workflow=OwningWorkFlow(\n",
    "                    name=\"{{workflow.name}}\", uid=\"{{workflow.uid}}\"\n",
    "                ),\n",
    "                # These place holders for namespace and job name are\n",
    "                # filled in by Kubeflow when the pipeline runs.\n",
    "                namespace=\"{{workflow.namespace}}\",\n",
    "                pytorch_job_name=job_name,\n",
    "                # Shared volumes used by the training script\n",
    "                pvcs=[\n",
    "                    PvcMount(\n",
    "                        pvc_name=(shared_pvc_name),\n",
    "                        mount_path=\"/workspace\",\n",
    "                    )\n",
    "                ],\n",
    "                working_dir=\"/workspace/kubeflow-ppc64le-examples/distributed_training/pytorch_model_frameworks/mnist/src/\",\n",
    "                # The command to run in each worker\n",
    "                # This almost always starts with \"torch.distributed.run\" for DDP\n",
    "                command=[\n",
    "                    \"python\",\n",
    "                    \"-m\",\n",
    "                    \"torch.distributed.run\",\n",
    "                    \"train.py\",\n",
    "                    \"--root_dir=./work\",\n",
    "                    \"--data_dir=/workspace/data\",\n",
    "                    f\"--model={model_ckpt}\",\n",
    "                    \"--batch_size=672\",\n",
    "                    \"--checkpoint\",\n",
    "                    \"--max_epochs=150\",\n",
    "                ],\n",
    "                # Number of workers\n",
    "                num_workers=3,\n",
    "                # Number of GPUs per worker (OK to leave this at 1)\n",
    "                gpus_per_worker=1,\n",
    "                # The base image used for the worker pods\n",
    "                worker_image=worker_image,\n",
    "            )\n",
    "            break\n",
    "        except RuntimeError as e:\n",
    "            print(f\"THE JOB FAILED BECAUSE OF ERROR {e}\")\n",
    "\n",
    "\n",
    "train_model_comp = kfp.components.create_component_from_func(\n",
    "    train_model, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31a8707d-77db-47b6-b029-1a3ba605edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"Handwritten digit classification\",\n",
    "    description=\"An example pipeline that trains using distributed pytorch\",\n",
    ")\n",
    "def mnist_pipeline():\n",
    "\n",
    "    workspace_volume_volop = dsl.VolumeOp(\n",
    "        name=\"Create workspace for training\",\n",
    "        resource_name=\"shared-workspace-pvc\",\n",
    "        modes=dsl.VOLUME_MODE_RWM,\n",
    "        size=\"4Gi\",\n",
    "        set_owner_reference=True,\n",
    "    )\n",
    "\n",
    "    prepare_workspace_task = prepare_workspace_comp()\n",
    "    prepare_workspace_task.add_pvolumes({\"/workspace\": workspace_volume_volop.volume})\n",
    "\n",
    "    train_model_task = train_model_comp(\n",
    "        workspace_volume_volop.volume.persistent_volume_claim.claim_name,\n",
    "        worker_image=BASE_IMAGE,\n",
    "    )\n",
    "    train_model_task.after(prepare_workspace_task)\n",
    "    # train_model_task.add_pvolumes({\"/workspace\": create_shared_volume_volop.volume})\n",
    "    # train_model_task.after(prepare_shared_storage_task)\n",
    "    # train_model_task.set_display_name(\"Train and Test Model\")\n",
    "\n",
    "    # copy_model_task = copy_data_comp(\n",
    "    #    \"/workspace/mnist_model.pt\", \"/target/mnist_model.pt\"\n",
    "    # )\n",
    "    # copy_model_task.add_pvolumes({\"/workspace\": create_shared_volume_volop.volume})\n",
    "    # copy_model_task.add_volume(\n",
    "    #    V1Volume(\n",
    "    #        name=notebook_pvc_name,\n",
    "    #        persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(\n",
    "    #            notebook_pvc_name\n",
    "    #        ),\n",
    "    #    )\n",
    "    # )\n",
    "    # copy_model_task.add_volume_mount(\n",
    "    #    V1VolumeMount(name=notebook_pvc_name, mount_path=\"/target\")\n",
    "    # )\n",
    "    # copy_model_task.set_display_name(f\"Copy Model to target PVC\")\n",
    "    # copy_model_task.after(train_model_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9970a3-f083-49b1-a7ab-5d999215adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"MNIST HW Classification Pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b121e2-6498-45a1-8391-d1936c532f1b",
   "metadata": {},
   "source": [
    "# Configure Pipeline\n",
    "\n",
    "The first transformer disables caching for our pipeline. Kubeflow caches tasks based on input and output parameters. Because we are using shared storage, the input parameters are the same as previous runs, however the data on the shared storage is most likely different.\n",
    "\n",
    "The second transformer adds a node constraint to all tasks. This is only needed in the IBM Lab. We currently have a few machines that are older Power 8 hardware in the cluster. Python 3.10 from RocketCE has been optimized for Power 9 and Power 10. We'll force all out pods to run on the newer AC922's with newer hardware. (This isn't an issue for environments that have all AC922s or newer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a36cd67f-8f7d-4186-85f8-a09935fcd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_conf = kfp.dsl.PipelineConf()\n",
    "\n",
    "# Disable Caching\n",
    "def disable_cache_transformer(op: dsl.ContainerOp):\n",
    "    if isinstance(op, dsl.ContainerOp):\n",
    "        op.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    else:\n",
    "        op.add_pod_annotation(\n",
    "            name=\"pipelines.kubeflow.org/max_cache_staleness\", value=\"P0D\"\n",
    "        )\n",
    "    return op\n",
    "\n",
    "\n",
    "pipeline_conf.add_op_transformer(disable_cache_transformer)\n",
    "\n",
    "# This transformer is only Relevant inside an IBM lab that has both P8 and P9 machines\n",
    "# (Assumptioin is that the P9 machines have the ai.accelerator label on them)\n",
    "def run_on_power_9_transformer(op: dsl.ContainerOp):\n",
    "    if isinstance(op, dsl.ContainerOp):\n",
    "        op.add_node_selector_constraint(\"ai.accelerator\", \"V100\")\n",
    "\n",
    "\n",
    "pipeline_conf.add_op_transformer(run_on_power_9_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1de34-2104-4cfe-a923-aa3177d549fa",
   "metadata": {},
   "source": [
    "# Compile, upload and run pipeline\n",
    "\n",
    "This creates a run of the pipeline within an experiment.\n",
    "\n",
    "The parameter to the pipeline is the name of the PVC to copy the model onto. *This PVC must have an access mode of ReadWriteMany!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d6ca018-cbbc-4a36-9135-6b2ecc9d48d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pipeline(pipeline_name: str):\n",
    "    \"\"\"Delete's a pipeline with the specified name\"\"\"\n",
    "\n",
    "    client = kfp.Client()\n",
    "    existing_pipelines = client.list_pipelines(page_size=999).pipelines\n",
    "    matches = (\n",
    "        [ep.id for ep in existing_pipelines if ep.name == pipeline_name]\n",
    "        if existing_pipelines\n",
    "        else []\n",
    "    )\n",
    "    for id in matches:\n",
    "        client.delete_pipeline(id)\n",
    "\n",
    "\n",
    "def get_experiment_id(experiment_name: str) -> str:\n",
    "    \"\"\"Returns the id for the experiment, creating the experiment if needed\"\"\"\n",
    "    client = kfp.Client()\n",
    "    existing_experiments = client.list_experiments(page_size=999).experiments\n",
    "    matches = (\n",
    "        [ex.id for ex in existing_experiments if ex.name == experiment_name]\n",
    "        if existing_experiments\n",
    "        else []\n",
    "    )\n",
    "\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "\n",
    "    exp = client.create_experiment(experiment_name)\n",
    "    return exp.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c00906ed-c38f-4159-bac8-ee8dd1b50689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=/pipeline/#/pipelines/details/29080f38-0578-49e1-912e-cebe301e4baf>Pipeline details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/a971830a-9bf2-47d9-a036-256a633452d1\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PIPELINE_NAME = \"train-mnist-pytorch-model\"\n",
    "\n",
    "client = kfp.Client()\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=mnist_pipeline,\n",
    "    package_path=f\"{PIPELINE_NAME}.yaml\",\n",
    "    pipeline_conf=pipeline_conf,\n",
    ")\n",
    "\n",
    "delete_pipeline(PIPELINE_NAME)\n",
    "uploaded_pipeline = client.upload_pipeline(f\"{PIPELINE_NAME}.yaml\", PIPELINE_NAME)\n",
    "run = client.run_pipeline(\n",
    "    experiment_id=get_experiment_id(\"mnist-pytorch-exp\"),\n",
    "    job_name=\"mnist-pytorch\",\n",
    "    pipeline_id=uploaded_pipeline.id,\n",
    "    params={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9bd57c2-35d1-4f73-b5c1-7ff08fb3ad21",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "Run timeout",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m TWENTY_MIN \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_run_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTWENTY_MIN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: result\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m: result\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39merror,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(result\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mfinished_at \u001b[38;5;241m-\u001b[39m result\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mcreated_at),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m: result\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mmetrics,\n\u001b[1;32m      8\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/kfp/_client.py:1271\u001b[0m, in \u001b[0;36mClient.wait_for_run_completion\u001b[0;34m(self, run_id, timeout)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWaiting for the job to complete...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m-> 1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun timeout\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1272\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_run_response\n",
      "\u001b[0;31mTimeoutError\u001b[0m: Run timeout"
     ]
    }
   ],
   "source": [
    "TWENTY_MIN = 20 * 60\n",
    "result = client.wait_for_run_completion(run.id, timeout=TWENTY_MIN)\n",
    "{\n",
    "    \"status\": result.run.status,\n",
    "    \"error\": result.run.error,\n",
    "    \"time\": str(result.run.finished_at - result.run.created_at),\n",
    "    \"metrics\": result.run.metrics,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc42bfe-2cab-44c6-94e2-3b95b2abf02c",
   "metadata": {},
   "source": [
    "# Check output\n",
    "\n",
    "After the pipeine completes, you should see the model in the root directory of the pvc defined by the NOTEBOOK_PVC_NAME variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011f068f-9264-48f3-a82f-99af8dcbd392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
