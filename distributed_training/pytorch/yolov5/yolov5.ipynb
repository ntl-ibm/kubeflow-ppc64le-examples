{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba72d66b-7e23-44c5-8fa3-e93d23f2088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694bbf2f-551d-435a-90c9-e810c64971a3",
   "metadata": {},
   "source": [
    "# Honey Bee Computer Vision Example\n",
    "\n",
    "This example shows how to use python scripts from open-source repos to train a yolov5 model, and evaluate the results.\n",
    "\n",
    "The example trains a model to detect Honey Bees using [YoloV5](https://github.com/ultralytics/yolov5). The purpose of the example is to explain how to train a model using Kubeflow, the YOLOV5 repo and sample data. \n",
    "\n",
    "Accessed classes are:\n",
    "* Bees (workers or foragers)\n",
    "* Bees carrying pollen\n",
    "* Drones\n",
    "* Queens\n",
    "\n",
    "\n",
    "Datasets for training of object detection models are usually large, and take a long time to train. They often contain many pre-augmented images. For our purposes, we've included a sample of training data to use for this exercise. The poor quantity and quality of the training data will not produce a good model, but it will train quickly, and allow for experimentation with the pipeline.\n",
    "\n",
    "For fun, we also included the weights from a model using a much larger version of this dataset with 500+ epochs (This takes many hours to train).\n",
    "\n",
    "The dataset was sampled from here: https://universe.roboflow.com/matt-nudi/honey-bee-detection-model-zgjnb (creative commons license, but requires an account/email to download).\n",
    "\n",
    "## Author\n",
    "\n",
    "Nick Lawrence ntl@us.ibm.com\n",
    "\n",
    "## License\n",
    "Apache-2.0 License\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4d10f2-c775-4816-a57e-5297c1c23d8a",
   "metadata": {},
   "source": [
    "The assumption is that this notebook has a volume mounted (you can set this up when you create the notebook). The PVC should have been created with an access mode of ReadWriteMany. This allows other pods to mount the volume.\n",
    "\n",
    "You can use the volume for your notebook's workspace (mounted at /home/jovyan/), or you can use a data volume.\n",
    "\n",
    "The data set will be extracted to the volume in these next few cells. The data will be loaded into the pipeline via a volume, rather than a download. This simulates a use case where the training data has been pre loaded on a volume in the kubernetes cluster, and is large enough where a download is expensive.\n",
    "\n",
    "The volume name is defined in this next cell, as is the path to the extracted Roboflow data set for the bees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b76914e-c3d1-496e-8a52-764eab5cd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOLUME_CLAIM_NAME = \"dist-demo-volume\"\n",
    "MOUNT_POINT = \"/home/jovyan/\"\n",
    "BEE_DATA_SET_SUBPATH = \"bee_dataset\"\n",
    "BEE_DATA_SET_PATH = f\"{MOUNT_POINT}/{BEE_DATA_SET_SUBPATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f8c147-ef4d-4cad-9613-f52395b14fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {BEE_DATA_SET_PATH}\n",
    "!tar -xf /home/jovyan/kubeflow-ppc64le-examples/object-detection-yolov5/data/dataset.tar.gz -C {BEE_DATA_SET_PATH} --strip-components 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf03b6e-d8cd-4900-896d-353f332a27c7",
   "metadata": {},
   "source": [
    "## Imports and constants\n",
    "\n",
    "If you've build your own yolov5 container, you should change the BASE_IMAGE variable to your own image here. The Dockerfile for the image is included in the \"Notebook Container Image Source\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b555cbe3-c15a-4361-aa42-153fa814e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import InputPath, OutputPath\n",
    "from kubernetes.client.models import (\n",
    "    V1Volume,\n",
    "    V1VolumeMount,\n",
    "    V1PersistentVolumeClaimVolumeSource,\n",
    "    V1EmptyDirVolumeSource,\n",
    ")\n",
    "from kfp.dsl import PipelineConf, data_passing_methods\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "BASE_IMAGE = \"quay.io/ntlawrence/yolov5-dist-pytorch:1.0.2\"\n",
    "COMPONENT_CATALOG_FOLDER = f\"{os.getenv('HOME')}/components\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6c0e3-98ed-462c-8746-3adc4ecdf930",
   "metadata": {},
   "source": [
    "## Load Data component\n",
    "The first component in the pipeline copies the data from an input path to an output parameter.\n",
    "\n",
    "Essentially this moves the data from the volume into the pipeline. A common problem when using PVCs is that paths to data in a PVC (strings), are not interchangable with pipeline inputs and outputs (InputPath and OutputPath). Components like this are needed to transform data on a PVC into something that can be used by existing pipeline components that expect InputPath and OutputPath params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f800195c-1c9c-4a92-8106-d884a0975288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_url(\n",
    "    source: str,\n",
    "    dest: OutputPath(str),\n",
    "):\n",
    "    import os\n",
    "    import shutil\n",
    "    from urllib.request import urlretrieve\n",
    "    from urllib.parse import urlparse\n",
    "\n",
    "    # Make target directories if needed\n",
    "    parent_dirs = os.path.dirname(dest)\n",
    "    if not os.path.exists(parent_dirs):\n",
    "        os.makedirs(parent_dirs)\n",
    "\n",
    "    # Option to use an empty file to indicate no weights\n",
    "    if not source:\n",
    "        with open(dest, \"w\") as _:\n",
    "            pass\n",
    "\n",
    "    source_details = urlparse(source)\n",
    "\n",
    "    if source_details.scheme == \"file\":\n",
    "        if os.path.isdir(source_details.path):\n",
    "            shutil.copytree(source_details.path, dest)\n",
    "        else:\n",
    "            shutil.copyfile(source_details.path, dest)\n",
    "    elif source_details.scheme in (\"http\", \"https\", \"ftp\", \"ftps\"):\n",
    "        urlretrieve(source, filename=dest)\n",
    "    else:\n",
    "        raise ValueError(f\"source does not use a supported url scheme\")\n",
    "\n",
    "\n",
    "load_from_url_comp = kfp.components.create_component_from_func(\n",
    "    load_from_url, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dbcc2e-66d8-466e-8535-a29d25c1e30c",
   "metadata": {},
   "source": [
    "## Copy data from one path to another\n",
    "This component is a helper to move data from one volume path to another.\n",
    "\n",
    "This component allows us to copy pipeline artifacts to a mounted PVC for use outside of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9fcda6-5f27-40dd-86da-f964b87852a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(source: str, dest: str):\n",
    "    import os\n",
    "    import shutil\n",
    "\n",
    "    # Make target directories if needed\n",
    "    parent_dirs = os.path.basename(dest)\n",
    "    if not os.path.exists(parent_dirs):\n",
    "        os.makedirs(parent_dirs)\n",
    "\n",
    "    if os.path.isdir(source):\n",
    "        shutil.copytree(source, dest)\n",
    "    else:\n",
    "        shutil.copyfile(source, dest)\n",
    "\n",
    "\n",
    "copy_data_comp = kfp.components.create_component_from_func(\n",
    "    copy_data, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71b0df9-4c9b-47b0-a9f3-52ebf96d6ab2",
   "metadata": {},
   "source": [
    "# Prepare shared storage\n",
    "For our distributed training, the workers need to share the model configuration and initial training weights.\n",
    "We also need to be able to copy the output data from the training back into the pipeline.\n",
    "\n",
    "This component set's up the shared storage for those tasks.\n",
    "\n",
    "(The training data is also shared between workers, but this is stored on it's on shared storage in this example, not the shared training storage PVC.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "453dc5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_shared_storage(\n",
    "    model_cfg_path: InputPath(str),\n",
    "    initial_weights_path: InputPath(str),\n",
    "):\n",
    "    import os\n",
    "    import shutil\n",
    "\n",
    "    def copyf(source: str, dest: str(str)):\n",
    "        \"\"\"\n",
    "        Copies a file or directory,\n",
    "        creating destination parent dirs as needed\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import shutil\n",
    "\n",
    "        parent_dirs = os.path.dirname(dest)\n",
    "        os.makedirs(parent_dirs, exist_ok=True)\n",
    "\n",
    "        if os.path.isdir(source):\n",
    "            shutil.copytree(source, dest)\n",
    "        else:\n",
    "            shutil.copyfile(source, dest)\n",
    "\n",
    "    # The \"training pvc is used to share data between the torch jobs and this component\n",
    "    # We need to copy the config and initial weights to it\n",
    "    copyf(model_cfg_path, f\"/workspace/input/config.yaml\")\n",
    "    copyf(initial_weights_path, f\"/workspace/input/weights.pt\")\n",
    "\n",
    "    # Create a directory to store the output of training, we'll\n",
    "    # copy data from here to output paths\n",
    "    os.makedirs(f\"workspace/output\", exist_ok=True)\n",
    "\n",
    "\n",
    "prepare_shared_storage_comp = kfp.components.create_component_from_func(\n",
    "    prepare_shared_storage,\n",
    "    base_image=BASE_IMAGE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ec2ab-9d32-44af-b126-57afbe8e9c39",
   "metadata": {},
   "source": [
    "## Train Model component\n",
    "\n",
    "Run the python train.py CLI to train the model\n",
    "\n",
    "This version uses multi-node GPU.\n",
    "\n",
    "The trained model and results.csv are reported as output parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "323c8c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_distributed(\n",
    "    model: OutputPath(str),\n",
    "    results: OutputPath(str),\n",
    "    epochs: int,\n",
    "    gpus: int,\n",
    "    training_pvc_name: str,\n",
    "    dataset_pvc_name: str,\n",
    "    worker_image: str,\n",
    "    dataset_subpath: str = \"\",\n",
    "    img: int = 640,\n",
    "    batch_size: int = 112,\n",
    "    replicas: int = 7,\n",
    "):\n",
    "    import os\n",
    "    import shutil\n",
    "    import distributed_kf_tools.deploy as deploy\n",
    "    from distributed_kf_tools.template import OwningWorkFlow, PvcMount\n",
    "\n",
    "    devices = \",\".join([str(gpu) for gpu in range(gpus)])\n",
    "\n",
    "    ## Start the PyTorch job for distributed training\n",
    "    deploy.run_pytorch_job(\n",
    "        # owning_workflow setups it up so that when the pipeline is deleted,\n",
    "        # the training job is cleaned up\n",
    "        owning_workflow=OwningWorkFlow(\n",
    "            name=\"{{workflow.name}}\", uid=\"{{workflow.uid}}\"\n",
    "        ),\n",
    "        # These place holders for namespace and job name are\n",
    "        # filled in by Kubeflow when the pipeline runs.\n",
    "        namespace=\"{{workflow.namespace}}\",\n",
    "        pytorch_job_name=\"{{workflow.name}}\",\n",
    "        # Shared volumes used by the training script\n",
    "        # The key to the mounting is that the \"runs\" directory of yolov5\n",
    "        # is mapped to the \"/workspace/output\" dir in the pvc.\n",
    "        # This allows us to get to the output of the runs\n",
    "        # after training (as /workspace/output in our mount of the PVC).\n",
    "        pvcs=[\n",
    "            PvcMount(\n",
    "                pvc_name=training_pvc_name,\n",
    "                mount_path=f\"/yolov5/runs/\",\n",
    "                subpath=\"output\",\n",
    "            ),\n",
    "            PvcMount(\n",
    "                pvc_name=training_pvc_name,\n",
    "                mount_path=f\"/training\",\n",
    "            ),\n",
    "            PvcMount(\n",
    "                pvc_name=dataset_pvc_name,\n",
    "                mount_path=f\"/dataset\",\n",
    "                subpath=dataset_subpath,\n",
    "            ),\n",
    "        ],\n",
    "        # The command to run in each worker\n",
    "        # This almost always starts with \"torch.distributed.run\" for DDP\n",
    "        command=[\n",
    "            \"python\",\n",
    "            \"-m\",\n",
    "            \"torch.distributed.run\",\n",
    "            \"train.py\",\n",
    "            f\"--device={devices}\",\n",
    "            f\"--img={img}\",\n",
    "            f\"--batch-size={batch_size}\",\n",
    "            \"--noplots\",\n",
    "            f\"--epochs={epochs}\",\n",
    "            \"--weights=/training/input/weights.pt\",\n",
    "            \"--cache=/tmp\",\n",
    "            \"--cfg=/training/input/config.yaml\",\n",
    "            \"--data=/dataset/data.yaml\",\n",
    "            \"--optimizer=Adam\",\n",
    "        ],\n",
    "        # Number of workers\n",
    "        num_workers=replicas,\n",
    "        # Number of GPUs per worker (OK to leave this at 1)\n",
    "        gpus_per_worker=gpus,\n",
    "        # The base image used for the worker pods\n",
    "        worker_image=worker_image,\n",
    "    )\n",
    "\n",
    "    ########################################################\n",
    "    # Copy trained model and results to output parameters\n",
    "    ########################################################\n",
    "    os.makedirs(os.path.dirname(model), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(results), exist_ok=True)\n",
    "\n",
    "    shutil.copyfile(f\"/training/output/train/exp/weights/best.pt\", model)\n",
    "    shutil.copyfile(f\"/training/output/train/exp/results.csv\", results)\n",
    "\n",
    "\n",
    "train_model_comp = kfp.components.create_component_from_func(\n",
    "    train_model_distributed,\n",
    "    base_image=BASE_IMAGE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff5ee1-b5ad-402b-a70d-9ec970fc59e0",
   "metadata": {},
   "source": [
    "## Component to convert the model to ONNX\n",
    "\n",
    "The export tool supports quantizing, the model, and so we've added that option as a parameter to the component. The ability to quantize is important for models that will be used for inferencing on edge devices. Many edge devices do not have the resources to evaluate deep neural networks, and and smaller model makes it possible to run inferencing in those environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87865918-1782-4392-9c6a-e14dd9c833b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_model_to_onnx(\n",
    "    model: InputPath(str),\n",
    "    model_format: str,\n",
    "    onnx_model: OutputPath(str),\n",
    "    quantize: str = \"\",\n",
    "):\n",
    "    import subprocess\n",
    "    import shutil\n",
    "    import os\n",
    "\n",
    "    # export.py uses the file name to determine the type of model\n",
    "    # mode is an input path where the name is generated by kubeflow\n",
    "    # We need to control the name that is used...\n",
    "    named_model = f\"/tmp/{os.path.basename(model)}.{model_format}\"\n",
    "    os.symlink(model, named_model)\n",
    "\n",
    "    quantize_param = f\"--{quantize}\" if quantize else \"\"\n",
    "\n",
    "    # https://github.com/ultralytics/yolov5/issues/10831\n",
    "    subprocess.run(\n",
    "        f\"python export.py --img 640 --include=onnx  {quantize_param} \"\n",
    "        f\"--data /dataset/data.yaml --weights {named_model} --device=cpu --opset 12\",\n",
    "        check=True,\n",
    "        cwd=\"/yolov5\",\n",
    "        shell=True,\n",
    "    )\n",
    "\n",
    "    shutil.copyfile(f\"/tmp/{os.path.basename(model)}.onnx\", onnx_model)\n",
    "\n",
    "\n",
    "convert_model_to_onnx_comp = kfp.components.create_component_from_func(\n",
    "    convert_model_to_onnx, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939ae4ac-d364-49b7-ba74-5b6898b801b8",
   "metadata": {},
   "source": [
    "## Model evaluation component\n",
    "\n",
    "This component can be used for both the original and onnx models. This allows comparisons between the ONNX model (which might be quantized), and the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3693a4de-9443-49a0-9222-466ce0996ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    results: OutputPath(str),\n",
    "    model: InputPath(str),\n",
    "    model_format: str = \"onnx\",  # onnx, pt, tf ....\n",
    "    conf_thres: float = 0.001,\n",
    "    iou_thres: float = 0.6,\n",
    "    max_det: int = 300,\n",
    "):\n",
    "    import subprocess\n",
    "    import os\n",
    "    import torch\n",
    "    from ruamel.yaml import YAML\n",
    "    import pathlib\n",
    "    import shutil\n",
    "\n",
    "    print(f\"The size of the model is {os.path.getsize(model)}\")\n",
    "\n",
    "    # valy.py uses the file name to determine the type of model\n",
    "    # mode is an input path where the name is generated by kubeflow\n",
    "    # We need to control the name that is used...\n",
    "    named_model = f\"/tmp/{os.path.basename(model)}.{model_format}\"\n",
    "    os.symlink(model, named_model)\n",
    "\n",
    "    subprocess.run(\n",
    "        f\"python val.py --weights {named_model} --data /dataset/data.yaml --img 640 \"\n",
    "        f\"--conf-thres {conf_thres} --iou-thres {iou_thres} --max-det {max_det} --workers=0 \",\n",
    "        check=True,\n",
    "        shell=True,\n",
    "        cwd=\"/yolov5\",\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(results), exist_ok=True)\n",
    "    shutil.copytree(\"/yolov5/runs/val/exp\", results)\n",
    "\n",
    "\n",
    "evaluate_model_comp = kfp.components.create_component_from_func(\n",
    "    evaluate_model, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9d1ff-2a55-4ed3-bf8f-4a03eee3a5db",
   "metadata": {},
   "source": [
    "## Write artifact to PVC\n",
    "\n",
    "Converts data from a pipeline parameter to a file stored on a PVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d76cbbb6-e6ac-4670-9abc-65de242a054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_artifact_to_path(source: InputPath(str), dest: str(str)):\n",
    "    import os\n",
    "    import shutil\n",
    "\n",
    "    parent_dirs = os.path.dirname(dest)\n",
    "    os.makedirs(parent_dirs, exist_ok=True)\n",
    "\n",
    "    if os.path.isdir(source):\n",
    "        shutil.copytree(source, dest)\n",
    "    else:\n",
    "        shutil.copyfile(source, dest)\n",
    "\n",
    "\n",
    "write_artifact_to_path_comp = kfp.components.create_component_from_func(\n",
    "    write_artifact_to_path, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139dd24b-4266-4672-81e8-715de84a23cd",
   "metadata": {},
   "source": [
    "## Upload the ONNX model\n",
    "\n",
    "The upload component is the same component that is shared with other examples. It loads the ONNX model into MinIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e184495-f063-4a9d-b488-dd494ae3000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_MODEL_COMPONENT = (\n",
    "    f\"{COMPONENT_CATALOG_FOLDER}/model-building/upload-model/component.yaml\"\n",
    ")\n",
    "\n",
    "upload_model_comp = kfp.components.load_component_from_file(UPLOAD_MODEL_COMPONENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8784575-c885-48dc-a78f-2805964f08a8",
   "metadata": {},
   "source": [
    "## Deploy Model Component\n",
    "\n",
    "Deploys the model to a NVIDIA Triton inference service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "343e326d-27bd-4e56-9d86-a136e8030c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOY_MODEL_COMPONENT = f\"{os.getenv('HOME')}/kubeflow-ppc64le-examples/deploy_triton_inference_service_component/deploy_triton_inference_service_component.yaml\"\n",
    "deploy_model_comp = kfp.components.load_component_from_file(DEPLOY_MODEL_COMPONENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50e359-defd-469d-a22b-61bfb1d7ce69",
   "metadata": {},
   "source": [
    "## Pipeline Definition\n",
    "\n",
    "This defines the pipeline, and the pipeline's paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e73b5831-97e9-44d2-87b5-d79679df21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKBOARD_RESOURCE_NAME = \"ml-blackboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bded8ffe-e62c-4b52-9d04-2f765ed6fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"bee-yolov5\")\n",
    "def bee_yolov5(\n",
    "    data_vol_pvc_name: str,\n",
    "    data_vol_subpath: str,\n",
    "    worker_image: str = BASE_IMAGE,\n",
    "    epochs: int = 750,\n",
    "    model_config_url: str = \"https://github.com/ultralytics/yolov5/raw/v7.0/models/yolov5s.yaml\",\n",
    "    initial_weights_url: str = \"https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt\",\n",
    "    quantize_onnx: str = \"int8\",\n",
    "    minio_url=\"minio-service.kubeflow:9000\",\n",
    "    model_version: int = 1,\n",
    "    dataset_size: str = \"4Gi\",\n",
    "    artifact_vol_pvc_name: str = \"\",\n",
    "    artifact_vol_subpath: str = \"\",\n",
    "):\n",
    "    def mount_volume(task, pvc_name, mount_path, volume_subpath, read_only=False):\n",
    "        task.add_volume(\n",
    "            V1Volume(\n",
    "                name=pvc_name,\n",
    "                persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(pvc_name),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        task.add_volume_mount(\n",
    "            V1VolumeMount(\n",
    "                name=pvc_name,\n",
    "                mount_path=mount_path,\n",
    "                sub_path=volume_subpath,\n",
    "                read_only=read_only,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    create_blackboard = dsl.VolumeOp(\n",
    "        name=\"Create Artefacts Blackboard\",\n",
    "        resource_name=BLACKBOARD_RESOURCE_NAME,\n",
    "        modes=dsl.VOLUME_MODE_RWO,\n",
    "        size=\"4Gi\",\n",
    "        set_owner_reference=True,\n",
    "    )\n",
    "\n",
    "    create_dataset_volume = dsl.VolumeOp(\n",
    "        name=f\"Create PVC for dataset\",\n",
    "        resource_name=\"dataset-pvc\",\n",
    "        modes=dsl.VOLUME_MODE_RWM,\n",
    "        size=dataset_size,\n",
    "        set_owner_reference=True,\n",
    "    )\n",
    "\n",
    "    # Load config  and data Tasks\n",
    "    model_config_task = load_from_url_comp(model_config_url)\n",
    "    model_config_task.after(create_blackboard)\n",
    "    model_config_task.set_display_name(\"Load model Config\")\n",
    "\n",
    "    initial_weights_task = load_from_url_comp(initial_weights_url)\n",
    "    initial_weights_task.after(create_blackboard)\n",
    "    initial_weights_task.set_display_name(\"Load initial weights\")\n",
    "\n",
    "    # Prepare Dataset\n",
    "    prepare_dataset_task = copy_data_comp(\"/src-vol\", \"/dest-vol/dataset\")\n",
    "    mount_volume(\n",
    "        prepare_dataset_task,\n",
    "        data_vol_pvc_name,\n",
    "        \"/src-vol\",\n",
    "        data_vol_subpath,\n",
    "        read_only=True,\n",
    "    )\n",
    "    mount_volume(\n",
    "        prepare_dataset_task,\n",
    "        create_dataset_volume.volume.persistent_volume_claim.claim_name,\n",
    "        \"/dest-vol\",\n",
    "        \"\",\n",
    "    )\n",
    "\n",
    "    prepare_dataset_task.after(create_dataset_volume)\n",
    "    prepare_dataset_task.after(create_blackboard)\n",
    "    prepare_dataset_task.set_display_name(\"Copy dataset to Pipeline owned PVC\")\n",
    "\n",
    "    # Create and prepare training volume\n",
    "    create_training_volume = dsl.VolumeOp(\n",
    "        name=f\"Create PVC for training\",\n",
    "        resource_name=\"yolov5-training\",\n",
    "        modes=dsl.VOLUME_MODE_RWM,\n",
    "        size=\"2G\",\n",
    "        set_owner_reference=True,\n",
    "    )\n",
    "\n",
    "    prepare_training_volume_task = prepare_shared_storage_comp(\n",
    "        model_cfg=model_config_task.outputs[\"dest\"],\n",
    "        initial_weights=initial_weights_task.outputs[\"dest\"],\n",
    "    )\n",
    "    mount_volume(\n",
    "        prepare_training_volume_task,\n",
    "        create_training_volume.volume.persistent_volume_claim.claim_name,\n",
    "        \"/workspace\",\n",
    "        \"\",\n",
    "    )\n",
    "    prepare_training_volume_task.after(create_training_volume)\n",
    "\n",
    "    # Train Model\n",
    "    train_model_task = train_model_comp(\n",
    "        epochs=epochs,\n",
    "        gpus=1,\n",
    "        worker_image=worker_image,\n",
    "        training_pvc_name=create_training_volume.volume.persistent_volume_claim.claim_name,\n",
    "        dataset_pvc_name=create_dataset_volume.volume.persistent_volume_claim.claim_name,\n",
    "        dataset_subpath=\"dataset\",\n",
    "    )\n",
    "\n",
    "    mount_volume(\n",
    "        train_model_task,\n",
    "        create_training_volume.volume.persistent_volume_claim.claim_name,\n",
    "        \"/training\",\n",
    "        \"\",\n",
    "    )\n",
    "    train_model_task.after(prepare_dataset_task)\n",
    "    train_model_task.after(prepare_training_volume_task)\n",
    "\n",
    "    # convert to ONNX\n",
    "    convert_model_to_onnx_task = convert_model_to_onnx_comp(\n",
    "        model=train_model_task.outputs[\"model\"],\n",
    "        model_format=\"pt\",\n",
    "        quantize=quantize_onnx,\n",
    "    )\n",
    "    mount_volume(\n",
    "        convert_model_to_onnx_task,\n",
    "        create_dataset_volume.volume.persistent_volume_claim.claim_name,\n",
    "        \"/dataset\",\n",
    "        \"dataset\",\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    evaluate_onnx_model_task = evaluate_model_comp(\n",
    "        model=convert_model_to_onnx_task.outputs[\"onnx_model\"],\n",
    "    )\n",
    "    evaluate_onnx_model_task.set_display_name(\"Evaluate ONNX Model\")\n",
    "    mount_volume(\n",
    "        evaluate_onnx_model_task,\n",
    "        create_dataset_volume.volume.persistent_volume_claim.claim_name,\n",
    "        \"/dataset\",\n",
    "        \"dataset\",\n",
    "    )\n",
    "\n",
    "    evaluate_pt_model_task = evaluate_model_comp(\n",
    "        model=train_model_task.outputs[\"model\"],\n",
    "        model_format=\"pt\",\n",
    "    )\n",
    "    evaluate_pt_model_task.set_display_name(\"Evaluate Torch Model\")\n",
    "    mount_volume(\n",
    "        evaluate_pt_model_task,\n",
    "        create_dataset_volume.volume.persistent_volume_claim.claim_name,\n",
    "        \"/dataset\",\n",
    "        \"dataset\",\n",
    "    )\n",
    "\n",
    "    # Upload ONNX model\n",
    "    upload_model_task = upload_model_comp(\n",
    "        convert_model_to_onnx_task.outputs[\"onnx_model\"],\n",
    "        minio_url=minio_url,\n",
    "        export_bucket=\"{{workflow.namespace}}-bee\",\n",
    "        model_format=\"onnx\",\n",
    "        model_name=\"bee\",\n",
    "        model_version=model_version,\n",
    "    )\n",
    "\n",
    "    # Deploy Inference Service\n",
    "    deploy_model_task = deploy_model_comp(\n",
    "        name=\"bee\",\n",
    "        rm_existing=True,\n",
    "        storage_uri=\"s3://{{workflow.namespace}}-bee/onnx\",\n",
    "        minio_url=minio_url,\n",
    "        predictor_protocol=\"v2\",\n",
    "    )\n",
    "    deploy_model_task.after(upload_model_task)\n",
    "\n",
    "    ##### Write evaluation results\n",
    "    with dsl.Condition(artifact_vol_pvc_name != \"\", name=\"store_onnx_metrics\"):\n",
    "        ## Save ONNX Metrics\n",
    "        write_onnx_artifact_to_path_task = write_artifact_to_path_comp(\n",
    "            evaluate_onnx_model_task.outputs[\"results\"],\n",
    "            \"/mnt/{{workflow.name}}/onnx-metrics\",\n",
    "        )\n",
    "        mount_volume(\n",
    "            write_onnx_artifact_to_path_task,\n",
    "            artifact_vol_pvc_name,\n",
    "            \"/mnt\",\n",
    "            artifact_vol_subpath,\n",
    "        )\n",
    "        write_onnx_artifact_to_path_task.set_display_name(\"Save ONNX metrics (PVC)\")\n",
    "\n",
    "        ## Save Torch Metrics\n",
    "        write_torch_artifact_to_path_task = write_artifact_to_path_comp(\n",
    "            evaluate_pt_model_task.outputs[\"results\"],\n",
    "            \"/mnt/{{workflow.name}}/pt-metrics\",\n",
    "        )\n",
    "        mount_volume(\n",
    "            write_torch_artifact_to_path_task,\n",
    "            artifact_vol_pvc_name,\n",
    "            \"/mnt\",\n",
    "            artifact_vol_subpath,\n",
    "        )\n",
    "        write_torch_artifact_to_path_task.set_display_name(\"Save Torch results (PVC)\")\n",
    "\n",
    "        ## Save Torch Model\n",
    "        write_torch_model_artifact_to_path_task = write_artifact_to_path_comp(\n",
    "            train_model_task.outputs[\"model\"],\n",
    "            \"/mnt/{{workflow.name}}/model.pt\",\n",
    "        )\n",
    "        mount_volume(\n",
    "            write_torch_model_artifact_to_path_task,\n",
    "            artifact_vol_pvc_name,\n",
    "            \"/mnt\",\n",
    "            artifact_vol_subpath,\n",
    "        )\n",
    "        write_torch_model_artifact_to_path_task.set_display_name(\n",
    "            \"Save Torch model (PVC)\"\n",
    "        )\n",
    "\n",
    "        ## Save ONNX Model\n",
    "        write_onnx_model_artifact_to_path_task = write_artifact_to_path_comp(\n",
    "            convert_model_to_onnx_task.outputs[\"onnx_model\"],\n",
    "            \"/mnt/{{workflow.name}}/model.onnx\",\n",
    "        )\n",
    "        mount_volume(\n",
    "            write_onnx_model_artifact_to_path_task,\n",
    "            artifact_vol_pvc_name,\n",
    "            \"/mnt\",\n",
    "            artifact_vol_subpath,\n",
    "        )\n",
    "        write_onnx_model_artifact_to_path_task.set_display_name(\"Save ONNX model (PVC)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee05810-645a-4f59-8499-55e6dbd1a02c",
   "metadata": {},
   "source": [
    "## Compile Pipeline with configuration options\n",
    "\n",
    "Uses a PVC for passing data between components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e610d564-1c10-4b31-a557-248706deb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://www.kubeflow.org/docs/components/pipelines/overview/caching/#managing-caching-staleness\n",
    "def disable_cache_transformer(op):\n",
    "    if isinstance(op, dsl.ContainerOp):\n",
    "        op.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    else:\n",
    "        op.add_pod_annotation(\n",
    "            name=\"pipelines.kubeflow.org/max_cache_staleness\", value=\"P0D\"\n",
    "        )\n",
    "    return op\n",
    "\n",
    "\n",
    "pipeline_conf = PipelineConf()\n",
    "pipeline_conf.add_op_transformer(disable_cache_transformer)\n",
    "\n",
    "pipeline_conf.data_passing_method = data_passing_methods.KubernetesVolume(\n",
    "    volume=V1Volume(\n",
    "        name=BLACKBOARD_RESOURCE_NAME,\n",
    "        persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(\n",
    "            \"{{workflow.name}}-\" + BLACKBOARD_RESOURCE_NAME\n",
    "        ),\n",
    "    ),\n",
    "    path_prefix=f\"{BLACKBOARD_RESOURCE_NAME}/\",\n",
    ")\n",
    "\n",
    "\n",
    "# This transformer is only relavent to an IBM Lab Sandbox\n",
    "# In that environment, we have Power 8 hardware, which\n",
    "# does not run the python 3.10 built by RocketCE.\n",
    "# This transformer forces all the work to run on the\n",
    "# AC922's (which have the label ai.accelerator=V100)\n",
    "#def run_on_power_9_transformer(op: dsl.ContainerOp):\n",
    "#    if isinstance(op, dsl.ContainerOp):\n",
    "#        op.add_node_selector_constraint(\"ai.accelerator\", \"V100\")\n",
    "\n",
    "\n",
    "#pipeline_conf.add_op_transformer(run_on_power_9_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2156e60-c033-4e1c-bde1-23d1a85fded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"Bee detector pipeline\"\n",
    "\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=bee_yolov5,\n",
    "    package_path=f\"{PIPELINE_NAME}.yaml\",\n",
    "    pipeline_conf=pipeline_conf,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881cd7d6-cbfc-4631-a196-7086dd530452",
   "metadata": {},
   "source": [
    "## Upload pipeline programmatically\n",
    "\n",
    "The YAML file generated by the previous compile can be used to create a pipeline through the UI.\n",
    "* Download the file to your workstation\n",
    "* Click \"Pipelines\" from the side bar\n",
    "* Press the \"upload pipeline\" button, and upload the YAML.\n",
    "\n",
    "After adding the pipline, you can run the pipeline from the UI without looking at the pipeline code. This allows an inexperienced user to run the pipeline with specific parameters, without the compelxity of Kubeflow componet code or K8S Awareness.\n",
    "\n",
    "These next few cells upload and run the pipeline programmatically, so that the example is \"automated\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3bf9f3c5-9a0c-4389-a802-c3a22ff40731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pipeline(pipeline_name: str):\n",
    "    \"\"\"Delete's a pipeline with the specified name\"\"\"\n",
    "\n",
    "    client = kfp.Client()\n",
    "    existing_pipelines = client.list_pipelines(page_size=999).pipelines\n",
    "    matches = (\n",
    "        [ep.id for ep in existing_pipelines if ep.name == pipeline_name]\n",
    "        if existing_pipelines\n",
    "        else []\n",
    "    )\n",
    "    for id in matches:\n",
    "        client.delete_pipeline(id)\n",
    "\n",
    "\n",
    "def get_experiment_id(experiment_name: str) -> str:\n",
    "    \"\"\"Returns the id for the experiment, creating the experiment if needed\"\"\"\n",
    "    client = kfp.Client()\n",
    "    existing_experiments = client.list_experiments(page_size=999).experiments\n",
    "    matches = (\n",
    "        [ex.id for ex in existing_experiments if ex.name == experiment_name]\n",
    "        if existing_experiments\n",
    "        else []\n",
    "    )\n",
    "\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "\n",
    "    exp = client.create_experiment(experiment_name)\n",
    "    return exp.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ddf37a64-9df0-4b00-a4ee-5b28a6c765d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline names need to be unique, so before we upload,\n",
    "# check for and delete any pipeline with the same name\n",
    "delete_pipeline(PIPELINE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e372f25-244e-4e31-96a3-9021d89b4412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=/pipeline/#/pipelines/details/de1b052c-7050-4b4e-8f0b-1a1523a4112b>Pipeline details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# upload the pipeline\n",
    "client = kfp.Client()\n",
    "uploaded_pipeline = client.upload_pipeline(f\"{PIPELINE_NAME}.yaml\", PIPELINE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3864f8d0-83d0-4fbc-ad77-78260c7e86e0",
   "metadata": {},
   "source": [
    "## Run the pipeline with parameters\n",
    "\n",
    "This is equivalent to running the pipeline from the pipelines view in the UI. Since a pipeline run needs to be part of an experiment, this code will create the experiment if it does not exist.\n",
    "\n",
    "When we run this manually, we'll use initial weights that have been trained on a much larger superset of this data, and with many more epochs. That will give us results that can be demoed with a fast training cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5f4733f-90fc-4dd3-842e-d37e5b9710d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/61da4737-1f60-4190-a66f-74567967e5cd\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_params = {\n",
    "    \"data_vol_pvc_name\": VOLUME_CLAIM_NAME,\n",
    "    \"data_vol_subpath\": BEE_DATA_SET_SUBPATH,\n",
    "    \"worker_image\": BASE_IMAGE,\n",
    "    \"epochs\": \"10\",\n",
    "    \"artifact_vol_pvc_name\": VOLUME_CLAIM_NAME,\n",
    "    \"artifact_vol_subpath\": \"runs\",\n",
    "}\n",
    "\n",
    "run = client.run_pipeline(\n",
    "    experiment_id=get_experiment_id(\"bee-exp\"),\n",
    "    job_name=\"bees\",\n",
    "    pipeline_id=uploaded_pipeline.id,\n",
    "    params=pipeline_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04249b8-0f60-44aa-a1b1-75749acee2ea",
   "metadata": {},
   "source": [
    "## Waits for the pipeline to complete \n",
    "\n",
    "* waits for up to 20 Min\n",
    "* Checks the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a774585c-f882-44ab-afc2-7e885fece3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Succeeded', 'error': None, 'time': '0:07:31'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TWENTY_MIN = 20 * 60\n",
    "result = client.wait_for_run_completion(run.id, timeout=TWENTY_MIN)\n",
    "{\n",
    "    \"status\": result.run.status,\n",
    "    \"error\": result.run.error,\n",
    "    \"time\": str(result.run.finished_at - result.run.created_at),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8ebc1-0fbc-4bbe-9fc4-4862a13f2d5e",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "We don't have yolov5 installed in the notebook server, but if we want to run the command with an inference, we can do that by running the command in a container.\n",
    "\n",
    "We use the same trick as other places where we mount a PVC that is also mounted locally.\n",
    "\n",
    "We need to be careful that the PVC that we share is read write multiple.\n",
    "\n",
    "The pipeline deployed the model to a Triton service, so that's the model that we'll use for prediction. Real world applications would build a front end web-app or transformer here to interact with the inference service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dff13d5c-235b-422f-a2d7-d3799a152557",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/var/run/secrets/kubernetes.io/serviceaccount/namespace\") as n:\n",
    "    NAMESPACE = n.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0be2de37-d66f-496d-8aa6-a87037a6ade4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): jobs.batch \"bee-inference-example\" not found\n",
      "job.batch/bee-inference-example created\n"
     ]
    }
   ],
   "source": [
    "inference_job_template = f\"\"\"\n",
    "apiVersion: batch/v1\n",
    "kind: Job\n",
    "metadata:\n",
    "  name: bee-inference-example\n",
    "spec:\n",
    "  template:\n",
    "    metadata:\n",
    "      annotations:\n",
    "        sidecar.istio.io/inject: >-\n",
    "                                 false\n",
    "    spec:\n",
    "      # The node selector is only relevant to a specific IBM Lab\n",
    "      # It forces the workload to run on an AC922 machine that has\n",
    "      # the ai.accelerator annotation, rather than the P8 machines\n",
    "      # in the environment. The image requires a P9 Machine. \n",
    "#    nodeSelector:\n",
    "#      ai.accelerator: V100\n",
    "     containers:\n",
    "      - command: [\"/bin/sh\", \"-c\"]\n",
    "        args: \n",
    "         - >-\n",
    "           python detect.py\n",
    "           --weights=http://bee.{NAMESPACE}.svc.cluster.local/v2/models/bee/infer\n",
    "           --data=/dataset/data.yaml\n",
    "           --source=/dataset/test/images/2016-03-15-04-09-38-1024x673_jpg.rf.aa352f3bd2a105dd7ff560e0ab42ae69.jpg\n",
    "           --conf-thres=.7\n",
    "           --iou-thres=.2\n",
    "           --max-det=500\n",
    "        image: {BASE_IMAGE}\n",
    "        imagePullPolicy: IfNotPresent\n",
    "        name: inference\n",
    "        volumeMounts:\n",
    "        - mountPath: /dataset\n",
    "          name: data\n",
    "          subPath: {BEE_DATA_SET_SUBPATH}\n",
    "        - mountPath: /yolov5/runs/\n",
    "          name: data\n",
    "          subPath: kubeflow-ppc64le-examples/pytorch_distributed/yolov5/notebook/\n",
    "     volumes:\n",
    "      - name: data\n",
    "        persistentVolumeClaim:\n",
    "          claimName: {VOLUME_CLAIM_NAME}\n",
    "      - emptyDir:\n",
    "          medium: Memory\n",
    "        name: dshm\n",
    "     restartPolicy: Never\n",
    "  backoffLimit: 0  \n",
    "\"\"\"\n",
    "\n",
    "!kubectl delete job bee-inference-example\n",
    "!echo '{inference_job_template}' | kubectl create -f -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "46d70740-0364-4efa-8aa3-0f1168578b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job.batch/bee-inference-example condition met\n",
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-qnx1ym7c because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "WARNING ⚠️ user config directory is not writeable, defaulting to '/tmp/Ultralytics'.\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['http://bee.kubeflow-ntl.svc.cluster.local/v2/models/bee/infer'], source=/dataset/test/images/2016-03-15-04-09-38-1024x673_jpg.rf.aa352f3bd2a105dd7ff560e0ab42ae69.jpg, data=/dataset/data.yaml, imgsz=[640, 640], conf_thres=0.7, iou_thres=0.2, max_det=500, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 v7.0-178-ga199480 Python-3.9.16 torch-1.13.0 CPU\n",
      "\n",
      "Using http://bee.kubeflow-ntl.svc.cluster.local/v2/models/bee/infer as Triton Inference Server...\n",
      "image 1/1 /dataset/test/images/2016-03-15-04-09-38-1024x673_jpg.rf.aa352f3bd2a105dd7ff560e0ab42ae69.jpg: 640x640 (no detections), 15976.3ms\n",
      "Speed: 14.7ms pre-process, 15976.3ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kubectl wait --for=condition=Complete job bee-inference-example --timeout=20m\n",
    "!kubectl logs -l job-name=bee-inference-example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f6e8e4-e92a-4cb2-bd06-b4549130da35",
   "metadata": {},
   "source": [
    "---\n",
    "You should now see the results from the classification in the local directory tree.\n",
    "\n",
    "The results are unlikely to be good, given the small training data and low number of epics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6407ee4-e7bb-4328-965d-52d20d218086",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
