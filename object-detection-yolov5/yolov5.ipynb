{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba72d66b-7e23-44c5-8fa3-e93d23f2088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694bbf2f-551d-435a-90c9-e810c64971a3",
   "metadata": {},
   "source": [
    "# Honey Bee Computer Vision Example\n",
    "\n",
    "This example shows how to use python scripts from open-source repos to train a yolov5 model, and evaluate the results.\n",
    "\n",
    "The example trains a model to detect Honey Bees using the V7 version of the https://github.com/ultralytics/yolov5. The purpose of the example is to explain how to train a model using Kubeflow, the YOLOV5 repo and sample data. \n",
    "\n",
    "Accessed classes are:\n",
    "* Bees (workers or foragers)\n",
    "* Bees carrying pollen\n",
    "* Drones\n",
    "* Queens\n",
    "\n",
    "\n",
    "Datasets for training of object detection models are usually large, and take a long time to train. They usually contain many pre-augmented images. For our purposes, we've included a sample of training data to use for this exercise. It will not produce a good model, but it will train quickly, and allow experimentation with the pipeline.\n",
    "\n",
    "We also included a pretrained model using a much larger version of this dataset with 500+ epochs (This takes many hours to train).\n",
    "\n",
    "The dataset was sampled from here: https://universe.roboflow.com/matt-nudi/honey-bee-detection-model-zgjnb (creative commons license, but requires collection of an email to download).\n",
    "\n",
    "The assumption is that this notebook has a data volume mounted (you can set this up when you create the notebook). The PVC should have been created with an access mode of ReadWriteMany. \n",
    "This allows other pods to mount the volume.\n",
    "\n",
    "Also assumed is that the notebook is running with a base image that has the yolov5 packages installed. You can see how the image was created by looking at the file in kubeflow-ppc64le-examples/object-detection-yolov5/Notebook Container Image Source/DockerFile.\n",
    "\n",
    "The data set will be extracted to the data volume in these next few cells. The data will be loaded into the pipeline via a volume, rather than a download. This simulates a use case where the training data has been pre loaded on a volume in the kubernetes cluster, and is large enough where a download is expensive.\n",
    "\n",
    "The volume name is defined in this next cell, as is the path to the extracted Roboflow data set for the bees. To keep things simple, the mount point is the same for both the notebook server, and also for the containers that mount the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b76914e-c3d1-496e-8a52-764eab5cd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOLUME_CLAIM_NAME = \"yolov5-work\"\n",
    "MOUNT_POINT = \"/home/jovyan/vol-1\"\n",
    "BEE_DATA_SET_PATH = f\"{MOUNT_POINT}/bee_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f8c147-ef4d-4cad-9613-f52395b14fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {BEE_DATA_SET_PATH}\n",
    "!tar -xf data/dataset.tar.gz -C {BEE_DATA_SET_PATH} --strip-components 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41eb3a-7842-401b-ab07-79c2816c79b3",
   "metadata": {},
   "source": [
    "## Copy YOLOV5 files to (notebook) persistent storage\n",
    "The base image has cloned the yolov5 repo into the root directory tree. (`/yolov5`). \n",
    "\n",
    "When the yolov5 scripts are executed, they will produce output in the same directory tree.\n",
    "\n",
    "The root directory is part of the containers R/W layer. That means that changes there are _NOT_ persisted. The root directory is also not accessible from the navigation bar of our notebook server.\n",
    "\n",
    "We'll copy the yolov5 files into our home directory, and that way we can run commands interactively and examine results with the file browser. Because the home directory has been mounted to a volume, the changes there will not be lost if the notebook server is shutdown.\n",
    "\n",
    "This copy is for interactive work in the notebook, the pipeline does not use this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e8229a-1d48-4ad6-ac60-1e74571755af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory is already copied\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -d /home/jovyan/yolov5 ] \n",
    "then \n",
    "   cp -R /yolov5 /home/jovyan/yolov5 \n",
    "else \n",
    "   echo \"The directory is already copied\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf03b6e-d8cd-4900-896d-353f332a27c7",
   "metadata": {},
   "source": [
    "## Imports and constants\n",
    "\n",
    "If you've build your own yolov5 container, you should change the BASE_IMAGE variable to your own image here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b555cbe3-c15a-4361-aa42-153fa814e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import InputPath, OutputPath\n",
    "from kubernetes.client.models import (\n",
    "    V1Volume,\n",
    "    V1VolumeMount,\n",
    "    V1PersistentVolumeClaimVolumeSource,\n",
    ")\n",
    "from kfp.dsl import PipelineConf, data_passing_methods\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "BASE_IMAGE = \"quay.io/ntlawrence/yolov5:pt1.12.1-yolo7.0-v1.1\"\n",
    "COMPONENT_CATALOG_FOLDER = f\"{os.getenv('HOME')}/components\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6c0e3-98ed-462c-8746-3adc4ecdf930",
   "metadata": {},
   "source": [
    "## Load Data component\n",
    "The first component in the pipeline copies the data from an input path to an output parameter.\n",
    "\n",
    "Essentially this moves the data from the volume into the pipeline. A common problem when using PVCs is that paths to data in a PVC (strings), are not interchangable with pipeline inputs and outputs (InputPath and OutputPath). Components like this are needed to transform data on a PVC into something that can be used by existing pipeline components that expect InputPath and OutputPath params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f800195c-1c9c-4a92-8106-d884a0975288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_url(\n",
    "    source: str,\n",
    "    dest: OutputPath(str),\n",
    "):\n",
    "    import os\n",
    "    import shutil\n",
    "    from urllib.request import urlretrieve\n",
    "    from urllib.parse import urlparse\n",
    "\n",
    "    # Make target directories if needed\n",
    "    parent_dirs = os.path.dirname(dest)\n",
    "    if not os.path.exists(parent_dirs):\n",
    "        os.makedirs(parent_dirs)\n",
    "\n",
    "    # Option to use an empty file to indicate no weights\n",
    "    if not source:\n",
    "        with open(dest, \"w\") as _:\n",
    "            pass\n",
    "\n",
    "    source_details = urlparse(source)\n",
    "\n",
    "    if source_details.scheme == \"file\":\n",
    "        if os.path.isdir(source_details.path):\n",
    "            shutil.copytree(source_details.path, dest)\n",
    "        else:\n",
    "            shutil.copyfile(source_details.path, dest)\n",
    "    elif source_details.scheme in (\"http\", \"https\", \"ftp\", \"ftps\"):\n",
    "        urlretrieve(source, filename=dest)\n",
    "    else:\n",
    "        raise ValueError(f\"source does not use a supported url scheme\")\n",
    "\n",
    "\n",
    "load_from_url_comp = kfp.components.create_component_from_func(\n",
    "    load_from_url, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dbcc2e-66d8-466e-8535-a29d25c1e30c",
   "metadata": {},
   "source": [
    "## Copy data from one path to another\n",
    "This component is a helper to move data from one volume path to another.\n",
    "\n",
    "This component allows us to copy pipeline artifacts to a mounted PVC for use outside of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd9fcda6-5f27-40dd-86da-f964b87852a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(source: str, dest: str):\n",
    "    import os\n",
    "    import shutil\n",
    "\n",
    "    # Make target directories if needed\n",
    "    parent_dirs = os.path.basename(dest)\n",
    "    if not os.path.exists(parent_dirs):\n",
    "        os.makedirs(parent_dirs)\n",
    "\n",
    "    if os.path.isdir(source):\n",
    "        shutil.copytree(source, dest)\n",
    "    else:\n",
    "        shutil.copyfile(source, dest)\n",
    "\n",
    "\n",
    "copy_data_comp = kfp.components.create_component_from_func(\n",
    "    copy_data, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ec2ab-9d32-44af-b126-57afbe8e9c39",
   "metadata": {},
   "source": [
    "## Train Model component\n",
    "\n",
    "Run the python train.py CLI to train the model\n",
    "\n",
    "Performance could be improved by using distributed training. This may be investigated and included in the example in the future.\n",
    "\n",
    "Integration with tensorboard is also an area that might be investigated and included in the future.\n",
    "\n",
    "The trained model and results.csv are reported as output parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96e35b5a-ad5d-4510-9574-c41c910382f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: OutputPath(str),\n",
    "    results: OutputPath(str),\n",
    "    model_cfg: InputPath(str),\n",
    "    initial_weights: InputPath(str),\n",
    "    epochs: int,\n",
    "):\n",
    "    import subprocess\n",
    "    import pathlib\n",
    "    from ruamel.yaml import YAML\n",
    "    import os\n",
    "    import shutil\n",
    "\n",
    "    # Option to pass an empty file to train from scratch\n",
    "    weights = initial_weights if os.path.getsize(initial_weights) > 0 else \"\"\n",
    "\n",
    "    subprocess.run(\"find /dataset -print\", shell=True)\n",
    "    subprocess.run(\n",
    "        f\"python train.py --img 640 --batch -1 --noplots --epochs {epochs} --cache /home/jovyan/cache --cfg={model_cfg} \"\n",
    "        f\"--data /dataset/data.yaml --weights {weights} --workers=0 --device=0 --optimizer=Adam\",\n",
    "        check=True,\n",
    "        cwd=\"/yolov5\",\n",
    "        shell=True,\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(model), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(results), exist_ok=True)\n",
    "\n",
    "    shutil.copyfile(\"/yolov5/runs/train/exp/weights/best.pt\", model)\n",
    "    shutil.copyfile(\"/yolov5/runs/train/exp/results.csv\", results)\n",
    "\n",
    "\n",
    "train_model_comp = kfp.components.create_component_from_func(\n",
    "    train_model, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff5ee1-b5ad-402b-a70d-9ec970fc59e0",
   "metadata": {},
   "source": [
    "## Component to convert the model to ONNX\n",
    "\n",
    "The export tool supports quantizing, the model, and so we've added that option as a parameter to the component. The ability to quantize is important for models that will be used for inferencing on edge devices. Many edge devices do not have the resources to evaluate deep neural networks, and and smaller model makes it possible to run inferencing in those environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87865918-1782-4392-9c6a-e14dd9c833b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_model_to_onnx(\n",
    "    model: InputPath(str),\n",
    "    model_format: str,\n",
    "    onnx_model: OutputPath(str),\n",
    "    quantize: str = \"\",\n",
    "):\n",
    "    import subprocess\n",
    "    import shutil\n",
    "    import os\n",
    "\n",
    "    # export.py uses the file name to determine the type of model\n",
    "    # mode is an input path where the name is generated by kubeflow\n",
    "    # We need to control the name that is used...\n",
    "    named_model = f\"/tmp/{os.path.basename(model)}.{model_format}\"\n",
    "    os.symlink(model, named_model)\n",
    "\n",
    "    quantize_param = f\"--{quantize}\" if quantize else \"\"\n",
    "\n",
    "    subprocess.run(\n",
    "        f\"python export.py --img 640 --include=onnx  {quantize_param} \"\n",
    "        f\"--data /dataset/data.yaml --weights {named_model} --device=cpu \",\n",
    "        check=True,\n",
    "        cwd=\"/yolov5\",\n",
    "        shell=True,\n",
    "    )\n",
    "\n",
    "    shutil.copyfile(f\"/tmp/{os.path.basename(model)}.onnx\", onnx_model)\n",
    "\n",
    "\n",
    "convert_model_to_onnx_comp = kfp.components.create_component_from_func(\n",
    "    convert_model_to_onnx, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939ae4ac-d364-49b7-ba74-5b6898b801b8",
   "metadata": {},
   "source": [
    "## Model evaluation component\n",
    "\n",
    "This component can be used for both the original and onnx models. This allows comparisons between the ONNX model (which might be quantized), and the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3693a4de-9443-49a0-9222-466ce0996ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    results: OutputPath(str),\n",
    "    model: InputPath(str),\n",
    "    model_format: str = \"onnx\",  # onnx, pt, tf ....\n",
    "    conf_thres: float = 0.001,\n",
    "    iou_thres: float = 0.6,\n",
    "    max_det: int = 300,\n",
    "):\n",
    "    import subprocess\n",
    "    import os\n",
    "    import torch\n",
    "    from ruamel.yaml import YAML\n",
    "    import pathlib\n",
    "    import shutil\n",
    "\n",
    "    print(f\"The size of the model is {os.path.getsize(model)}\")\n",
    "\n",
    "    if model_format == \"onnx\" and not torch.cuda.is_available():\n",
    "        # the base image is built with an onnxruntime for GPU\n",
    "        # This should work for both CPU and GPU, but val.py\n",
    "        # does it's own checking for CPU onnxruntime only\n",
    "        # Since that's not installed and not on pypl for ppc64le,\n",
    "        # The script won't work unless we change up the version\n",
    "        subprocess.run(\n",
    "            \"mamba install -c rocketce onnxruntime=1.13.1=hea80eff_cpu_py39_pb3.19_1 -y\",\n",
    "            check=True,\n",
    "            shell=True,\n",
    "        )\n",
    "\n",
    "    # valy.py uses the file name to determine the type of model\n",
    "    # mode is an input path where the name is generated by kubeflow\n",
    "    # We need to control the name that is used...\n",
    "    named_model = f\"/tmp/{os.path.basename(model)}.{model_format}\"\n",
    "    os.symlink(model, named_model)\n",
    "\n",
    "    subprocess.run(\n",
    "        f\"python val.py --weights {named_model} --data /dataset/data.yaml --img 640 \"\n",
    "        f\"--conf-thres {conf_thres} --iou-thres {iou_thres} --max-det {max_det} --workers=0 \",\n",
    "        check=True,\n",
    "        shell=True,\n",
    "        cwd=\"/yolov5\",\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(results), exist_ok=True)\n",
    "    shutil.copytree(\"/yolov5/runs/val/exp\", results)\n",
    "\n",
    "\n",
    "evaluate_model_comp = kfp.components.create_component_from_func(\n",
    "    evaluate_model, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9d1ff-2a55-4ed3-bf8f-4a03eee3a5db",
   "metadata": {},
   "source": [
    "## Write artifact to PVC\n",
    "\n",
    "Converts data from a pipeline parameter to a file stored on a PVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d76cbbb6-e6ac-4670-9abc-65de242a054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_artifact_to_path(source: InputPath(str), dest: str(str)):\n",
    "    import os\n",
    "    import shutil\n",
    "\n",
    "    parent_dirs = os.path.dirname(dest)\n",
    "    os.makedirs(parent_dirs, exist_ok=True)\n",
    "\n",
    "    if os.path.isdir(source):\n",
    "        shutil.copytree(source, dest)\n",
    "    else:\n",
    "        shutil.copyfile(source, dest)\n",
    "\n",
    "\n",
    "write_artifact_to_path_comp = kfp.components.create_component_from_func(\n",
    "    write_artifact_to_path, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139dd24b-4266-4672-81e8-715de84a23cd",
   "metadata": {},
   "source": [
    "## Upload the ONNX model\n",
    "\n",
    "The upload component is the same component that is shared with other examples. It loads the ONNX model into MinIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e184495-f063-4a9d-b488-dd494ae3000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_MODEL_COMPONENT = (\n",
    "    f\"{COMPONENT_CATALOG_FOLDER}/model-building/upload-model/component.yaml\"\n",
    ")\n",
    "\n",
    "upload_model_comp = kfp.components.load_component_from_file(UPLOAD_MODEL_COMPONENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8784575-c885-48dc-a78f-2805964f08a8",
   "metadata": {},
   "source": [
    "## Deploy Model Component\n",
    "\n",
    "Deploys the model to a NVIDIA Triton inference service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "343e326d-27bd-4e56-9d86-a136e8030c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOY_MODEL_COMPONENT = f\"{os.getenv('HOME')}/kubeflow-ppc64le-examples/deploy_triton_inference_service_component/deploy_triton_inference_service_component.yaml\"\n",
    "deploy_model_comp = kfp.components.load_component_from_file(DEPLOY_MODEL_COMPONENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50e359-defd-469d-a22b-61bfb1d7ce69",
   "metadata": {},
   "source": [
    "## Pipeline Definition\n",
    "\n",
    "This defines the pipeline, and the pipeline's paramters. We'll compile this pipeline into a YAML file that we can upload, and access through the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e73b5831-97e9-44d2-87b5-d79679df21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKBOARD_RESOURCE_NAME = \"ml-blackboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bded8ffe-e62c-4b52-9d04-2f765ed6fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"bee-yolov5\")\n",
    "def bee_yolov5(\n",
    "    data_vol_pvc_name: str,\n",
    "    data_vol_subpath: str,\n",
    "    epochs: int = 750,\n",
    "    model_config_url: str = \"https://github.com/ultralytics/yolov5/raw/v7.0/models/yolov5s.yaml\",\n",
    "    initial_weights_url: str = \"https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt\",\n",
    "    quantize_onnx: str = \"int8\",\n",
    "    minio_url=\"minio-service.kubeflow:9000\",\n",
    "    model_version: int = 1,\n",
    "    dataset_size: str = \"4Gi\",\n",
    "    artifact_vol_pvc_name: str = \"\",\n",
    "    artifact_vol_subpath: str = \"\",\n",
    "):\n",
    "    def mount_volume(task, pvc_name, mount_path, volume_subpath, read_only=False):\n",
    "        task.add_volume(\n",
    "            V1Volume(\n",
    "                name=pvc_name,\n",
    "                persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(pvc_name),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        task.add_volume_mount(\n",
    "            V1VolumeMount(\n",
    "                name=pvc_name,\n",
    "                mount_path=mount_path,\n",
    "                sub_path=volume_subpath,\n",
    "                read_only=read_only,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    create_blackboard = dsl.VolumeOp(\n",
    "        name=\"Create Artefacts Blackboard\",\n",
    "        resource_name=BLACKBOARD_RESOURCE_NAME,\n",
    "        modes=dsl.VOLUME_MODE_RWO,\n",
    "        size=\"4Gi\",\n",
    "        set_owner_reference=True,\n",
    "    )\n",
    "\n",
    "    DATASET_VOLUME_NAME = \"dataset-pvc\"\n",
    "    # Pipeline automatically adds {{workflow.name} prefix when creating\n",
    "    # the resource!\n",
    "    DATASET_VOLUME = \"{{workflow.name}}-\" + DATASET_VOLUME_NAME\n",
    "    create_dataset_volume = dsl.VolumeOp(\n",
    "        name=f\"Create PVC for dataset\",\n",
    "        resource_name=DATASET_VOLUME_NAME,\n",
    "        modes=dsl.VOLUME_MODE_RWM,\n",
    "        size=dataset_size,\n",
    "        set_owner_reference=True,\n",
    "    )\n",
    "\n",
    "    # Load config  and data Tasks\n",
    "    model_config_task = load_from_url_comp(model_config_url)\n",
    "    model_config_task.after(create_blackboard)\n",
    "    model_config_task.set_display_name(\"Load model Config\")\n",
    "\n",
    "    initial_weights_task = load_from_url_comp(initial_weights_url)\n",
    "    initial_weights_task.after(create_blackboard)\n",
    "    initial_weights_task.set_display_name(\"Load initial weights\")\n",
    "\n",
    "    copy_dataset_task = copy_data_comp(\"/src-vol\", \"/dest-vol/dataset\")\n",
    "    mount_volume(\n",
    "        copy_dataset_task,\n",
    "        data_vol_pvc_name,\n",
    "        \"/src-vol\",\n",
    "        data_vol_subpath,\n",
    "        read_only=True,\n",
    "    )\n",
    "    mount_volume(copy_dataset_task, DATASET_VOLUME, \"/dest-vol\", \"\")\n",
    "    copy_dataset_task.after(create_dataset_volume)\n",
    "    copy_dataset_task.after(create_blackboard)\n",
    "    copy_dataset_task.set_display_name(\"Copy dataset to Pipeline owed PVC\")\n",
    "\n",
    "    # Train Model\n",
    "    train_model_task = train_model_comp(\n",
    "        model_cfg=model_config_task.outputs[\"dest\"],\n",
    "        initial_weights=initial_weights_task.outputs[\"dest\"],\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    train_model_task.set_gpu_limit(1)\n",
    "    train_model_task.set_memory_limit(\"30G\")\n",
    "    mount_volume(train_model_task, DATASET_VOLUME, \"/dataset\", \"dataset\")\n",
    "    train_model_task.after(copy_dataset_task)\n",
    "\n",
    "    # convert to ONNX\n",
    "    convert_model_to_onnx_task = convert_model_to_onnx_comp(\n",
    "        model=train_model_task.outputs[\"model\"],\n",
    "        model_format=\"pt\",\n",
    "        quantize=quantize_onnx,\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    evaluate_onnx_model_task = evaluate_model_comp(\n",
    "        model=convert_model_to_onnx_task.outputs[\"onnx_model\"],\n",
    "    )\n",
    "    evaluate_onnx_model_task.set_display_name(\"Evaluate ONNX Model\")\n",
    "    mount_volume(evaluate_onnx_model_task, DATASET_VOLUME, \"/dataset\", \"dataset\")\n",
    "\n",
    "    evaluate_pt_model_task = evaluate_model_comp(\n",
    "        model=train_model_task.outputs[\"model\"],\n",
    "        model_format=\"pt\",\n",
    "    )\n",
    "    evaluate_pt_model_task.set_display_name(\"Evaluate Torch Model\")\n",
    "    mount_volume(evaluate_pt_model_task, DATASET_VOLUME, \"/dataset\", \"dataset\")\n",
    "\n",
    "    # Upload ONNX model\n",
    "    upload_model_task = upload_model_comp(\n",
    "        convert_model_to_onnx_task.outputs[\"onnx_model\"],\n",
    "        minio_url=minio_url,\n",
    "        export_bucket=\"{{workflow.namespace}}-bee\",\n",
    "        model_format=\"onnx\",\n",
    "        model_name=\"bee\",\n",
    "        model_version=model_version,\n",
    "    )\n",
    "\n",
    "    # Deploy Inference Service\n",
    "    deploy_model_task = deploy_model_comp(\n",
    "        name=\"bee\",\n",
    "        rm_existing=True,\n",
    "        storage_uri=\"s3://{{workflow.namespace}}-bee/onnx\",\n",
    "        minio_url=minio_url,\n",
    "        predictor_protocol=\"v2\",\n",
    "    )\n",
    "    deploy_model_task.after(upload_model_task)\n",
    "\n",
    "    ##### Write evaluation results\n",
    "    with dsl.Condition(artifact_vol_pvc_name != \"\", name=\"store_onnx_metrics\"):\n",
    "        ## Save ONNX Metrics\n",
    "        write_onnx_artifact_to_path_task = write_artifact_to_path_comp(\n",
    "            evaluate_onnx_model_task.outputs[\"results\"],\n",
    "            \"/mnt/{{workflow.name}}/onnx-metrics\",\n",
    "        )\n",
    "        mount_volume(\n",
    "            write_onnx_artifact_to_path_task,\n",
    "            artifact_vol_pvc_name,\n",
    "            \"/mnt\",\n",
    "            artifact_vol_subpath,\n",
    "        )\n",
    "        write_onnx_artifact_to_path_task.set_display_name(\"Save ONNX metrics (PVC)\")\n",
    "\n",
    "        ## Save Torch Metrics\n",
    "        write_torch_artifact_to_path_task = write_artifact_to_path_comp(\n",
    "            evaluate_pt_model_task.outputs[\"results\"],\n",
    "            \"/mnt/{{workflow.name}}/pt-metrics\",\n",
    "        )\n",
    "        mount_volume(\n",
    "            write_torch_artifact_to_path_task,\n",
    "            artifact_vol_pvc_name,\n",
    "            \"/mnt\",\n",
    "            artifact_vol_subpath,\n",
    "        )\n",
    "        write_torch_artifact_to_path_task.set_display_name(\"Save Torch results (PVC)\")\n",
    "\n",
    "        ## Save Torch Model\n",
    "        write_torch_model_artifact_to_path_task = write_artifact_to_path_comp(\n",
    "            train_model_task.outputs[\"model\"],\n",
    "            \"/mnt/{{workflow.name}}/model.pt\",\n",
    "        )\n",
    "        mount_volume(\n",
    "            write_torch_model_artifact_to_path_task,\n",
    "            artifact_vol_pvc_name,\n",
    "            \"/mnt\",\n",
    "            artifact_vol_subpath,\n",
    "        )\n",
    "        write_torch_model_artifact_to_path_task.set_display_name(\n",
    "            \"Save Torch model (PVC)\"\n",
    "        )\n",
    "\n",
    "        ## Save ONNX Model\n",
    "        write_onnx_model_artifact_to_path_task = write_artifact_to_path_comp(\n",
    "            convert_model_to_onnx_task.outputs[\"onnx_model\"],\n",
    "            \"/mnt/{{workflow.name}}/model.onnx\",\n",
    "        )\n",
    "        mount_volume(\n",
    "            write_onnx_model_artifact_to_path_task,\n",
    "            artifact_vol_pvc_name,\n",
    "            \"/mnt\",\n",
    "            artifact_vol_subpath,\n",
    "        )\n",
    "        write_onnx_model_artifact_to_path_task.set_display_name(\"Save ONNX model (PVC)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee05810-645a-4f59-8499-55e6dbd1a02c",
   "metadata": {},
   "source": [
    "## Compile Pipeline with configuration options\n",
    "\n",
    "Uses a PVC for passing data between components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e610d564-1c10-4b31-a557-248706deb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://www.kubeflow.org/docs/components/pipelines/overview/caching/#managing-caching-staleness\n",
    "def disable_cache_transformer(op):\n",
    "    if isinstance(op, dsl.ContainerOp):\n",
    "        op.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    else:\n",
    "        op.add_pod_annotation(\n",
    "            name=\"pipelines.kubeflow.org/max_cache_staleness\", value=\"P0D\"\n",
    "        )\n",
    "    return op\n",
    "\n",
    "\n",
    "pipeline_conf = PipelineConf()\n",
    "pipeline_conf.add_op_transformer(disable_cache_transformer)\n",
    "\n",
    "pipeline_conf.data_passing_method = data_passing_methods.KubernetesVolume(\n",
    "    volume=V1Volume(\n",
    "        name=BLACKBOARD_RESOURCE_NAME,\n",
    "        persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(\n",
    "            \"{{workflow.name}}-\" + BLACKBOARD_RESOURCE_NAME\n",
    "        ),\n",
    "    ),\n",
    "    path_prefix=f\"{BLACKBOARD_RESOURCE_NAME}/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2156e60-c033-4e1c-bde1-23d1a85fded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"Bee detector pipeline\"\n",
    "\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=bee_yolov5,\n",
    "    package_path=f\"{PIPELINE_NAME}.yaml\",\n",
    "    pipeline_conf=pipeline_conf,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881cd7d6-cbfc-4631-a196-7086dd530452",
   "metadata": {},
   "source": [
    "## Upload pipeline programmatically\n",
    "\n",
    "The YAML file generated by the previous compile can be used to create a pipeline through the UI.\n",
    "* Download the file to your workstation\n",
    "* Click \"Pipelines\" from the side bar\n",
    "* Press the \"upload pipeline\" button, and upload the YAML.\n",
    "\n",
    "After adding the pipline, you can run the pipeline from the UI without looking at the pipeline code. This allows an inexperienced user to run the pipeline with specific parameters, without the compelxity of Kubeflow componet code or K8S Awareness.\n",
    "\n",
    "These next few cells upload and run the pipeline programmatically, so that the example is \"automated\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3bf9f3c5-9a0c-4389-a802-c3a22ff40731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pipeline(pipeline_name: str):\n",
    "    \"\"\"Delete's a pipeline with the specified name\"\"\"\n",
    "\n",
    "    client = kfp.Client()\n",
    "    existing_pipelines = client.list_pipelines(page_size=999).pipelines\n",
    "    matches = (\n",
    "        [ep.id for ep in existing_pipelines if ep.name == pipeline_name]\n",
    "        if existing_pipelines\n",
    "        else []\n",
    "    )\n",
    "    for id in matches:\n",
    "        client.delete_pipeline(id)\n",
    "\n",
    "\n",
    "def get_experiment_id(experiment_name: str) -> str:\n",
    "    \"\"\"Returns the id for the experiment, creating the experiment if needed\"\"\"\n",
    "    client = kfp.Client()\n",
    "    existing_experiments = client.list_experiments(page_size=999).experiments\n",
    "    matches = (\n",
    "        [ex.id for ex in existing_experiments if ex.name == experiment_name]\n",
    "        if existing_experiments\n",
    "        else []\n",
    "    )\n",
    "\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "\n",
    "    exp = client.create_experiment(experiment_name)\n",
    "    return exp.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ddf37a64-9df0-4b00-a4ee-5b28a6c765d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline names need to be unique, so before we upload,\n",
    "# check for and delete any pipeline with the same name\n",
    "delete_pipeline(PIPELINE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e372f25-244e-4e31-96a3-9021d89b4412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=/pipeline/#/pipelines/details/87a8104b-0cc2-4600-b356-3e86c21e462f>Pipeline details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# upload the pipeline\n",
    "client = kfp.Client()\n",
    "uploaded_pipeline = client.upload_pipeline(f\"{PIPELINE_NAME}.yaml\", PIPELINE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3864f8d0-83d0-4fbc-ad77-78260c7e86e0",
   "metadata": {},
   "source": [
    "## Run the pipeline with parameters\n",
    "\n",
    "This is equivalent to running the pipeline from the pipelines view in the UI. Since a pipeline run needs to be part of an experiment, this code will create the experiment if it does not exist.\n",
    "\n",
    "When we run this manually, we'll use initial weights that have been trained on a much larger superset of this data, and with many more epochs. That will give us results that can be demoed with a fast training cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5f4733f-90fc-4dd3-842e-d37e5b9710d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/3e08c31b-2f28-4b6e-8e12-012280e53450\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_params = {\n",
    "    \"data_vol_pvc_name\": VOLUME_CLAIM_NAME,\n",
    "    \"data_vol_subpath\": \"bee_dataset\",\n",
    "    \"initial_weights_url\": \"https://github.com/ntl-ibm/kubeflow-ppc64le-examples/raw/main/object-detection-yolov5/data/model.onnx\",\n",
    "    \"epochs\": \"15\",\n",
    "    \"artifact_vol_pvc_name\": VOLUME_CLAIM_NAME,\n",
    "    \"artifact_vol_subpath\": \"runs\",\n",
    "}\n",
    "\n",
    "run = client.run_pipeline(\n",
    "    experiment_id=get_experiment_id(\"bee-exp\"),\n",
    "    job_name=\"bees\",\n",
    "    pipeline_id=uploaded_pipeline.id,\n",
    "    params=pipeline_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04249b8-0f60-44aa-a1b1-75749acee2ea",
   "metadata": {},
   "source": [
    "## Waits for the pipeline to complete \n",
    "\n",
    "* waits for up to 20 Min\n",
    "* Checks the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a774585c-f882-44ab-afc2-7e885fece3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWENTY_MIN = 20 * 60\n",
    "result = client.wait_for_run_completion(run.id, timeout=TWENTY_MIN)\n",
    "{\n",
    "    \"status\": result.run.status,\n",
    "    \"error\": result.run.error,\n",
    "    \"time\": str(result.run.finished_at - result.run.created_at),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f2e097-3f09-4def-ac34-a0c56cd3401c",
   "metadata": {},
   "source": [
    "## Inference Example\n",
    "\n",
    "Since the pipeline deploys an inference service, you will see the inference service in the 'Models' list. \n",
    "\n",
    "The URL for the service can used for the weights. The detect tool knows how to talk to NVIDIA triton infrence servers, and the model has already been deployed to this service by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fadb0d2-c85e-4c86-bce5-21509765aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE = f\"{BEE_DATA_SET_PATH}/test/images/2016-03-15-04-09-38-1024x673_jpg.rf.aa352f3bd2a105dd7ff560e0ab42ae69.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec10bc8-d2b6-4864-8c4d-cd9022946436",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/jovyan/yolov5/detect.py --weights=http://bee.kubeflow-ntl.svc.cluster.local/v2/models/bee/infer --data=$BEE_DATA_SET_PATH/data.yaml --source=$IMAGE --conf-thres=.7 --iou-thres=.2 --max-det=500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea2ab2-7592-4ecf-93a2-ddee5f193b95",
   "metadata": {},
   "source": [
    "Because we have an ONNX model in our repo that was trained over many epocs, we can use that model, instead of the InferenceService\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3318ac4-ec13-4c9a-9c9c-02c81b911611",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/jovyan/vol-1/yolov5/detect.py --weights=/home/jovyan/kubeflow-ppc64le-examples/object-detection-yolov5/data/model.onnx --data=/home/jovyan/vol-1/bee_data/data.yaml --source=$IMAGE --conf-thres=.7 --iou-thres=.2 --max-det=500"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
