{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0eebbdcc-5ac4-43be-90a0-2bc1a73538e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141507e7-ea34-4cc9-acd5-2fd7a324166c",
   "metadata": {},
   "source": [
    "# Katib Experiment using the UI\n",
    "\n",
    "This tutorial shows how to run an experiment using Kubeflow's Katib UI. The example finds the best hyperparameters for a MNIST model implemented in PyTorch.\n",
    "\n",
    "A Katib Experiment runs trials in parallel; each trial is a run of the training algorithm with a specific set of hyperparameters.\n",
    "\n",
    "In practice, each trial (training run) could be distributed across multiple GPUs and there could also be multiple trials running in parallel. In this example trials do not distribute the training across GPUS. However, multiple trials run in parallel. This is a simple way to use multiple GPUs within the experiment, with needing distributed training for each trial.\n",
    "\n",
    "We will place our training data and training script on a shared PVC so that it can be shared across trials running in parallel.\n",
    "\n",
    "The example shows how to interact with the UI and does NOT make use of Kubeflow pipelines. (The Katib SDK does enable pipeline integration, which may be covered in other examples).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e7284-78c5-417e-bf27-f5f03fde6fbe",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "The notebook needs a data volume to load the training data and script to. The volume needs to be mounted read-write-many.\n",
    "\n",
    "You will have to recreate the notebook server and mount a volume if this volume is not already mounted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "742b4fc7-1cfe-4596-8728-251958bf0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOLUME_NAME = \"my-notebook-datavol-1\"\n",
    "VOLUME_MOUNT_POINT = \"/home/jovyan/my-notebook-datavol-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0d27a-5ade-4b3a-9f93-637ea3789b66",
   "metadata": {},
   "source": [
    "# Download training data & Copy Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e4e8920-b24a-40ad-9f90-412c5843dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "_ = MNIST(VOLUME_MOUNT_POINT, download=True, train=True)\n",
    "_ = MNIST(VOLUME_MOUNT_POINT, download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ee6d681d-9413-41b1-83f9-528b18e52cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../../distributed_training/pytorch/mnist/mnist.py $VOLUME_MOUNT_POINT/mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c3352-4ea5-4fbe-8b53-feec877b8a90",
   "metadata": {},
   "source": [
    "# Define a trial\n",
    "\n",
    "The first step of any experiment is to define a trial that will take the parameters that need to be optimized. We'll create a template for Kubernetes Job that runs the training in PyTorch. The job will define a pod that mounts the storage that contains the training data and script. The Pod will invoke the python script in its command.\n",
    "\n",
    "Several parameters to the script are defined to reference Katib search parameters. Katib will replace these with values provided by the suggestion during the experiment.\n",
    "\n",
    "Take care that any data written to common storage (/workspace) does not conflict with other trails running in parallel. Our program uses '/tmp' as the root directory, and disables checkpointing to avoid conficts.\n",
    "\n",
    "The python SDK is used here to create the Job definition, although it is also common to create a YAML declaration for the Job as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b57a8760-e8a3-48ff-9fab-bf2f0722c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client, config\n",
    "from kubernetes.client import (\n",
    "    V1ObjectMeta,\n",
    "    V1ConfigMap,\n",
    "    V1Job,\n",
    "    V1JobSpec,\n",
    "    V1PodTemplateSpec,\n",
    "    V1PodSpec,\n",
    "    V1Container,\n",
    "    V1Volume,\n",
    "    V1VolumeMount,\n",
    "    V1PersistentVolumeClaimVolumeSource,\n",
    "    V1EmptyDirVolumeSource,\n",
    "    V1ResourceRequirements,\n",
    ")\n",
    "\n",
    "job = V1Job(\n",
    "    api_version=\"batch/v1\",\n",
    "    kind=\"Job\",\n",
    "    spec=V1JobSpec(\n",
    "        template=V1PodTemplateSpec(\n",
    "            metadata=V1ObjectMeta(\n",
    "                # https://github.com/kubeflow/website/issues/2011\n",
    "                annotations={\"sidecar.istio.io/inject\": \"false\"},\n",
    "            ),\n",
    "            spec=V1PodSpec(\n",
    "                restart_policy=\"Never\",\n",
    "                containers=[\n",
    "                    V1Container(\n",
    "                        name=\"pytorch\",\n",
    "                        image=\"quay.io/ntlawrence/mnist-dist-pytorch:1.0.4\",\n",
    "                        command=[\n",
    "                            \"python\",\n",
    "                            \"/workspace/mnist.py\",\n",
    "                            \"--root_dir=/tmp/workspace\",\n",
    "                            \"--data_dir=/workspace\",\n",
    "                            \"--model=/tmp/mnist_model.pt\",\n",
    "                            \"--batch_size=672\",\n",
    "                            \"--max_epochs=${trialParameters.epochs}\",\n",
    "                            \"--lr=${trialParameters.lr}\",\n",
    "                            \"--no-checkpoint\",\n",
    "                            \"--metric_log_file=/var/log/katib/metrics.log\",\n",
    "                        ],\n",
    "                        resources=V1ResourceRequirements(limits={\"nvidia.com/gpu\": 1}),\n",
    "                        volume_mounts=[\n",
    "                            V1VolumeMount(mount_path=\"/workspace\", name=\"workspace\"),\n",
    "                            V1VolumeMount(mount_path=\"/dev/shm\", name=\"dshm\"),\n",
    "                        ],\n",
    "                    )\n",
    "                ],\n",
    "                volumes=[\n",
    "                    V1Volume(\n",
    "                        name=\"workspace\",\n",
    "                        persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(\n",
    "                            claim_name=VOLUME_NAME\n",
    "                        ),\n",
    "                    ),\n",
    "                    V1Volume(\n",
    "                        name=\"dshm\", empty_dir=V1EmptyDirVolumeSource(medium=\"Memory\")\n",
    "                    ),\n",
    "                ],\n",
    "            ),\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa332f4-999f-4de9-b243-77075abe68f4",
   "metadata": {},
   "source": [
    "## Convert to YAML\n",
    "\n",
    "The python code in the previous cell is a progammatic way of creating the declaration for the job. This next cell shows what the description looks like in YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16aa21ad-90a6-4354-807c-ce46a8a45a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: batch/v1\n",
      "kind: Job\n",
      "spec:\n",
      "  template:\n",
      "    metadata:\n",
      "      annotations:\n",
      "        sidecar.istio.io/inject: 'false'\n",
      "    spec:\n",
      "      containers:\n",
      "      - command:\n",
      "        - python\n",
      "        - /workspace/mnist.py\n",
      "        - --root_dir=/tmp/workspace\n",
      "        - --data_dir=/workspace\n",
      "        - --model=/tmp/mnist_model.pt\n",
      "        - --batch_size=672\n",
      "        - --max_epochs=${trialParameters.epochs}\n",
      "        - --lr=${trialParameters.lr}\n",
      "        - --no-checkpoint\n",
      "        - --metric_log_file=/tmp/hyper_log.json\n",
      "        image: quay.io/ntlawrence/mnist-dist-pytorch:1.0.4\n",
      "        name: pytorch\n",
      "        resources:\n",
      "          limits:\n",
      "            nvidia.com/gpu: 1\n",
      "        volumeMounts:\n",
      "        - mountPath: /workspace\n",
      "          name: workspace\n",
      "        - mountPath: /dev/shm\n",
      "          name: dshm\n",
      "      restartPolicy: Never\n",
      "      volumes:\n",
      "      - name: workspace\n",
      "        persistentVolumeClaim:\n",
      "          claimName: my-notebook-datavol-1\n",
      "      - emptyDir:\n",
      "          medium: Memory\n",
      "        name: dshm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ruamel.yaml import YAML\n",
    "from ruamel.yaml.compat import StringIO\n",
    "yaml=YAML()\n",
    "s = StringIO()\n",
    "client_api = client.ApiClient()\n",
    "yaml.dump(client_api.sanitize_for_serialization(job), s)\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a02f9-4336-4899-b58f-435544b20202",
   "metadata": {},
   "source": [
    "# Create a configmap with the template\n",
    "It is possible to directly copy the yaml from the previous cell when creating the Katib experiment.\n",
    "\n",
    "If many experiments will be created using the same trial template, the template's YAML can be saved in a configmap and referenced in each experiment.\n",
    "\n",
    "This next cell creates a config map with the trial template as the value for pytorch-mnist-job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a298213a-cf95-4b6a-8a3e-d5c770d5be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_config_map = client.V1ConfigMap(\n",
    "    metadata=V1ObjectMeta(\n",
    "     name=\"katib-example-trial-defs\",\n",
    "     labels={\"katib.kubeflow.org/component\": \"trial-templates\"}\n",
    "    ),\n",
    "    data={\"pytorch-mnist-job\" : s.getvalue()}\n",
    ")\n",
    "\n",
    "with open(\"/var/run/secrets/kubernetes.io/serviceaccount/namespace\", \"r\") as f:\n",
    "    NAMESPACE = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ecf76708-c336-4926-9d18-e53c130b2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.load_incluster_config()\n",
    "k8s_api = client.CoreV1Api()\n",
    "#rsp = k8s_api.delete_namespaced_config_map(namespace=NAMESPACE, name=\"katib-example-trial-defs\")\n",
    "rsp = k8s_api.create_namespaced_config_map(namespace=NAMESPACE, body=trials_config_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f454002-d21b-45ed-9011-1c029bc85b88",
   "metadata": {},
   "source": [
    "# Create Experiment\n",
    "\n",
    "Now that the trial has been defined, we are ready to use Katib to optimize the hyperparameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccea53d-7889-49a0-b4b2-209a8cd6513b",
   "metadata": {},
   "source": [
    "Navigate to the Experiments (AutoML) panel and Click the new Experiment Button\n",
    "\n",
    "<img src=\"./images/Katib_AutoML.jpeg\" alt=\"Create Experiment Button\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28a8d4-757f-43fc-944b-fdfb7382dd45",
   "metadata": {},
   "source": [
    "Give the experiment a name such as 'my-experiment'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9731753-33fd-4f68-9164-b58f324c82c8",
   "metadata": {},
   "source": [
    "The trial thresholds controls the maximum number of trials that can run in parallel and the maximum number of trials that will be explored. For this experiment, leave these at the default values.\n",
    "\n",
    "<img src=\"./images/Trial_Thresholds.jpeg\" alt=\"Set Thresholds\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6594d-2dc9-4335-9529-6a2533025d9d",
   "metadata": {},
   "source": [
    "The objective controls what metric should be used to measure the result of the hyperparameters.\n",
    "\n",
    "For this tutorial, we want to maximize the f1 score. In practice, we could set a goal value such that the experiment would end if a set of parameters was found that met or exceeded the goal. We'll set this to a very high .999 so that the experiment runs to completion.\n",
    "\n",
    "Add the additional metric of acc. This means that accuracy will be tracked and reported in the experiment. (But the experiment will not try to maximize accuracy).\n",
    "\n",
    "<img src=\"./images/Trial_Objective.jpeg\" alt=\"Objective Function\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78358cd-80aa-4f19-89fe-e6232ccea22a",
   "metadata": {},
   "source": [
    "Use Basesian Optimization as a search algorithm.\n",
    "\n",
    "In the algorithm settings, the \"Random State\" should be set to a value. This makes the experiment more repeatable. This example used 42.\n",
    "\n",
    "<img src=\"./images/Search_Alg.jpeg\" alt=\"Search Algorithm\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b66d9ca-25a3-4076-889c-7ca4e882d578",
   "metadata": {},
   "source": [
    "For this tutorial, leave the Early Stopping as \"None\".\n",
    "\n",
    "<img src=\"./images/Early_Stop.jpeg\" alt=\"Early Stopping\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a9f73-5488-4e73-880d-3204135e489c",
   "metadata": {},
   "source": [
    "Set the search space of the hyper parameters. This tells Katib the space of values that it should consider for each suggestion.\n",
    "This example optimizes two hyperparameters, lr and epochs.\n",
    "* Use the existing values for lr\n",
    "* Delete the other parameters\n",
    "* Add an epochs parameter, type int with a range of 5 to 25 and step 5\n",
    "\n",
    "<img src=\"./images/Hyper_Parameters.jpeg\" alt=\"Hyper Parameters\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ab751e-a6f4-4595-bad6-adf0a673d945",
   "metadata": {},
   "source": [
    "The python script is designed to write metrics to a file. We'll use a File metrics collector, with the default file name.\n",
    "\n",
    "<img src=\"./images/Metrics_Collector.jpeg\" alt=\"Metrics Collector\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e20563a-9208-4ac9-912b-7c13d6217a36",
   "metadata": {},
   "source": [
    "Fill in the trial template. Because we saved the Job description in a config map, we can reference that here.\n",
    "\n",
    "The primary container name should be set to 'pytorch', since this is the name of the container our training code runs under.\n",
    "The Yaml for the Job is filled in automatically after you change the configMap name and namespace to the config map created in this script.\n",
    "\n",
    "<img src=\"./images/Trial_Template_1.jpeg\" alt=\"Trial Template\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b9a66b",
   "metadata": {},
   "source": [
    "Fill in the reference variables under the template. This is how variables in the template are matched to the parameters from the search space.\n",
    "\n",
    "<img src=\"./images/Trial_Template_2.jpeg\" alt=\"Trial Template references\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fed1ae",
   "metadata": {},
   "source": [
    "Press Create to create the experiment and start it running.\n",
    "\n",
    "The running experiment will appear in the experiment's list.\n",
    "\n",
    "<img src=\"./images/Running_Experiment.jpeg\" alt=\"Experiment\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd9eaf",
   "metadata": {},
   "source": [
    "The best parameters are shown in the overview of the experiment.\n",
    "\n",
    "<img src=\"./images/Best_Trial.jpeg\" alt=\"Optimal Hyperparameters\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc473783",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
