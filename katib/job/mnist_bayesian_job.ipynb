{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141507e7-ea34-4cc9-acd5-2fd7a324166c",
   "metadata": {},
   "source": [
    "# Katib Experiment using the UI\n",
    "\n",
    "This tutorial shows how to run an experiment using Kubeflow's Katib UI. The example finds the best hyperparameters for a MNIST model implemented in PyTorch.\n",
    "\n",
    "A Katib Experiment runs trials in parallel; each trial is a run of the training algorithm with a specific set of hyperparameters.\n",
    "\n",
    "In practice, each trial (training run) could use multiple GPUs and there could be multiple trials running in parallel. This example trains a MNIST model with a single GPU, but with multiple trials running in parallel. This is a simple way to use multiple GPUs with the experiment, with needing distributed training for each trial.\n",
    "\n",
    "We will place our training data and training script on a shared PVC so that it can be shared across trials running in parallel.\n",
    "\n",
    "The example does NOT make use of Kubeflow pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e7284-78c5-417e-bf27-f5f03fde6fbe",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "The notebook needs a data volume to load the training data and model file to. The volume needs to be mounted read-write-many.\n",
    "\n",
    "You will have to recreate the notebook server and mount a volume if this volume is not already mounted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "742b4fc7-1cfe-4596-8728-251958bf0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOLUME_NAME = 'my-notebook-datavol-1'\n",
    "VOLUME_MOUNT_POINT = '/home/jovyan/my-notebook-datavol-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0d27a-5ade-4b3a-9f93-637ea3789b66",
   "metadata": {},
   "source": [
    "# Download training data & Copy Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e4e8920-b24a-40ad-9f90-412c5843dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "_ = MNIST(VOLUME_MOUNT_POINT, download=True, train=True)\n",
    "_ = MNIST(VOLUME_MOUNT_POINT, download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee6d681d-9413-41b1-83f9-528b18e52cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../../distributed_training/pytorch/mnist/mnist.py $VOLUME_MOUNT_POINT/mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f454002-d21b-45ed-9011-1c029bc85b88",
   "metadata": {},
   "source": [
    "# Create Experiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccea53d-7889-49a0-b4b2-209a8cd6513b",
   "metadata": {},
   "source": [
    "Navigate to the Experiments (AutoML) panel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28a8d4-757f-43fc-944b-fdfb7382dd45",
   "metadata": {},
   "source": [
    "Click new experiment, name the experiment bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9731753-33fd-4f68-9164-b58f324c82c8",
   "metadata": {},
   "source": [
    "The trial thresholds controls the maximum number of trials that can run in parallel and the maximum number of trials that will be explored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6594d-2dc9-4335-9529-6a2533025d9d",
   "metadata": {},
   "source": [
    "The objective controls what metric should be used to measure the result of the hyperparameters.\n",
    "\n",
    "For this tutorial, we want to maximize the f1 score. In practice, we could set a goal value such that the experiment would end if a set of parameters was found that met or exceeded the goal. We'll set this to a very high .999 so that the experiment runs to completion.\n",
    "\n",
    "Add the additional metric of acc. This means that accuracy will be tracked and reported in the experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78358cd-80aa-4f19-89fe-e6232ccea22a",
   "metadata": {},
   "source": [
    "Use Basesian Optimization as a search algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b66d9ca-25a3-4076-889c-7ca4e882d578",
   "metadata": {},
   "source": [
    "This tutorial does not use Early Stopping, but for some projects stopping early may be important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a9f73-5488-4e73-880d-3204135e489c",
   "metadata": {},
   "source": [
    "Set the search space of the hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ab751e-a6f4-4595-bad6-adf0a673d945",
   "metadata": {},
   "source": [
    "The python script is designed to write metrics to a json file. We'll use a File metrics collector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a02f9-4336-4899-b58f-435544b20202",
   "metadata": {},
   "source": [
    "The trial template defines how each trial should be launched.\n",
    "\n",
    "We'll launch each trial as a Job. A Job is a little less powerful than a PyTorchJob, which support distributed training for PyTorch. However we already have parallelism by running trials in parallel, and a Job is a bit simpler to use with Katib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b57a8760-e8a3-48ff-9fab-bf2f0722c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client, config\n",
    "from kubernetes.client import (V1ObjectMeta, \n",
    "                              V1ConfigMap, \n",
    "                              V1Job, \n",
    "                              V1JobSpec, \n",
    "                              V1PodTemplateSpec, \n",
    "                              V1PodSpec, \n",
    "                              V1Container, \n",
    "                              V1Volume, \n",
    "                              V1VolumeMount,\n",
    "                              V1PersistentVolumeClaimVolumeSource,\n",
    "                              V1EmptyDirVolumeSource,\n",
    "                              V1ResourceRequirements)\n",
    "\n",
    "job = V1Job(\n",
    "    api_version=\"batch/v1\",\n",
    "    kind=\"Job\",\n",
    "    spec=V1JobSpec(\n",
    "    template=V1PodTemplateSpec(\n",
    "     spec=V1PodSpec(\n",
    "         restart_policy=\"Never\",\n",
    "         containers=[\n",
    "             V1Container(\n",
    "                 name=\"pytorch\",\n",
    "                 image=\"quay.io/ntlawrence/mnist-dist-pytorch:1.0.4\",\n",
    "                 command=[\n",
    "                            \"python\",\n",
    "                            \"/workspace/mnist.py\",\n",
    "                            \"--root_dir=/tmp/workspace\",\n",
    "                            \"--data_dir=/workspace\",\n",
    "                            \"--model=/tmp/mnist_model.pt\",\n",
    "                            \"--batch_size=672\",\n",
    "                            \"--max_epochs=${trialParameters.epochs}\",\n",
    "                            \"--lr=${trialParameters.lr}\",\n",
    "                            \"--no-checkpoint\",\n",
    "                            \"--metric_log_file=/tmp/hyper_log.json\"\n",
    "                        ],\n",
    "                 resources=V1ResourceRequirements(limits={\"nvidia.com/gpu\": 1}),\n",
    "                 volume_mounts=[\n",
    "                     V1VolumeMount(mount_path=\"/workspace\", name=\"workspace\"),\n",
    "                     V1VolumeMount(mount_path=\"/dev/shm\", name=\"dshm\")\n",
    "                 ]\n",
    "             )\n",
    "         ],\n",
    "         volumes=[V1Volume(\n",
    "                        name=\"workspace\",\n",
    "                        persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(claim_name=VOLUME_NAME)\n",
    "                  ),\n",
    "                  V1Volume(name=\"dshm\", \n",
    "                           empty_dir=V1EmptyDirVolumeSource(medium=\"Memory\")\n",
    "                           ),\n",
    "                 ]\n",
    "     )\n",
    "    )\n",
    "   )\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16aa21ad-90a6-4354-807c-ce46a8a45a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: batch/v1\n",
      "kind: Job\n",
      "spec:\n",
      "  template:\n",
      "    spec:\n",
      "      containers:\n",
      "      - command:\n",
      "        - python\n",
      "        - /workspace/mnist.py\n",
      "        - --root_dir=/tmp/workspace\n",
      "        - --data_dir=/workspace\n",
      "        - --model=/tmp/mnist_model.pt\n",
      "        - --batch_size=672\n",
      "        - --max_epochs=${trialParameters.epochs}\n",
      "        - --lr=${trialParameters.lr}\n",
      "        - --no-checkpoint\n",
      "        - --metric_log_file=/tmp/hyper_log.json\n",
      "        image: quay.io/ntlawrence/mnist-dist-pytorch:1.0.4\n",
      "        name: pytorch\n",
      "        resources:\n",
      "          limits:\n",
      "            nvidia.com/gpu: 1\n",
      "        volumeMounts:\n",
      "        - mountPath: /workspace\n",
      "          name: workspace\n",
      "        - mountPath: /dev/shm\n",
      "          name: dshm\n",
      "      restartPolicy: Never\n",
      "      volumes:\n",
      "      - name: workspace\n",
      "        persistentVolumeClaim:\n",
      "          claimName: my-notebook-datavol-1\n",
      "      - emptyDir:\n",
      "          medium: Memory\n",
      "        name: dshm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ruamel.yaml import YAML\n",
    "from ruamel.yaml.compat import StringIO\n",
    "yaml=YAML()\n",
    "s = StringIO()\n",
    "client_api = client.ApiClient()\n",
    "yaml.dump(client_api.sanitize_for_serialization(job), s)\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a298213a-cf95-4b6a-8a3e-d5c770d5be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_config_map = client.V1ConfigMap(\n",
    "    metadata=V1ObjectMeta(\n",
    "     name=\"katib-trial-defs\",\n",
    "     labels={\"katib.kubeflow.org/component\": \"trial-templates\"}\n",
    "    ),\n",
    "    data={\"pytorch-mnist-job\" : s.getvalue()}\n",
    ")\n",
    "\n",
    "with open(\"/var/run/secrets/kubernetes.io/serviceaccount/namespace\", \"r\") as f:\n",
    "    NAMESPACE = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ecf76708-c336-4926-9d18-e53c130b2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.load_incluster_config()\n",
    "k8s_api = client.CoreV1Api()\n",
    "rsp = k8s_api.delete_namespaced_config_map(namespace=NAMESPACE, name=\"katib-trial-defs\")\n",
    "rsp = k8s_api.create_namespaced_config_map(namespace=NAMESPACE, body=trials_config_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285343ef-24f8-47cd-8568-e7a3b01d67d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e1c426-310a-43b3-9de6-9889e85e53e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
