{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72d66b-7e23-44c5-8fa3-e93d23f2088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "694bbf2f-551d-435a-90c9-e810c64971a3",
   "metadata": {},
   "source": [
    "# Honey Bee Computer Vision Example\n",
    "\n",
    "This example shows how to use python scripts from open-source repos to train a yolov5 model, and evaluate the results.\n",
    "\n",
    "The example trains a model to detect Honey Bees using the V7 version of the https://github.com/ultralytics/yolov5. The purpose of the example is to explain how to train a model using Kubeflow, the YOLOV5 repo and sample data. \n",
    "\n",
    "Accessed classes are:\n",
    "* Bees (workers or foragers)\n",
    "* Bees carrying pollen\n",
    "* Drones\n",
    "* Queens\n",
    "\n",
    "\n",
    "Datasets for training of object detection models are usually large, and take a long time to train. They often contain many pre-augmented images. For our purposes, we've included a sample of training data to use for this exercise. The poor quantity and quality of the training data will not produce a good model, but it will train quickly, and allow for experimentation with the pipeline.\n",
    "\n",
    "For fun, we also included the weights from a model using a much larger version of this dataset with 500+ epochs (This takes many hours to train).\n",
    "\n",
    "The dataset was sampled from here: https://universe.roboflow.com/matt-nudi/honey-bee-detection-model-zgjnb (creative commons license, but requires an account/email to download).\n",
    "\n",
    "## Author\n",
    "\n",
    "Nick Lawrence ntl@us.ibm.com\n",
    "\n",
    "## License\n",
    "Apache-2.0 License\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b4d10f2-c775-4816-a57e-5297c1c23d8a",
   "metadata": {},
   "source": [
    "The assumption is that this notebook has a data volume mounted (you can set this up when you create the notebook). The PVC should have been created with an access mode of ReadWriteMany. \n",
    "This allows other pods to mount the volume.\n",
    "\n",
    "Also assumed is that the notebook is running with a base image that has the yolov5 packages installed. You can see how the image was created by looking at the file in kubeflow-ppc64le-examples/object-detection-yolov5/Notebook Container Image Source/DockerFile.\n",
    "\n",
    "The data set will be extracted to the data volume in these next few cells. The data will be loaded into the pipeline via a volume, rather than a download. This simulates a use case where the training data has been pre loaded on a volume in the kubernetes cluster, and is large enough where a download is expensive.\n",
    "\n",
    "The volume name is defined in this next cell, as is the path to the extracted Roboflow data set for the bees. To keep things simple, the mount point is the same for both the notebook server, and also for the containers that mount the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b76914e-c3d1-496e-8a52-764eab5cd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOLUME_CLAIM_NAME = \"yolov5-work\"\n",
    "MOUNT_POINT = \"/home/jovyan/vol-1\"\n",
    "BEE_DATA_SET_SUBPATH = \"bee_dataset\"\n",
    "BEE_DATA_SET_PATH = f\"{MOUNT_POINT}/{BEE_DATA_SET_SUBPATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f8c147-ef4d-4cad-9613-f52395b14fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {BEE_DATA_SET_PATH}\n",
    "!tar -xf data/dataset.tar.gz -C {BEE_DATA_SET_PATH} --strip-components 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e41eb3a-7842-401b-ab07-79c2816c79b3",
   "metadata": {},
   "source": [
    "## Copy YOLOV5 files to (notebook) persistent storage\n",
    "The base image has cloned the yolov5 repo into the root directory tree. (`/yolov5`). \n",
    "\n",
    "When the yolov5 scripts are executed from within the notebook, they will produce output in the same directory tree.\n",
    "\n",
    "The root directory is part of the containers R/W layer. That means that changes there are _NOT_ persisted. The root directory is also not accessible from the navigation bar of our notebook server.\n",
    "\n",
    "We'll copy the yolov5 files into our home directory, and that way we can run commands interactively and examine results with the file browser. Because the home directory has been mounted to a volume, the changes there will not be lost if the notebook server is shutdown.\n",
    "\n",
    "This copy is for interactive work in the notebook, the pipeline does not use this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8229a-1d48-4ad6-ac60-1e74571755af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -d /home/jovyan/yolov5 ] \n",
    "then \n",
    "   cp -R /yolov5 /home/jovyan/yolov5 \n",
    "else \n",
    "   echo \"The directory is already copied\"\n",
    "fi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdf03b6e-d8cd-4900-896d-353f332a27c7",
   "metadata": {},
   "source": [
    "## Imports and constants\n",
    "\n",
    "If you've build your own yolov5 container, you should change the BASE_IMAGE variable to your own image here. The Dockerfile for the image is included in the \"Notebook Container Image Source\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555cbe3-c15a-4361-aa42-153fa814e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import InputPath, OutputPath\n",
    "from kubernetes.client.models import (\n",
    "    V1Volume,\n",
    "    V1VolumeMount,\n",
    "    V1PersistentVolumeClaimVolumeSource,\n",
    "    V1EmptyDirVolumeSource,\n",
    ")\n",
    "from kfp.dsl import PipelineConf, data_passing_methods\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "BASE_IMAGE = \"quay.io/ntlawrence/yolov5:pt1.12.1-yolov7.0-v2.0\"\n",
    "COMPONENT_CATALOG_FOLDER = f\"{os.getenv('HOME')}/components\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68f6c0e3-98ed-462c-8746-3adc4ecdf930",
   "metadata": {},
   "source": [
    "## Load Data component\n",
    "The first component in the pipeline copies the data from an input path to an output parameter.\n",
    "\n",
    "Essentially this moves the data from the volume into the pipeline. A common problem when using PVCs is that paths to data in a PVC (strings), are not interchangable with pipeline inputs and outputs (InputPath and OutputPath). Components like this are needed to transform data on a PVC into something that can be used by existing pipeline components that expect InputPath and OutputPath params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800195c-1c9c-4a92-8106-d884a0975288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_url(\n",
    "    source: str,\n",
    "    dest: OutputPath(str),\n",
    "):\n",
    "    import os\n",
    "    import shutil\n",
    "    from urllib.request import urlretrieve\n",
    "    from urllib.parse import urlparse\n",
    "\n",
    "    # Make target directories if needed\n",
    "    parent_dirs = os.path.dirname(dest)\n",
    "    if not os.path.exists(parent_dirs):\n",
    "        os.makedirs(parent_dirs)\n",
    "\n",
    "    # Option to use an empty file to indicate no weights\n",
    "    if not source:\n",
    "        with open(dest, \"w\") as _:\n",
    "            pass\n",
    "\n",
    "    source_details = urlparse(source)\n",
    "\n",
    "    if source_details.scheme == \"file\":\n",
    "        if os.path.isdir(source_details.path):\n",
    "            shutil.copytree(source_details.path, dest)\n",
    "        else:\n",
    "            shutil.copyfile(source_details.path, dest)\n",
    "    elif source_details.scheme in (\"http\", \"https\", \"ftp\", \"ftps\"):\n",
    "        urlretrieve(source, filename=dest)\n",
    "    else:\n",
    "        raise ValueError(f\"source does not use a supported url scheme\")\n",
    "\n",
    "\n",
    "load_from_url_comp = kfp.components.create_component_from_func(\n",
    "    load_from_url, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91dbcc2e-66d8-466e-8535-a29d25c1e30c",
   "metadata": {},
   "source": [
    "## Copy data from one path to another\n",
    "This component is a helper to move data from one volume path to another.\n",
    "\n",
    "This component allows us to copy pipeline artifacts to a mounted PVC for use outside of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9fcda6-5f27-40dd-86da-f964b87852a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(source: str, dest: str):\n",
    "    import os\n",
    "    import shutil\n",
    "\n",
    "    # Make target directories if needed\n",
    "    parent_dirs = os.path.basename(dest)\n",
    "    if not os.path.exists(parent_dirs):\n",
    "        os.makedirs(parent_dirs)\n",
    "\n",
    "    if os.path.isdir(source):\n",
    "        shutil.copytree(source, dest)\n",
    "    else:\n",
    "        shutil.copyfile(source, dest)\n",
    "\n",
    "\n",
    "copy_data_comp = kfp.components.create_component_from_func(\n",
    "    copy_data, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea3ec2ab-9d32-44af-b126-57afbe8e9c39",
   "metadata": {},
   "source": [
    "## Train Model component\n",
    "\n",
    "Run the python train.py CLI to train the model\n",
    "\n",
    "This version uses multi-node GPU.\n",
    "\n",
    "Integration with tensorboard is also an area that might be investigated and included in the future.\n",
    "\n",
    "The trained model and results.csv are reported as output parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323c8c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_distributed(\n",
    "    model: OutputPath(str),\n",
    "    results: OutputPath(str),\n",
    "    model_cfg_path: InputPath(str),\n",
    "    initial_weights_path: InputPath(str),\n",
    "    epochs: int,\n",
    "    gpus: int,\n",
    "    training_pvc_name: str,\n",
    "    training_pvc_mount: str,\n",
    "    dataset_pvc_name: str,\n",
    "    dataset_subpath: str = \"\",\n",
    "    img: int = 640,\n",
    "    batch_size: int = 96,\n",
    "    timeout: int = 60 * 60 * 8,\n",
    "    yolov5_base_image: str = \"quay.io/ntlawrence/yolov5:pt1.12.1-yolov7.0-v2.0\",\n",
    "    replicas: int = 3,\n",
    "):\n",
    "    import os\n",
    "    import subprocess\n",
    "    import shutil\n",
    "\n",
    "    # Install kubeflow-training, hack/fix other dependents\n",
    "    subprocess.run(\"pip uninstall -y kfp\", shell=True)\n",
    "    subprocess.run(\"pip install kubernetes==26.1.0\", shell=True, check=True)\n",
    "    subprocess.run(\"pip install kubeflow-training==1.6.0\", shell=True, check=True)\n",
    "\n",
    "    from kubernetes.client import (\n",
    "        V1PodTemplateSpec,\n",
    "        V1ObjectMeta,\n",
    "        V1PodSpec,\n",
    "        V1Container,\n",
    "        V1EnvVar,\n",
    "        V1ResourceRequirements,\n",
    "        V1VolumeMount,\n",
    "        V1Volume,\n",
    "        V1PersistentVolumeClaimVolumeSource,\n",
    "        V1EmptyDirVolumeSource,\n",
    "        V1OwnerReference,\n",
    "    )\n",
    "\n",
    "    from kubeflow.training import (\n",
    "        V1ReplicaSpec,\n",
    "        KubeflowOrgV1PyTorchJob,\n",
    "        KubeflowOrgV1PyTorchJobSpec,\n",
    "        KubeflowOrgV1ElasticPolicy,\n",
    "        V1RunPolicy,\n",
    "        TrainingClient,\n",
    "    )\n",
    "\n",
    "    from kubeflow.training.constants import constants\n",
    "    from kubernetes import client, config, watch\n",
    "\n",
    "    def copyf(source: str, dest: str(str)):\n",
    "        \"\"\"\n",
    "        Copies a file or directory,\n",
    "        creating destination parent dirs as needed\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import shutil\n",
    "\n",
    "        parent_dirs = os.path.dirname(dest)\n",
    "        os.makedirs(parent_dirs, exist_ok=True)\n",
    "\n",
    "        if os.path.isdir(source):\n",
    "            shutil.copytree(source, dest)\n",
    "        else:\n",
    "            shutil.copyfile(source, dest)\n",
    "\n",
    "    def wait_for_pod_ready(name: str, namespace: str = \"{{workflow.namespace}}\"):\n",
    "        \"\"\"Waits for a Pod to become ready.\n",
    "        At that point all containers have been started\n",
    "        \"\"\"\n",
    "        config.load_incluster_config()\n",
    "        w = watch.Watch()\n",
    "        core_v1 = client.CoreV1Api()\n",
    "\n",
    "        # Watching a specific pod is done with a field selector on the name.\n",
    "        # https://github.com/kubernetes-client/python/issues/467\n",
    "        for event in w.stream(\n",
    "            func=core_v1.list_namespaced_pod,\n",
    "            namespace=namespace,\n",
    "            field_selector=f\"metadata.name={name}\",\n",
    "            timeout_seconds=120,\n",
    "        ):\n",
    "            # Phases: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase\n",
    "            if event[\"object\"].status.phase not in {\"Pending\"}:\n",
    "                w.stop()\n",
    "                return\n",
    "            # event.type: ADDED, MODIFIED, DELETED\n",
    "            if event[\"type\"] == \"DELETED\":\n",
    "                print(f\" {name} deleted before it started\")\n",
    "                w.stop()\n",
    "                return\n",
    "\n",
    "    # The \"training pvc is used to share data between the torch jobs and this component\n",
    "    # We need to copy the config and initial weights to it\n",
    "    copyf(model_cfg_path, f\"{training_pvc_mount}/input/config.yaml\")\n",
    "    copyf(initial_weights_path, f\"{training_pvc_mount}/input/weights.pt\")\n",
    "\n",
    "    # Create a directory to store the output of training, we'll\n",
    "    # copy data from here to output paths\n",
    "    os.makedirs(f\"{training_pvc_mount}/output\", exist_ok=True)\n",
    "\n",
    "    ###########################################\n",
    "    # PyTorchJob template for the training job\n",
    "    ###########################################\n",
    "\n",
    "    # Define GPU device list and job name\n",
    "    devices = \",\".join([str(d) for d in range(gpus)])\n",
    "    job_name = \"{{workflow.name}}-training\"\n",
    "\n",
    "    # An owner reference for the workflow\n",
    "    # When the workflow is deleted, the torch job is\n",
    "    # garbage collected.\n",
    "    workflow_ownership = V1OwnerReference(\n",
    "        api_version=\"v1\",\n",
    "        kind=\"Workflow\",\n",
    "        name=\"{{workflow.name}}\",\n",
    "        uid=\"{{workflow.uid}}\",\n",
    "    )\n",
    "\n",
    "    # Pod definition for each worker replica\n",
    "    # Defines the container image, command, and volume mounts\n",
    "    # yolov5 handles the distributed training for us, but\n",
    "    # there is an example of how to write your own\n",
    "    # training code here: https://github.com/kubeflow/training-operator/blob/master/examples/pytorch/elastic/imagenet/\n",
    "    pod_template = V1PodTemplateSpec(\n",
    "        metadata=V1ObjectMeta(\n",
    "            name=job_name,\n",
    "            namespace=\"{{workflow.namespace}}\",\n",
    "            owner_references=[workflow_ownership],\n",
    "            annotations={\"sidecar.istio.io/inject\": \"false\"},\n",
    "        ),\n",
    "        spec=V1PodSpec(\n",
    "            containers=[\n",
    "                V1Container(\n",
    "                    name=constants.PYTORCHJOB_CONTAINER,\n",
    "                    image=yolov5_base_image,\n",
    "                    image_pull_policy=\"IfNotPresent\",\n",
    "                    working_dir=\"/yolov5\",\n",
    "                    command=[\n",
    "                        \"python\",\n",
    "                        \"-m\",\n",
    "                        \"torch.distributed.run\",\n",
    "                        \"--nproc_per_node=1\",\n",
    "                        \"train.py\",\n",
    "                        f\"--device={devices}\",\n",
    "                        \"--img=640\",\n",
    "                        \"--batch-size=96\",\n",
    "                        \"--noplots\",\n",
    "                        f\"--epochs={epochs}\",\n",
    "                        \"--weights=/input/weights.pt\",\n",
    "                        \"--cache=/home/jovyan/cache\",\n",
    "                        \"--cfg=/input/config.yaml\",\n",
    "                        \"--data=/dataset/data.yaml\",\n",
    "                        \"--optimizer=Adam\",\n",
    "                    ],\n",
    "                    env=[\n",
    "                        V1EnvVar(name=\"LOGLEVEL\", value=\"DEBUG\"),\n",
    "                        V1EnvVar(name=\"NCCL_DEBUG\", value=\"INFO\"),\n",
    "                    ],\n",
    "                    # Allocate GPUs to each pod\n",
    "                    resources=V1ResourceRequirements(\n",
    "                        limits={\"nvidia.com/gpu\": f\"{gpus}\"}\n",
    "                    ),\n",
    "                    volume_mounts=[\n",
    "                        # Mount the input files directory from the training pvc\n",
    "                        V1VolumeMount(\n",
    "                            mount_path=\"/input\", name=\"training\", sub_path=\"input\"\n",
    "                        ),\n",
    "                        # This mounts the output directory of the training pvc\n",
    "                        # to a path where yolov5 stores the model and results.\n",
    "                        # And then we can copy those files back into kubeflow,\n",
    "                        # Because this component has that directory accessible\n",
    "                        # to it.\n",
    "                        V1VolumeMount(\n",
    "                            mount_path=\"/yolov5/runs/\",\n",
    "                            name=\"training\",\n",
    "                            sub_path=\"output\",\n",
    "                        ),\n",
    "                        # PyTorch requires shared memory on each pod\n",
    "                        V1VolumeMount(mount_path=\"/dev/shm\", name=\"dshm\"),\n",
    "                        # Mount the dataset pvc\n",
    "                        V1VolumeMount(\n",
    "                            mount_path=\"/dataset\",\n",
    "                            sub_path=dataset_subpath,\n",
    "                            name=\"dataset\",\n",
    "                        ),\n",
    "                    ],\n",
    "                )\n",
    "            ],\n",
    "            volumes=[\n",
    "                V1Volume(\n",
    "                    name=\"training\",\n",
    "                    persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(\n",
    "                        claim_name=training_pvc_name\n",
    "                    ),\n",
    "                ),\n",
    "                V1Volume(\n",
    "                    name=\"dataset\",\n",
    "                    persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(\n",
    "                        claim_name=dataset_pvc_name\n",
    "                    ),\n",
    "                ),\n",
    "                V1Volume(\n",
    "                    name=\"dshm\", empty_dir=V1EmptyDirVolumeSource(medium=\"Memory\")\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # The PyTorchJob supports the concept of a master replica, but not\n",
    "    # specified the first worker takes that role. Having only workers\n",
    "    # simplifies the template a bit. This is how the imagenet example is\n",
    "    # setup. https://github.com/kubeflow/training-operator/blob/master/examples/pytorch/elastic/imagenet/\n",
    "    worker_spec = V1ReplicaSpec(\n",
    "        replicas=replicas, restart_policy=\"Never\", template=pod_template\n",
    "    )\n",
    "\n",
    "    # The owner references and replica spec are used to define the torch job\n",
    "    pytorchjob = KubeflowOrgV1PyTorchJob(\n",
    "        api_version=f\"{constants.KUBEFLOW_GROUP}/{constants.OPERATOR_VERSION}\",\n",
    "        kind=constants.PYTORCHJOB_KIND,\n",
    "        metadata=V1ObjectMeta(name=job_name, owner_references=[workflow_ownership]),\n",
    "        spec=KubeflowOrgV1PyTorchJobSpec(\n",
    "            # c10d is the most commonly used because it doesn't require additional\n",
    "            # packages. The primary advantage that elastic solutions offer is the\n",
    "            # ability to use cheap hardware in the cloud that can be taken away\n",
    "            # at any time. That doesn't apply so much for Power servers that are\n",
    "            # running on on-premise. Here we default to a fixed size of the\n",
    "            # number of replicias.\n",
    "            elastic_policy=KubeflowOrgV1ElasticPolicy(rdzv_backend=\"c10d\"),\n",
    "            run_policy=V1RunPolicy(clean_pod_policy=\"None\"),\n",
    "            pytorch_replica_specs={\"Worker\": worker_spec},\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    ##########################\n",
    "    # Submit training job\n",
    "    ##########################\n",
    "    training_client = TrainingClient()\n",
    "    training_client.create_pytorchjob(pytorchjob)\n",
    "\n",
    "    try:\n",
    "        training_client.wait_for_job_conditions(\n",
    "            job_name,\n",
    "            expected_conditions={\n",
    "                constants.JOB_CONDITION_RUNNING,\n",
    "                constants.JOB_CONDITION_SUCCEEDED,\n",
    "                constants.JOB_CONDITION_FAILED,\n",
    "            },\n",
    "            job_kind=constants.PYTORCHJOB_KIND,\n",
    "            timeout=120,\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        # https://github.com/kubeflow/training-operator/issues/1806#issue-1708084586\n",
    "        pass\n",
    "\n",
    "    # Wait for pods to be ready, must do this before reading logs\n",
    "    pod_names = training_client.get_job_pod_names(name=job_name, is_master=None)\n",
    "    for pod in pod_names:\n",
    "        wait_for_pod_ready(pod)\n",
    "\n",
    "    # stream logs for all workers\n",
    "    # (most of the interesting stuff is in worker 0)\n",
    "    training_client.get_job_logs(\n",
    "        name=job_name,\n",
    "        is_master=False,\n",
    "        container=constants.PYTORCHJOB_CONTAINER,\n",
    "        follow=True,\n",
    "    )\n",
    "\n",
    "    # No more logs means workers have finished, wait for the rest of the job\n",
    "    try:\n",
    "        training_client.wait_for_job_conditions(\n",
    "            job_name,\n",
    "            expected_conditions={\n",
    "                constants.JOB_CONDITION_SUCCEEDED,\n",
    "                constants.JOB_CONDITION_FAILED,\n",
    "            },\n",
    "            timeout=timeout,\n",
    "            job_kind=constants.PYTORCHJOB_KIND,\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        # https://github.com/kubeflow/training-operator/issues/1806#issue-1708084586\n",
    "        pass\n",
    "\n",
    "    if training_client.is_job_failed(name=job_name, job_kind=constants.PYTORCHJOB_KIND):\n",
    "        raise RuntimeError(f\"Job {job_name} Failed!\")\n",
    "\n",
    "    ########################################################\n",
    "    # Copy trained model and results to output parameters\n",
    "    ########################################################\n",
    "    os.makedirs(os.path.dirname(model), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(results), exist_ok=True)\n",
    "    shutil.copyfile(f\"/{training_pvc_mount}/output/train/exp/weights/best.pt\", model)\n",
    "    shutil.copyfile(f\"/{training_pvc_mount}/output/train/exp/results.csv\", results)\n",
    "\n",
    "\n",
    "train_model_comp = kfp.components.create_component_from_func(\n",
    "    train_model_distributed,\n",
    "    base_image=BASE_IMAGE,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfff5ee1-b5ad-402b-a70d-9ec970fc59e0",
   "metadata": {},
   "source": [
    "## Component to convert the model to ONNX\n",
    "\n",
    "The export tool supports quantizing, the model, and so we've added that option as a parameter to the component. The ability to quantize is important for models that will be used for inferencing on edge devices. Many edge devices do not have the resources to evaluate deep neural networks, and and smaller model makes it possible to run inferencing in those environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87865918-1782-4392-9c6a-e14dd9c833b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_model_to_onnx(\n",
    "    model: InputPath(str),\n",
    "    model_format: str,\n",
    "    onnx_model: OutputPath(str),\n",
    "    quantize: str = \"\",\n",
    "):\n",
    "    import subprocess\n",
    "    import shutil\n",
    "    import os\n",
    "\n",
    "    # export.py uses the file name to determine the type of model\n",
    "    # mode is an input path where the name is generated by kubeflow\n",
    "    # We need to control the name that is used...\n",
    "    named_model = f\"/tmp/{os.path.basename(model)}.{model_format}\"\n",
    "    os.symlink(model, named_model)\n",
    "\n",
    "    quantize_param = f\"--{quantize}\" if quantize else \"\"\n",
    "\n",
    "    # https://github.com/ultralytics/yolov5/issues/10831\n",
    "    subprocess.run(\n",
    "        f\"python export.py --img 640 --include=onnx  {quantize_param} \"\n",
    "        f\"--data /dataset/data.yaml --weights {named_model} --device=cpu --opset 12\",\n",
    "        check=True,\n",
    "        cwd=\"/yolov5\",\n",
    "        shell=True,\n",
    "    )\n",
    "\n",
    "    shutil.copyfile(f\"/tmp/{os.path.basename(model)}.onnx\", onnx_model)\n",
    "\n",
    "\n",
    "convert_model_to_onnx_comp = kfp.components.create_component_from_func(\n",
    "    convert_model_to_onnx, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "939ae4ac-d364-49b7-ba74-5b6898b801b8",
   "metadata": {},
   "source": [
    "## Model evaluation component\n",
    "\n",
    "This component can be used for both the original and onnx models. This allows comparisons between the ONNX model (which might be quantized), and the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3693a4de-9443-49a0-9222-466ce0996ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    results: OutputPath(str),\n",
    "    model: InputPath(str),\n",
    "    model_format: str = \"onnx\",  # onnx, pt, tf ....\n",
    "    conf_thres: float = 0.001,\n",
    "    iou_thres: float = 0.6,\n",
    "    max_det: int = 300,\n",
    "):\n",
    "    import subprocess\n",
    "    import os\n",
    "    import torch\n",
    "    from ruamel.yaml import YAML\n",
    "    import pathlib\n",
    "    import shutil\n",
    "\n",
    "    print(f\"The size of the model is {os.path.getsize(model)}\")\n",
    "\n",
    "    if model_format == \"onnx\" and not torch.cuda.is_available():\n",
    "        # the base image is built with an onnxruntime for GPU\n",
    "        # This should work for both CPU and GPU, but val.py\n",
    "        # does it's own checking for CPU onnxruntime only\n",
    "        # Since that's not installed and not on pypl for ppc64le,\n",
    "        # The script won't work unless we change up the version\n",
    "        subprocess.run(\n",
    "            \"mamba install -c rocketce onnxruntime=1.13.1=hea80eff_cpu_py39_pb3.19_1 -y\",\n",
    "            check=True,\n",
    "            shell=True,\n",
    "        )\n",
    "\n",
    "    # valy.py uses the file name to determine the type of model\n",
    "    # mode is an input path where the name is generated by kubeflow\n",
    "    # We need to control the name that is used...\n",
    "    named_model = f\"/tmp/{os.path.basename(model)}.{model_format}\"\n",
    "    os.symlink(model, named_model)\n",
    "\n",
    "    subprocess.run(\n",
    "        f\"python val.py --weights {named_model} --data /dataset/data.yaml --img 640 \"\n",
    "        f\"--conf-thres {conf_thres} --iou-thres {iou_thres} --max-det {max_det} --workers=0 \",\n",
    "        check=True,\n",
    "        shell=True,\n",
    "        cwd=\"/yolov5\",\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(results), exist_ok=True)\n",
    "    shutil.copytree(\"/yolov5/runs/val/exp\", results)\n",
    "\n",
    "\n",
    "evaluate_model_comp = kfp.components.create_component_from_func(\n",
    "    evaluate_model, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0d9d1ff-2a55-4ed3-bf8f-4a03eee3a5db",
   "metadata": {},
   "source": [
    "## Write artifact to PVC\n",
    "\n",
    "Converts data from a pipeline parameter to a file stored on a PVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76cbbb6-e6ac-4670-9abc-65de242a054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_artifact_to_path(source: InputPath(str), dest: str(str)):\n",
    "    import os\n",
    "    import shutil\n",
    "\n",
    "    parent_dirs = os.path.dirname(dest)\n",
    "    os.makedirs(parent_dirs, exist_ok=True)\n",
    "\n",
    "    if os.path.isdir(source):\n",
    "        shutil.copytree(source, dest)\n",
    "    else:\n",
    "        shutil.copyfile(source, dest)\n",
    "\n",
    "\n",
    "write_artifact_to_path_comp = kfp.components.create_component_from_func(\n",
    "    write_artifact_to_path, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "139dd24b-4266-4672-81e8-715de84a23cd",
   "metadata": {},
   "source": [
    "## Upload the ONNX model\n",
    "\n",
    "The upload component is the same component that is shared with other examples. It loads the ONNX model into MinIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e184495-f063-4a9d-b488-dd494ae3000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_MODEL_COMPONENT = (\n",
    "    f\"{COMPONENT_CATALOG_FOLDER}/model-building/upload-model/component.yaml\"\n",
    ")\n",
    "\n",
    "upload_model_comp = kfp.components.load_component_from_file(UPLOAD_MODEL_COMPONENT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8784575-c885-48dc-a78f-2805964f08a8",
   "metadata": {},
   "source": [
    "## Deploy Model Component\n",
    "\n",
    "Deploys the model to a NVIDIA Triton inference service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e326d-27bd-4e56-9d86-a136e8030c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOY_MODEL_COMPONENT = f\"{os.getenv('HOME')}/kubeflow-ppc64le-examples/deploy_triton_inference_service_component/deploy_triton_inference_service_component.yaml\"\n",
    "deploy_model_comp = kfp.components.load_component_from_file(DEPLOY_MODEL_COMPONENT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a50e359-defd-469d-a22b-61bfb1d7ce69",
   "metadata": {},
   "source": [
    "## Pipeline Definition\n",
    "\n",
    "This defines the pipeline, and the pipeline's paramters. We'll compile this pipeline into a YAML file that we can upload, and access through the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b5831-97e9-44d2-87b5-d79679df21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKBOARD_RESOURCE_NAME = \"ml-blackboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7a476-1775-4ff4-8390-2ec445f28ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded8ffe-e62c-4b52-9d04-2f765ed6fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"bee-yolov5\")\n",
    "def bee_yolov5(\n",
    "    data_vol_pvc_name: str,\n",
    "    data_vol_subpath: str,\n",
    "    epochs: int = 750,\n",
    "    model_config_url: str = \"https://github.com/ultralytics/yolov5/raw/v7.0/models/yolov5s.yaml\",\n",
    "    initial_weights_url: str = \"https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt\",\n",
    "    quantize_onnx: str = \"int8\",\n",
    "    minio_url=\"minio-service.kubeflow:9000\",\n",
    "    model_version: int = 1,\n",
    "    dataset_size: str = \"4Gi\",\n",
    "    artifact_vol_pvc_name: str = \"\",\n",
    "    artifact_vol_subpath: str = \"\",\n",
    "):\n",
    "    def mount_volume(task, pvc_name, mount_path, volume_subpath, read_only=False):\n",
    "        task.add_volume(\n",
    "            V1Volume(\n",
    "                name=pvc_name,\n",
    "                persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(pvc_name),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        task.add_volume_mount(\n",
    "            V1VolumeMount(\n",
    "                name=pvc_name,\n",
    "                mount_path=mount_path,\n",
    "                sub_path=volume_subpath,\n",
    "                read_only=read_only,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    create_blackboard = dsl.VolumeOp(\n",
    "        name=\"Create Artefacts Blackboard\",\n",
    "        resource_name=BLACKBOARD_RESOURCE_NAME,\n",
    "        modes=dsl.VOLUME_MODE_RWO,\n",
    "        size=\"4Gi\",\n",
    "        set_owner_reference=True,\n",
    "    )\n",
    "\n",
    "    DATASET_VOLUME_NAME = \"dataset-pvc\"\n",
    "    # Pipeline automatically adds {{workflow.name} prefix when creating\n",
    "    # the resource!\n",
    "    DATASET_VOLUME = \"{{workflow.name}}-\" + DATASET_VOLUME_NAME\n",
    "    create_dataset_volume = dsl.VolumeOp(\n",
    "        name=f\"Create PVC for dataset\",\n",
    "        resource_name=DATASET_VOLUME_NAME,\n",
    "        modes=dsl.VOLUME_MODE_RWM,\n",
    "        size=dataset_size,\n",
    "        set_owner_reference=True,\n",
    "    )\n",
    "\n",
    "    # Load config  and data Tasks\n",
    "    model_config_task = load_from_url_comp(model_config_url)\n",
    "    model_config_task.after(create_blackboard)\n",
    "    model_config_task.set_display_name(\"Load model Config\")\n",
    "\n",
    "    initial_weights_task = load_from_url_comp(initial_weights_url)\n",
    "    initial_weights_task.after(create_blackboard)\n",
    "    initial_weights_task.set_display_name(\"Load initial weights\")\n",
    "\n",
    "    copy_dataset_task = copy_data_comp(\"/src-vol\", \"/dest-vol/dataset\")\n",
    "    mount_volume(\n",
    "        copy_dataset_task,\n",
    "        data_vol_pvc_name,\n",
    "        \"/src-vol\",\n",
    "        data_vol_subpath,\n",
    "        read_only=True,\n",
    "    )\n",
    "    mount_volume(copy_dataset_task, DATASET_VOLUME, \"/dest-vol\", \"\")\n",
    "    copy_dataset_task.after(create_dataset_volume)\n",
    "    copy_dataset_task.after(create_blackboard)\n",
    "    copy_dataset_task.set_display_name(\"Copy dataset to Pipeline owed PVC\")\n",
    "\n",
    "    TRAINING_VOLUME_NAME = \"yolov5-training\"\n",
    "    TRAINING_VOLUME = \"{{workflow.name}}-\" + TRAINING_VOLUME_NAME\n",
    "    create_training_volume = dsl.VolumeOp(\n",
    "        name=f\"Create PVC for training\",\n",
    "        resource_name=TRAINING_VOLUME_NAME,\n",
    "        modes=dsl.VOLUME_MODE_RWM,\n",
    "        size=\"2G\",\n",
    "        set_owner_reference=True,\n",
    "    )\n",
    "\n",
    "    # Train Model\n",
    "    train_model_task = train_model_comp(\n",
    "        model_cfg=model_config_task.outputs[\"dest\"],\n",
    "        initial_weights=initial_weights_task.outputs[\"dest\"],\n",
    "        epochs=epochs,\n",
    "        gpus=1,\n",
    "        training_pvc_name=TRAINING_VOLUME,\n",
    "        training_pvc_mount=\"/training\",\n",
    "        dataset_pvc_name=DATASET_VOLUME,\n",
    "        dataset_subpath=\"dataset\",\n",
    "    )\n",
    "\n",
    "    mount_volume(train_model_task, TRAINING_VOLUME, \"/training\", \"\")\n",
    "    train_model_task.after(copy_dataset_task)\n",
    "    train_model_task.after(create_training_volume)\n",
    "\n",
    "    # convert to ONNX\n",
    "    convert_model_to_onnx_task = convert_model_to_onnx_comp(\n",
    "        model=train_model_task.outputs[\"model\"],\n",
    "        model_format=\"pt\",\n",
    "        quantize=quantize_onnx,\n",
    "    )\n",
    "    mount_volume(convert_model_to_onnx_task, DATASET_VOLUME, \"/dataset\", \"dataset\")\n",
    "\n",
    "    # Evaluate\n",
    "    evaluate_onnx_model_task = evaluate_model_comp(\n",
    "        model=convert_model_to_onnx_task.outputs[\"onnx_model\"],\n",
    "    )\n",
    "    evaluate_onnx_model_task.set_display_name(\"Evaluate ONNX Model\")\n",
    "    mount_volume(evaluate_onnx_model_task, DATASET_VOLUME, \"/dataset\", \"dataset\")\n",
    "\n",
    "    evaluate_pt_model_task = evaluate_model_comp(\n",
    "        model=train_model_task.outputs[\"model\"],\n",
    "        model_format=\"pt\",\n",
    "    )\n",
    "    evaluate_pt_model_task.set_display_name(\"Evaluate Torch Model\")\n",
    "    mount_volume(evaluate_pt_model_task, DATASET_VOLUME, \"/dataset\", \"dataset\")\n",
    "\n",
    "    # Upload ONNX model\n",
    "    upload_model_task = upload_model_comp(\n",
    "        convert_model_to_onnx_task.outputs[\"onnx_model\"],\n",
    "        minio_url=minio_url,\n",
    "        export_bucket=\"{{workflow.namespace}}-bee\",\n",
    "        model_format=\"onnx\",\n",
    "        model_name=\"bee\",\n",
    "        model_version=model_version,\n",
    "    )\n",
    "\n",
    "    # Deploy Inference Service\n",
    "    deploy_model_task = deploy_model_comp(\n",
    "        name=\"bee\",\n",
    "        rm_existing=True,\n",
    "        storage_uri=\"s3://{{workflow.namespace}}-bee/onnx\",\n",
    "        minio_url=minio_url,\n",
    "        predictor_protocol=\"v2\",\n",
    "    )\n",
    "    deploy_model_task.after(upload_model_task)\n",
    "\n",
    "    ##### Write evaluation results\n",
    "    with dsl.Condition(artifact_vol_pvc_name != \"\", name=\"store_onnx_metrics\"):\n",
    "        ## Save ONNX Metrics\n",
    "        write_onnx_artifact_to_path_task = write_artifact_to_path_comp(\n",
    "            evaluate_onnx_model_task.outputs[\"results\"],\n",
    "            \"/mnt/{{workflow.name}}/onnx-metrics\",\n",
    "        )\n",
    "        mount_volume(\n",
    "            write_onnx_artifact_to_path_task,\n",
    "            artifact_vol_pvc_name,\n",
    "            \"/mnt\",\n",
    "            artifact_vol_subpath,\n",
    "        )\n",
    "        write_onnx_artifact_to_path_task.set_display_name(\"Save ONNX metrics (PVC)\")\n",
    "\n",
    "        ## Save Torch Metrics\n",
    "        write_torch_artifact_to_path_task = write_artifact_to_path_comp(\n",
    "            evaluate_pt_model_task.outputs[\"results\"],\n",
    "            \"/mnt/{{workflow.name}}/pt-metrics\",\n",
    "        )\n",
    "        mount_volume(\n",
    "            write_torch_artifact_to_path_task,\n",
    "            artifact_vol_pvc_name,\n",
    "            \"/mnt\",\n",
    "            artifact_vol_subpath,\n",
    "        )\n",
    "        write_torch_artifact_to_path_task.set_display_name(\"Save Torch results (PVC)\")\n",
    "\n",
    "        ## Save Torch Model\n",
    "        write_torch_model_artifact_to_path_task = write_artifact_to_path_comp(\n",
    "            train_model_task.outputs[\"model\"],\n",
    "            \"/mnt/{{workflow.name}}/model.pt\",\n",
    "        )\n",
    "        mount_volume(\n",
    "            write_torch_model_artifact_to_path_task,\n",
    "            artifact_vol_pvc_name,\n",
    "            \"/mnt\",\n",
    "            artifact_vol_subpath,\n",
    "        )\n",
    "        write_torch_model_artifact_to_path_task.set_display_name(\n",
    "            \"Save Torch model (PVC)\"\n",
    "        )\n",
    "\n",
    "        ## Save ONNX Model\n",
    "        write_onnx_model_artifact_to_path_task = write_artifact_to_path_comp(\n",
    "            convert_model_to_onnx_task.outputs[\"onnx_model\"],\n",
    "            \"/mnt/{{workflow.name}}/model.onnx\",\n",
    "        )\n",
    "        mount_volume(\n",
    "            write_onnx_model_artifact_to_path_task,\n",
    "            artifact_vol_pvc_name,\n",
    "            \"/mnt\",\n",
    "            artifact_vol_subpath,\n",
    "        )\n",
    "        write_onnx_model_artifact_to_path_task.set_display_name(\"Save ONNX model (PVC)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ee05810-645a-4f59-8499-55e6dbd1a02c",
   "metadata": {},
   "source": [
    "## Compile Pipeline with configuration options\n",
    "\n",
    "Uses a PVC for passing data between components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e610d564-1c10-4b31-a557-248706deb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://www.kubeflow.org/docs/components/pipelines/overview/caching/#managing-caching-staleness\n",
    "def disable_cache_transformer(op):\n",
    "    if isinstance(op, dsl.ContainerOp):\n",
    "        op.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    else:\n",
    "        op.add_pod_annotation(\n",
    "            name=\"pipelines.kubeflow.org/max_cache_staleness\", value=\"P0D\"\n",
    "        )\n",
    "    return op\n",
    "\n",
    "\n",
    "pipeline_conf = PipelineConf()\n",
    "pipeline_conf.add_op_transformer(disable_cache_transformer)\n",
    "\n",
    "pipeline_conf.data_passing_method = data_passing_methods.KubernetesVolume(\n",
    "    volume=V1Volume(\n",
    "        name=BLACKBOARD_RESOURCE_NAME,\n",
    "        persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(\n",
    "            \"{{workflow.name}}-\" + BLACKBOARD_RESOURCE_NAME\n",
    "        ),\n",
    "    ),\n",
    "    path_prefix=f\"{BLACKBOARD_RESOURCE_NAME}/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2156e60-c033-4e1c-bde1-23d1a85fded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"Bee detector pipeline\"\n",
    "\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=bee_yolov5,\n",
    "    package_path=f\"{PIPELINE_NAME}.yaml\",\n",
    "    pipeline_conf=pipeline_conf,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "881cd7d6-cbfc-4631-a196-7086dd530452",
   "metadata": {},
   "source": [
    "## Upload pipeline programmatically\n",
    "\n",
    "The YAML file generated by the previous compile can be used to create a pipeline through the UI.\n",
    "* Download the file to your workstation\n",
    "* Click \"Pipelines\" from the side bar\n",
    "* Press the \"upload pipeline\" button, and upload the YAML.\n",
    "\n",
    "After adding the pipline, you can run the pipeline from the UI without looking at the pipeline code. This allows an inexperienced user to run the pipeline with specific parameters, without the compelxity of Kubeflow componet code or K8S Awareness.\n",
    "\n",
    "These next few cells upload and run the pipeline programmatically, so that the example is \"automated\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9f3c5-9a0c-4389-a802-c3a22ff40731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pipeline(pipeline_name: str):\n",
    "    \"\"\"Delete's a pipeline with the specified name\"\"\"\n",
    "\n",
    "    client = kfp.Client()\n",
    "    existing_pipelines = client.list_pipelines(page_size=999).pipelines\n",
    "    matches = (\n",
    "        [ep.id for ep in existing_pipelines if ep.name == pipeline_name]\n",
    "        if existing_pipelines\n",
    "        else []\n",
    "    )\n",
    "    for id in matches:\n",
    "        client.delete_pipeline(id)\n",
    "\n",
    "\n",
    "def get_experiment_id(experiment_name: str) -> str:\n",
    "    \"\"\"Returns the id for the experiment, creating the experiment if needed\"\"\"\n",
    "    client = kfp.Client()\n",
    "    existing_experiments = client.list_experiments(page_size=999).experiments\n",
    "    matches = (\n",
    "        [ex.id for ex in existing_experiments if ex.name == experiment_name]\n",
    "        if existing_experiments\n",
    "        else []\n",
    "    )\n",
    "\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "\n",
    "    exp = client.create_experiment(experiment_name)\n",
    "    return exp.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf37a64-9df0-4b00-a4ee-5b28a6c765d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline names need to be unique, so before we upload,\n",
    "# check for and delete any pipeline with the same name\n",
    "delete_pipeline(PIPELINE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e372f25-244e-4e31-96a3-9021d89b4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the pipeline\n",
    "client = kfp.Client()\n",
    "uploaded_pipeline = client.upload_pipeline(f\"{PIPELINE_NAME}.yaml\", PIPELINE_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3864f8d0-83d0-4fbc-ad77-78260c7e86e0",
   "metadata": {},
   "source": [
    "## Run the pipeline with parameters\n",
    "\n",
    "This is equivalent to running the pipeline from the pipelines view in the UI. Since a pipeline run needs to be part of an experiment, this code will create the experiment if it does not exist.\n",
    "\n",
    "When we run this manually, we'll use initial weights that have been trained on a much larger superset of this data, and with many more epochs. That will give us results that can be demoed with a fast training cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4733f-90fc-4dd3-842e-d37e5b9710d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_params = {\n",
    "    \"data_vol_pvc_name\": VOLUME_CLAIM_NAME,\n",
    "    \"data_vol_subpath\": BEE_DATA_SET_SUBPATH,\n",
    "    \"epochs\": \"50\",\n",
    "    \"artifact_vol_pvc_name\": VOLUME_CLAIM_NAME,\n",
    "    \"artifact_vol_subpath\": \"runs\",\n",
    "}\n",
    "\n",
    "run = client.run_pipeline(\n",
    "    experiment_id=get_experiment_id(\"bee-exp\"),\n",
    "    job_name=\"bees\",\n",
    "    pipeline_id=uploaded_pipeline.id,\n",
    "    params=pipeline_params,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b04249b8-0f60-44aa-a1b1-75749acee2ea",
   "metadata": {},
   "source": [
    "## Waits for the pipeline to complete \n",
    "\n",
    "* waits for up to 20 Min\n",
    "* Checks the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a774585c-f882-44ab-afc2-7e885fece3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWENTY_MIN = 20 * 60\n",
    "result = client.wait_for_run_completion(run.id, timeout=TWENTY_MIN)\n",
    "{\n",
    "    \"status\": result.run.status,\n",
    "    \"error\": result.run.error,\n",
    "    \"time\": str(result.run.finished_at - result.run.created_at),\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0f2e097-3f09-4def-ac34-a0c56cd3401c",
   "metadata": {},
   "source": [
    "## Inference Example\n",
    "\n",
    "Since the pipeline deploys an inference service, you will see the inference service in the 'Models' list. \n",
    "\n",
    "The URL for the service can used for the weights. The detect tool knows how to talk to NVIDIA triton infrence servers, and the model has already been deployed to this service by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fadb0d2-c85e-4c86-bce5-21509765aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE = f\"{BEE_DATA_SET_PATH}/test/images/2016-03-15-04-09-38-1024x673_jpg.rf.aa352f3bd2a105dd7ff560e0ab42ae69.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec10bc8-d2b6-4864-8c4d-cd9022946436",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/jovyan/yolov5/detect.py --weights=http://bee.kubeflow-ntl.svc.cluster.local/v2/models/bee/infer --data=$BEE_DATA_SET_PATH/data.yaml --source=$IMAGE --conf-thres=.7 --iou-thres=.2 --max-det=500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6407ee4-e7bb-4328-965d-52d20d218086",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed71b423-b33d-41fd-9c7d-e35bae6b304e",
   "metadata": {},
   "source": [
    "Because we have an ONNX model in our repo that was trained over many epocs, we can use that model, instead of the InferenceService.\n",
    "\n",
    "Because we are running the inference in the notebook, and because the tool expects a specific version of ONNX Runtime, we must install that first.\n",
    "\n",
    "There are actually several ways to solve this problem:\n",
    "\n",
    "* Install onnxruntime in each container that is running onnxruntime on the CPU (The approach taken here)\n",
    "* Change the container image to install the CPU version, and do the install in components that need the GPU version\n",
    "* Update the yolov5 code so that it understands the package versions available in conda/rocketce.\n",
    "\n",
    "The best choice can only be determined by considering a real problem that is being solved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966d87c-e5c3-4919-a551-7ca5327c95c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mamba install -c rocketce onnxruntime=1.13.1=hea80eff_cpu_py39_pb3.19_1 -y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3549f11-c48f-488f-bafd-d3619934577b",
   "metadata": {},
   "source": [
    "Now we can run the inference script in the notebook, against the (better) model that was included in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3318ac4-ec13-4c9a-9c9c-02c81b911611",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/jovyan/yolov5/detect.py --weights=/home/jovyan/kubeflow-ppc64le-examples/object-detection-yolov5/data/model.onnx --data=/home/jovyan/vol-1/bee_data/data.yaml --source=$IMAGE --conf-thres=.7 --iou-thres=.2 --max-det=500"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
