import kserve
from typing import Dict, Union
import os
import numpy as np
from ray import serve
import logging
from tritonclient.grpc.service_pb2 import ModelInferRequest
import onnxruntime as ort
from kserve.protocol import InferRequest, InferResponse, InferOutput

logging.basicConfig()
logging.getLogger().addHandler(logging.StreamHandler())
logging.getLogger().setLevel(logging.INFO)


@serve.deployment(name="credit-risk-transformer", config={"num_replicas": 2})
class CreditRiskPredictor(kserve.Model):
    MODEL_PATH = "/mnt/models/model.onnx"
    RISK_THRESHOLD = int(os.environ["THRESHOLD"])

    def __init__(self, name: str):
        super().__init__(name)
        self.name = name
        self.load()
        self.ready = True

    def load(self):
        self.INFERENCE_SESSION = ort.InferenceSession(
            CreditRiskPredictor.MODEL_PATH, providers=["CPUExecutionProvider"]
        )

    def predict(
        self,
        payload: Union[Dict, InferRequest, ModelInferRequest],
        headers: Dict[str, str] = None,
    ) -> InferResponse:
        if isinstance(payload, ModelInferRequest):
            payload = InferRequest.from_grpc(payload)
        elif isinstance(payload, Dict):
            payload = InferRequest.from_rest(payload)

        scores = self.INFERENCE_SESSION.run([], {"input": payload.inputs[0].contents})
        scores = scores[0].reshape(-1, 1)
        result = np.ndarray(
            [1 if score > CreditRiskPredictor.THRESHOLD else 0 for score in scores],
            dtype=np.uint8,
        )
        output_0 = InferOutput(name="risk", share=result.shape, datatype="UINT8")
        output_0.set_data_from_numpy(result)

        return InferResponse(
            id=payload.id, model_name=self.name, infer_outputs=[output_0]
        )


if __name__ == "__main__":
    kserve.ModelServer().start({"credit-risk-predictor": CreditRiskPredictor})
