{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e0dc445-cfe0-450c-a265-01b624e38af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed409e1c-fd43-48ad-8ae5-238e0c7c65a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe775e26-80e2-4877-a4a7-d7f04f0e01f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibm-db==3.1.2 in /opt/conda/lib/python3.9/site-packages (3.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ibm-db==3.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d5f9c08-0a8f-43b5-8a25-fe1d3e1dda2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import ibm_db\n",
    "import ibm_db_dbi\n",
    "from kubernetes import client, config, utils\n",
    "import yaml\n",
    "from http import HTTPStatus\n",
    "\n",
    "config.load_incluster_config()\n",
    "\n",
    "with open(\"/var/run/secrets/kubernetes.io/serviceaccount/namespace\", \"r\") as f:\n",
    "    NAMESPACE = f.read()\n",
    "\n",
    "core_v1_api = client.CoreV1Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1765c3-0575-47e3-8bd2-c2e2128f1bd3",
   "metadata": {},
   "source": [
    "# Gather dataset column names and levels into configmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da61ba30-66f7-415f-b40f-79781c60c5ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': ['CheckingStatus',\n",
       "  'LoanDuration',\n",
       "  'CreditHistory',\n",
       "  'LoanPurpose',\n",
       "  'LoanAmount',\n",
       "  'ExistingSavings',\n",
       "  'EmploymentDuration',\n",
       "  'InstallmentPercent',\n",
       "  'Sex',\n",
       "  'OthersOnLoan',\n",
       "  'CurrentResidenceDuration',\n",
       "  'OwnsProperty',\n",
       "  'Age',\n",
       "  'InstallmentPlans',\n",
       "  'Housing',\n",
       "  'ExistingCreditsCount',\n",
       "  'Job',\n",
       "  'Dependents',\n",
       "  'Telephone',\n",
       "  'ForeignWorker',\n",
       "  'Risk'],\n",
       " 'label_columns': {'CheckingStatus': ['0_to_200',\n",
       "   'greater_200',\n",
       "   'less_0',\n",
       "   'no_checking'],\n",
       "  'CreditHistory': ['all_credits_paid_back',\n",
       "   'credits_paid_to_date',\n",
       "   'no_credits',\n",
       "   'outstanding_credit',\n",
       "   'prior_payments_delayed'],\n",
       "  'LoanPurpose': ['appliances',\n",
       "   'business',\n",
       "   'car_new',\n",
       "   'car_used',\n",
       "   'education',\n",
       "   'furniture',\n",
       "   'other',\n",
       "   'radio_tv',\n",
       "   'repairs',\n",
       "   'retraining',\n",
       "   'vacation'],\n",
       "  'ExistingSavings': ['100_to_500',\n",
       "   '500_to_1000',\n",
       "   'greater_1000',\n",
       "   'less_100',\n",
       "   'unknown'],\n",
       "  'EmploymentDuration': ['1_to_4',\n",
       "   '4_to_7',\n",
       "   'greater_7',\n",
       "   'less_1',\n",
       "   'unemployed'],\n",
       "  'Sex': ['female', 'male'],\n",
       "  'OthersOnLoan': ['co-applicant', 'guarantor', 'none'],\n",
       "  'OwnsProperty': ['car_other', 'real_estate', 'savings_insurance', 'unknown'],\n",
       "  'InstallmentPlans': ['bank', 'none', 'stores'],\n",
       "  'Housing': ['free', 'own', 'rent'],\n",
       "  'Job': ['management_self-employed', 'skilled', 'unemployed', 'unskilled'],\n",
       "  'Telephone': ['none', 'yes'],\n",
       "  'ForeignWorker': ['no', 'yes'],\n",
       "  'Risk': ['No Risk', 'Risk']},\n",
       " 'int_columns': ['LoanDuration',\n",
       "  'LoanAmount',\n",
       "  'InstallmentPercent',\n",
       "  'CurrentResidenceDuration',\n",
       "  'Age',\n",
       "  'ExistingCreditsCount',\n",
       "  'Dependents']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "df = pd.read_csv(\"./german_credit_data_biased_training.csv\")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == np.dtype(\"O\"):\n",
    "        df[col] = df[col].astype(\"category\")\n",
    "\n",
    "column_map: Dict[str, Any] = {}\n",
    "column_map[\"columns\"] = list(df.columns)\n",
    "\n",
    "column_map[\"label_columns\"] = {\n",
    "    col: list(df[col].dtype.categories)\n",
    "    for col in column_map[\"columns\"]\n",
    "    if type(df[col].dtype) == pd.core.dtypes.dtypes.CategoricalDtype\n",
    "}\n",
    "column_map[\"int_columns\"] = [\n",
    "    col for col in column_map[\"columns\"] if df[col].dtype == np.dtype(\"int64\")\n",
    "]\n",
    "\n",
    "column_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3bb5207-8108-46ef-be8e-77f556625179",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_CONFIG_MAP_NAME = \"credit-risk-columns\"\n",
    "cm = client.V1ConfigMap(\n",
    "    metadata=client.V1ObjectMeta(name=COLUMNS_CONFIG_MAP_NAME, namespace=NAMESPACE),\n",
    "    data={\"columns\": json.dumps(column_map, indent=2)},\n",
    ")\n",
    "\n",
    "try:\n",
    "    core_v1_api.create_namespaced_config_map(namespace=NAMESPACE, body=cm)\n",
    "except client.ApiException as e:\n",
    "    if e.status == HTTPStatus.CONFLICT:\n",
    "        core_v1_api.patch_namespaced_config_map(\n",
    "            namespace=NAMESPACE, name=COLUMNS_CONFIG_MAP_NAME, body=cm\n",
    "        )\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bcfba7-c72d-48f3-a47d-ca032b4130b9",
   "metadata": {},
   "source": [
    "# Split data into test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1113880-4003-4d80-854a-e04eb7a78b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, train_size=0.8, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc73b2f-1067-47dc-9273-28489a581347",
   "metadata": {},
   "source": [
    "# DB2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f41a8e-2d18-45f6-816d-00198442d3f4",
   "metadata": {},
   "source": [
    "## Create Secret with DB2 Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4a3f650-c049-4475-a563-9070b751ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"db2-secret.yaml\", \"r\") as f:\n",
    "    desc = yaml.safe_load(f)\n",
    "    try:\n",
    "        api.create_namespaced_secret(body=desc, namespace=NAMESPACE)\n",
    "    except client.ApiException as e:\n",
    "        if e.status == HTTPStatus.CONFLICT:\n",
    "            api.patch_namespaced_secret(\n",
    "                body=desc, name=desc[\"metadata\"][\"name\"], namespace=NAMESPACE\n",
    "            )\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0c3e034-a2ee-4264-8432-5be62a08c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db2_conn(core_v1_api: client.CoreV1Api) -> ibm_db.IBM_DBConnection:\n",
    "    secret = core_v1_api.read_namespaced_secret(\"db2-credentials\", NAMESPACE)\n",
    "\n",
    "    to_str = lambda b64_data: base64.b64decode(b64_data).decode(\"utf-8\")\n",
    "    host, username, password, port = (\n",
    "        to_str(secret.data[\"host\"]),\n",
    "        to_str(secret.data[\"username\"]),\n",
    "        to_str(secret.data[\"password\"]),\n",
    "        to_str(secret.data[\"port\"]),\n",
    "    )\n",
    "\n",
    "    conn_str = (\n",
    "        \"DRIVER={IBM DB2 ODBC DRIVER};\"\n",
    "        f\"DATABASE=BLUDB;HOSTNAME={host};PORT={port};PROTOCOL=TCPIP;UID={username};Pwd={password};SECURITY=SSL;\"\n",
    "    )\n",
    "\n",
    "    conn = ibm_db.connect(conn_str, \"\", \"\")\n",
    "\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd655d69-79ba-4ea4-816f-6d4d599b0888",
   "metadata": {},
   "source": [
    "## Verify DB2 Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59e30d9b-b7c1-49ff-9689-c8e09173da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import textwrap\n",
    "\n",
    "log = logging.getLogger(\"SETUP\")\n",
    "\n",
    "try:\n",
    "    db2 = get_db2_conn(api)\n",
    "except NameError:\n",
    "    raise\n",
    "except Exception as e:  # no better exception to catch\n",
    "    log.error(e)\n",
    "    log.error(\n",
    "        textwrap.dedent(\n",
    "            \"\"\"\n",
    "           DB2 connection failed! Please check that db2-secret.yaml in this directory contains the correct connection details. \n",
    "           Re-run the script to recreate the secret\n",
    "        \"\"\"\n",
    "        )\n",
    "    )\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed39dd2-ad25-48ce-b27a-ffcd2a339159",
   "metadata": {},
   "source": [
    "## DB2 Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e010d14c-ce7f-458c-9bcb-99e00a3a6d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_exists(table_name: str, conn: ibm_db.IBM_DBConnection) -> Union[dict, bool]:\n",
    "    stmt = ibm_db.prepare(\n",
    "        conn,\n",
    "        \"SELECT * FROM SYSIBM.TABLES WHERE table_name = ? AND \"\n",
    "        \"table_schema = CURRENT_SCHEMA\",\n",
    "    )\n",
    "    _ = ibm_db.execute(stmt, (table_name,))\n",
    "    return ibm_db.fetch_assoc(stmt)\n",
    "\n",
    "\n",
    "def build_check_constraints_sql(\n",
    "    table_name: str, column_info: Dict[str, Any]\n",
    ") -> List[str]:\n",
    "    constraints = []\n",
    "    for label_col, levels in column_info[\"label_columns\"].items():\n",
    "        safe_col_name = '\"' + label_col.replace('\"', \"\") + '\"'\n",
    "        str_levels = [\"'\" + level.replace(\"'\", \"''\") + \"'\" for level in levels]\n",
    "        constraints.append(f\"CHECK ({safe_col_name} IN ({','.join(str_levels)}))\")\n",
    "    return constraints\n",
    "\n",
    "\n",
    "def build_create_table_sql(\n",
    "    name: str, column_info: Dict[str, Any], identity_start: int = 1\n",
    ") -> str:\n",
    "    sql_safe_table_name = '\"' + name.replace('\"', \"\") + '\"'\n",
    "\n",
    "    cols_sql = []\n",
    "    for col in column_info[\"label_columns\"]:\n",
    "        safe_col_name = '\"' + col.replace('\"', \"\") + '\"'\n",
    "        cols_sql.append(f\"{safe_col_name} VARCHAR(32000) NOT NULL\")\n",
    "    for col in column_info[\"int_columns\"]:\n",
    "        safe_col_name = '\"' + col.replace('\"', \"\") + '\"'\n",
    "        cols_sql.append(f\"{safe_col_name} BIGINT NOT NULL\")\n",
    "\n",
    "    return (\n",
    "        f\"CREATE TABLE {sql_safe_table_name} (\"\n",
    "        + f\"CLIENT_ID BIGINT GENERATED BY DEFAULT AS IDENTITY (START WITH {identity_start}),\"\n",
    "        + \", \".join(cols_sql)\n",
    "        + \", \"\n",
    "        + \", \".join(build_check_constraints_sql(name, column_info))\n",
    "        + \")\"\n",
    "    )\n",
    "\n",
    "\n",
    "def df_to_sql(\n",
    "    name: str,\n",
    "    conn: ibm_db.IBM_DBConnection,\n",
    "    df: pd.DataFrame,\n",
    "    columns: Dict[str, Any],\n",
    "    identity_start: int = 1,\n",
    ") -> None:\n",
    "    sql_safe_name = name.replace('\"', \"\")\n",
    "    if table_exists(name, conn):\n",
    "        ibm_db.exec_immediate(conn, f'DROP TABLE \"{sql_safe_name}\"')\n",
    "\n",
    "    sql = build_create_table_sql(sql_safe_name, columns, identity_start)\n",
    "    ibm_db.exec_immediate(conn, sql)\n",
    "\n",
    "    iStmtColsSql = \",\".join([f'\"{col}\"' for col in columns[\"columns\"]])\n",
    "    iValues = \",\".join([\"?\" for _ in range(len(columns[\"columns\"]))])\n",
    "    iSql = f'INSERT INTO \"{sql_safe_name}\" ({iStmtColsSql}) VALUES({iValues})'\n",
    "\n",
    "    stmt = ibm_db.prepare(conn, iSql)\n",
    "    df_values = tuple([tuple(x) for x in df.loc[:, columns[\"columns\"]].values])\n",
    "    ibm_db.execute_many(stmt, df_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fc7f78-82f7-4158-a7ff-9c8af4d646e3",
   "metadata": {},
   "source": [
    "### Create Test and Training tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42d9ce60-5562-4687-ab9f-1d0ed540ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_sql(\"TRAIN\", db2, train, column_map)\n",
    "df_to_sql(\"TEST\", db2, test, column_map, identity_start=len(train) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ddcac-69d6-4dee-b8cd-51f9a97a2e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
