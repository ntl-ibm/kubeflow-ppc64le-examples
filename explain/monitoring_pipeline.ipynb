{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39cca785-1fe7-45ac-b567-7670ca9fd996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.components import InputPath, OutputPath\n",
    "from kfp import dsl\n",
    "from typing import List, Tuple\n",
    "from kfp.dsl import ContainerOp\n",
    "from kubernetes.client.models import V1EnvVar,V1EnvVarSource, V1SecretKeySelector,V1ConfigMapKeySelector\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e721fe88-4ce3-4193-b568-97656c3b0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_IMAGE = \"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6504d5da-ad61-4dfc-a221-43d1657b791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_from_db2(table_name: str,\n",
    "                     data_frame_pkl: OutputPath(str),\n",
    "                     target_column: str = 'Risk',\n",
    "                     predictions_column: str = ''):\n",
    "    import warnings\n",
    "    import ibm_db\n",
    "    import ibm_db_dbi\n",
    "    import os\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    from typing import Dict, Any\n",
    "    \n",
    "    def assign_categories_to_df(df: pd.DataFrame, column_info: Dict[str, any]) -> None:\n",
    "        for col_name, levels in column_info[\"label_columns\"].items():\n",
    "            if col_name in df.columns:\n",
    "                ctype = pd.CategoricalDtype(categories=levels, ordered=False)\n",
    "                df[col_name] = df[col_name].astype(ctype)\n",
    "\n",
    "    def df_from_sql(\n",
    "        name: str,\n",
    "        conn: ibm_db.IBM_DBConnection,\n",
    "        column_info: Dict[str, Any],\n",
    "        target_col: str = 'Risk',\n",
    "        predictions_col: str = ''\n",
    "    ) -> pd.DataFrame:\n",
    "        sql_safe_name = name.replace('\"', \"\")\n",
    "\n",
    "        column_list = column_info[\"columns\"] + ([] if not predictions_col else [predictions_col])\n",
    "        rStmtColsSql = \",\".join([f'\"{col}\"' for col in column_list])\n",
    "        rSql = f'SELECT {rStmtColsSql} FROM \"{sql_safe_name}\"'\n",
    "\n",
    "        read_conn = ibm_db_dbi.Connection(conn)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", message=\"pandas only support SQLAlchemy\")\n",
    "            df = pd.read_sql(rSql, read_conn)\n",
    "\n",
    "        assign_categories_to_df(df, column_info)\n",
    "        if predictions_col:\n",
    "            df[predictions_col] = df[predictions_col].astype(df[target_col].dtype)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    conn_str = (\n",
    "    \"DRIVER={IBM DB2 ODBC DRIVER};\"\n",
    "    f\"DATABASE=BLUDB;HOSTNAME={os.environ['db2_host']};PORT={os.environ['db2_port']};PROTOCOL=TCPIP;UID={os.environ['db2_user']};Pwd={os.environ['db2_pwd']};SECURITY=SSL;\"\n",
    "    )\n",
    "        \n",
    "    conn = ibm_db.connect(conn_str, \"\", \"\")\n",
    "\n",
    "    column_info = json.loads(os.environ[\"COLUMNS\"])\n",
    "    df = df_from_sql(table_name, conn, column_info, target_column, predictions_column)\n",
    "    df.to_pickle(data_frame_pkl)\n",
    "\n",
    "\n",
    "load_df_from_db2_comp = kfp.components.create_component_from_func(\n",
    "    func=load_df_from_db2, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25da8a2e-74dd-4377-9609-6a65e4b6702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evidently_report(reference_df: InputPath(str),\n",
    "                      production_df: InputPath(str),\n",
    "                      mlpipeline_ui_metadata_path: OutputPath(str),\n",
    "                      output_report: OutputPath(str),\n",
    "                      output_json: OutputPath(str),\n",
    "                      target: str = 'Risk',\n",
    "                      report_type: str = 'drift'\n",
    "                     ):\n",
    "    from evidently.metric_preset import (\n",
    "    DataDriftPreset,\n",
    "    TargetDriftPreset,\n",
    "    ClassificationPreset,\n",
    "    )\n",
    "    from evidently.report import Report\n",
    "    from evidently import ColumnMapping\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import json\n",
    "    \n",
    "    reference_dataset = pd.read_pickle(reference_df)\n",
    "    production_dataset = pd.read_pickle(production_df)\n",
    "    column_info = json.loads(os.environ[\"COLUMNS\"])\n",
    "\n",
    "    column_mapping = ColumnMapping()\n",
    "    column_mapping.target = target\n",
    "    column_mapping.task = \"classification\"\n",
    "   \n",
    "\n",
    "    column_mapping.numerical_features = [\n",
    "        c\n",
    "        for c in column_info[\"int_columns\"]\n",
    "        if c != target\n",
    "    ]\n",
    "    column_mapping.categorical_features = [\n",
    "        c\n",
    "        for c in column_info[\"label_columns\"]\n",
    "        if c != target\n",
    "    ]\n",
    "\n",
    "    if report_type.lower() == \"drift\":\n",
    "        report = Report(\n",
    "            metrics=[\n",
    "                DataDriftPreset(),\n",
    "            ]\n",
    "        )\n",
    "    elif report_type.lower() == \"target_drift\":\n",
    "        report = Report(\n",
    "            metrics=[\n",
    "                TargetDriftPreset(),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    report.run(\n",
    "        reference_data=reference_dataset,\n",
    "        current_data=production_dataset,\n",
    "        column_mapping=column_mapping,\n",
    "    )\n",
    "\n",
    "    Path(output_report).parent.mkdir(parents=True, exist_ok=True)\n",
    "    report.save_html(output_report)\n",
    "    html_content = open(output_report, \"r\").read()\n",
    "    metadata = {\n",
    "        \"outputs\": [\n",
    "            {\n",
    "                \"type\": \"web-app\",\n",
    "                \"storage\": \"inline\",\n",
    "                \"source\": html_content,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    with open(mlpipeline_ui_metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "        \n",
    "    with open(output_json, \"w\") as json_f:\n",
    "        json_f.write(report.json())\n",
    "        \n",
    "evidently_report_comp = kfp.components.create_component_from_func(\n",
    "    func=evidently_report, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b91ebc7-0f40-482f-b4d2-0d002fc086dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evidently_classification_report(production_df: InputPath(str),\n",
    "                      mlpipeline_ui_metadata_path: OutputPath(str),\n",
    "                      output_report: OutputPath(str),\n",
    "                      output_json: OutputPath(str),\n",
    "                      target: str = 'Risk',\n",
    "                      predictions: str = 'PredictedRisk',\n",
    "                      pos_class: str = 'Risk'\n",
    "                     ):\n",
    "    from evidently.metric_preset import (\n",
    "    ClassificationPreset,\n",
    "    )\n",
    "    from evidently.report import Report\n",
    "    from evidently import ColumnMapping\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import json\n",
    "\n",
    "    production_dataset = pd.read_pickle(production_df)\n",
    "  \n",
    "    production_dataset.dropna(subset=[target, predictions], inplace=True)\n",
    "    column_info = json.loads(os.environ[\"COLUMNS\"])\n",
    "\n",
    "    column_mapping = ColumnMapping()\n",
    "    #column_mapping.target_names = ['No Risk', 'Risk']\n",
    "    column_mapping.target = 'Risk' #'Actual_Int'\n",
    "    column_mapping.prediction = 'PredictedRisk' #'Predicted_Int'\n",
    "    column_mapping.pos_label = 'Risk'\n",
    "    column_mapping.task = \"classification\"\n",
    "\n",
    "   \n",
    "\n",
    "    column_mapping.numerical_features = [\n",
    "        c\n",
    "        for c in column_info[\"int_columns\"]\n",
    "        if c != target\n",
    "    ]\n",
    "    column_mapping.categorical_features = [\n",
    "        c\n",
    "        for c in column_info[\"label_columns\"]\n",
    "        if c != target\n",
    "    ]\n",
    "  \n",
    "    report = Report(\n",
    "        metrics=[\n",
    "            ClassificationPreset()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    #production_dataset['Actual_Int'] = production_dataset[target].apply(lambda v: 1 if v == pos_class else 0)\n",
    "    #production_dataset['Predicted_Int'] = production_dataset[predictions].apply(lambda v: 1 if v == pos_class else 0)\n",
    "\n",
    "    report.run(\n",
    "        reference_data=None,\n",
    "        current_data=production_dataset,\n",
    "        column_mapping=column_mapping,\n",
    "    )\n",
    "\n",
    "    Path(output_report).parent.mkdir(parents=True, exist_ok=True)\n",
    "    report.save_html(output_report)\n",
    "    html_content = open(output_report, \"r\").read()\n",
    "    metadata = {\n",
    "        \"outputs\": [\n",
    "            {\n",
    "                \"type\": \"web-app\",\n",
    "                \"storage\": \"inline\",\n",
    "                \"source\": html_content,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    with open(mlpipeline_ui_metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "        \n",
    "    with open(output_json, \"w\") as json_f:\n",
    "        json_f.write(report.json())\n",
    "        \n",
    "evidently_classification_report_comp = kfp.components.create_component_from_func(\n",
    "    func=evidently_classification_report, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5da929a4-5137-4704-855d-60cc02b2220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "def check_metrics(classification_report: InputPath(str),\n",
    "                  data_drift_report: InputPath(str),\n",
    "                  target_drift_report: InputPath(str)) -> NamedTuple(\"EvaluationOutput\", [(\"mlpipeline_metrics\", \"Metrics\")]):\n",
    "    import json\n",
    "    from collections import namedtuple\n",
    "\n",
    "    with open(classification_report) as class_f:\n",
    "         classification = json.load(class_f)\n",
    "\n",
    "    ClassificationQualityMetric = next(filter(lambda m: m[\"metric\"] == \"ClassificationQualityMetric\", classification[\"metrics\"]))\n",
    "        \n",
    "    \n",
    "    metrics = {\n",
    "        \"metrics\": [\n",
    "            {\"name\": \"f1\", \"numberValue\": ClassificationQualityMetric[\"result\"][\"current\"][\"f1\"], \"format\": \"RAW\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    out_tuple = namedtuple(\"EvaluationOutput\", [\"mlpipeline_metrics\"])\n",
    "    return out_tuple(json.dumps(metrics))\n",
    "\n",
    "check_metrics_comp = kfp.components.create_component_from_func(\n",
    "    func=check_metrics, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2fe96e3-5cfc-4723-bf2b-514348a2fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes.client import ( V1PersistentVolumeClaimVolumeSource, V1Volume, V1VolumeMount)\n",
    "@dsl.pipeline(\n",
    "    name=\"Monitor Credit Risk AI\",\n",
    "    description=\"An example pipeline that monitors the behavior of the AI model within the application\",\n",
    ")\n",
    "def monitor_credit_model_pipeline():\n",
    "    def env_var_from_secret(env_var_name: str, secret_name: str, secret_key: str) -> V1EnvVar:\n",
    "        return V1EnvVar(name=env_var_name,\n",
    "                                     value_from=V1EnvVarSource(\n",
    "                                         secret_key_ref=V1SecretKeySelector(\n",
    "                                             name=secret_name,\n",
    "                                             key=secret_key\n",
    "                                         )\n",
    "                                     )\n",
    "                                    )\n",
    "    \n",
    "    def add_db2_connection_secrets(pipeline_task) -> None:\n",
    "        pipeline_task.container.add_env_variable(env_var_from_secret(\"db2_host\", \"db2-credentials\", \"host\"))\n",
    "        pipeline_task.container.add_env_variable(env_var_from_secret(\"db2_user\", \"db2-credentials\", \"username\"))\n",
    "        pipeline_task.container.add_env_variable(env_var_from_secret(\"db2_pwd\", \"db2-credentials\", \"password\"))\n",
    "        pipeline_task.container.add_env_variable(env_var_from_secret(\"db2_port\", \"db2-credentials\", \"port\"))\n",
    "\n",
    "    load_reference_data_task = load_df_from_db2_comp(table_name=\"TRAIN\")\n",
    "    load_reference_data_task.set_display_name(\"Load_Reference_Data_From_DB2\")\n",
    "    add_db2_connection_secrets(load_reference_data_task)\n",
    "\n",
    "    load_production_data_task = load_df_from_db2_comp(table_name=\"CLIENT_DATA\", predictions_column='PredictedRisk')\n",
    "    load_production_data_task.set_display_name(\"Load_Production_Data_From_DB2\")\n",
    "    add_db2_connection_secrets(load_production_data_task)\n",
    "\n",
    "    drift_report_task = evidently_report_comp(\n",
    "                            reference_df = load_reference_data_task.outputs[\"data_frame_pkl\"],\n",
    "                            production_df = load_production_data_task.outputs[\"data_frame_pkl\"],\n",
    "                            report_type=\"drift\"\n",
    "    )\n",
    "    drift_report_task.set_display_name(\"Produce Data Drift Report\")\n",
    "\n",
    "    target_drift_report_task = evidently_report_comp(\n",
    "                            reference_df = load_reference_data_task.outputs[\"data_frame_pkl\"],\n",
    "                            production_df = load_production_data_task.outputs[\"data_frame_pkl\"],\n",
    "                            report_type=\"target_drift\"\n",
    "    )\n",
    "    target_drift_report_task.set_display_name(\"Produce Target Drift Report\")\n",
    "    \n",
    "    classification_report_task = evidently_classification_report_comp(\n",
    "                            production_df = load_production_data_task.outputs[\"data_frame_pkl\"],\n",
    "    )\n",
    "    classification_report_task.set_display_name(\"Produce classification Report\")\n",
    "    \n",
    "    \n",
    "    check_metrics_task = check_metrics_comp(\n",
    "              classification_report=classification_report_task.outputs[\"output_json\"],\n",
    "                  data_drift_report=drift_report_task.outputs[\"output_json\"],\n",
    "                  target_drift_report=target_drift_report_task.outputs[\"output_json\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf3eae2e-ec33-46b5-bbbf-4104409212f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pipeline(pipeline_name: str):\n",
    "    \"\"\"Delete's a pipeline with the specified name\"\"\"\n",
    "\n",
    "    client = kfp.Client()\n",
    "    existing_pipelines = client.list_pipelines(page_size=999).pipelines\n",
    "    matches = (\n",
    "        [ep.id for ep in existing_pipelines if ep.name == pipeline_name]\n",
    "        if existing_pipelines\n",
    "        else []\n",
    "    )\n",
    "    for id in matches:\n",
    "        client.delete_pipeline(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3fba760-5a07-428c-8e58-38ffba93fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_id(experiment_name: str) -> str:\n",
    "    \"\"\"Returns the id for the experiment, creating the experiment if needed\"\"\"\n",
    "    client = kfp.Client()\n",
    "    existing_experiments = client.list_experiments(page_size=999).experiments\n",
    "    matches = (\n",
    "        [ex.id for ex in existing_experiments if ex.name == experiment_name]\n",
    "        if existing_experiments\n",
    "        else []\n",
    "    )\n",
    "\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "\n",
    "    exp = client.create_experiment(experiment_name)\n",
    "    return exp.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621931e2-bfa9-42ba-b3b5-0ab466c4b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_conf = kfp.dsl.PipelineConf()\n",
    "\n",
    "def provide_column_info_transformer(op: dsl.ContainerOp):\n",
    "    \n",
    "    if isinstance(op, dsl.ContainerOp):\n",
    "        op.container.add_env_variable(\n",
    "            V1EnvVar(name=\"COLUMNS\",\n",
    "                    value_from=V1EnvVarSource(\n",
    "                                         config_map_key_ref=V1ConfigMapKeySelector(\n",
    "                                             name=\"credit-risk-columns\",\n",
    "                                             key=\"columns\"\n",
    "                                         )\n",
    "                                     )\n",
    "                    )\n",
    "        )\n",
    "                            \n",
    "\n",
    "pipeline_conf.add_op_transformer(provide_column_info_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28f9c95a-8496-4d3f-8509-fe27271b1cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=/pipeline/#/pipelines/details/e7aa99a1-7b71-463c-a4c4-a411b3d09597>Pipeline details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PIPELINE_NAME = \"Monitor_Credit_Risk_AI\"\n",
    "# Pipeline names need to be unique, so before we upload,\n",
    "# check for and delete any pipeline with the same name\n",
    "delete_pipeline(PIPELINE_NAME)\n",
    "\n",
    "        \n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=monitor_credit_model_pipeline,\n",
    "    package_path=f\"{PIPELINE_NAME}.yaml\",\n",
    "    pipeline_conf=pipeline_conf,\n",
    ")\n",
    "\n",
    "# upload\n",
    "client = kfp.Client()\n",
    "uploaded_pipeline = client.upload_pipeline(f\"{PIPELINE_NAME}.yaml\", PIPELINE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "665d4723-bf14-4a7f-bc15-38bc0b712e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': datetime.datetime(2023, 10, 20, 20, 45, 48, tzinfo=tzlocal()),\n",
      " 'default_version': {'code_source_url': None,\n",
      "                     'created_at': datetime.datetime(2023, 10, 20, 20, 45, 48, tzinfo=tzlocal()),\n",
      "                     'description': None,\n",
      "                     'id': 'e7aa99a1-7b71-463c-a4c4-a411b3d09597',\n",
      "                     'name': 'Monitor_Credit_Risk_AI',\n",
      "                     'package_url': None,\n",
      "                     'parameters': None,\n",
      "                     'resource_references': [{'key': {'id': 'e7aa99a1-7b71-463c-a4c4-a411b3d09597',\n",
      "                                                      'type': 'PIPELINE'},\n",
      "                                              'name': None,\n",
      "                                              'relationship': 'OWNER'}]},\n",
      " 'description': None,\n",
      " 'error': None,\n",
      " 'id': 'e7aa99a1-7b71-463c-a4c4-a411b3d09597',\n",
      " 'name': 'Monitor_Credit_Risk_AI',\n",
      " 'parameters': None,\n",
      " 'resource_references': None,\n",
      " 'url': None}\n"
     ]
    }
   ],
   "source": [
    "print(uploaded_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17616f00-8eff-41a0-b6c5-c9204a65155b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/686142bb-a8c0-4b89-b9f0-29d7e8e25508\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'created_at': datetime.datetime(2023, 10, 20, 21, 18, 22, tzinfo=tzlocal()),\n",
       " 'description': 'Tests for data drift and f1 performance',\n",
       " 'enabled': True,\n",
       " 'error': None,\n",
       " 'id': 'ef33c733-422f-4c3d-9bb6-340835a95882',\n",
       " 'max_concurrency': '1',\n",
       " 'mode': None,\n",
       " 'name': 'monitor_credit_risk_api_performance',\n",
       " 'no_catchup': None,\n",
       " 'pipeline_spec': {'parameters': None,\n",
       "                   'pipeline_id': 'e7aa99a1-7b71-463c-a4c4-a411b3d09597',\n",
       "                   'pipeline_manifest': None,\n",
       "                   'pipeline_name': 'Monitor_Credit_Risk_AI',\n",
       "                   'runtime_config': None,\n",
       "                   'workflow_manifest': '{\"kind\":\"Workflow\",\"apiVersion\":\"argoproj.io/v1alpha1\",\"metadata\":{\"generateName\":\"monitor-credit-risk-ai-\",\"creationTimestamp\":null,\"labels\":{\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.18\"},\"annotations\":{\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.18\",\"pipelines.kubeflow.org/pipeline_compilation_time\":\"2023-10-20T20:45:48.628040\",\"pipelines.kubeflow.org/pipeline_spec\":\"{\\\\\"description\\\\\": '\n",
       "                                        '\\\\\"An example pipeline that monitors '\n",
       "                                        'the behavior of the AI model within '\n",
       "                                        'the application\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"Monitor Credit Risk '\n",
       "                                        'AI\\\\\"}\"}},\"spec\":{\"templates\":[{\"name\":\"check-metrics\",\"inputs\":{\"artifacts\":[{\"name\":\"evidently-classification-report-output_json\",\"path\":\"/tmp/inputs/classification_report/data\"},{\"name\":\"evidently-report-output_json\",\"path\":\"/tmp/inputs/data_drift_report/data\"},{\"name\":\"evidently-report-2-output_json\",\"path\":\"/tmp/inputs/target_drift_report/data\"}]},\"outputs\":{\"artifacts\":[{\"name\":\"mlpipeline-metrics\",\"path\":\"/tmp/outputs/mlpipeline_metrics/data\"}]},\"metadata\":{\"annotations\":{\"pipelines.kubeflow.org/component_ref\":\"{}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--classification-report\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"classification_report\\\\\"}, '\n",
       "                                        '\\\\\"--data-drift-report\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"data_drift_report\\\\\"}, '\n",
       "                                        '\\\\\"--target-drift-report\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"target_drift_report\\\\\"}, '\n",
       "                                        '\\\\\"----output-paths\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"mlpipeline_metrics\\\\\"}], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        'check_metrics(classification_report,\\\\\\\\n                  '\n",
       "                                        'data_drift_report,\\\\\\\\n                  '\n",
       "                                        'target_drift_report):\\\\\\\\n    import '\n",
       "                                        'json\\\\\\\\n    from collections import '\n",
       "                                        'namedtuple\\\\\\\\n\\\\\\\\n    with '\n",
       "                                        'open(classification_report) as '\n",
       "                                        'class_f:\\\\\\\\n         classification '\n",
       "                                        '= json.load(class_f)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'ClassificationQualityMetric = '\n",
       "                                        'next(filter(lambda m: '\n",
       "                                        'm[\\\\\\\\\\\\\"metric\\\\\\\\\\\\\"] == '\n",
       "                                        '\\\\\\\\\\\\\"ClassificationQualityMetric\\\\\\\\\\\\\", '\n",
       "                                        'classification[\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\"]))\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'metrics = {\\\\\\\\n        '\n",
       "                                        '\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\": '\n",
       "                                        '[\\\\\\\\n            '\n",
       "                                        '{\\\\\\\\\\\\\"name\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"f1\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"numberValue\\\\\\\\\\\\\": '\n",
       "                                        'ClassificationQualityMetric[\\\\\\\\\\\\\"result\\\\\\\\\\\\\"][\\\\\\\\\\\\\"current\\\\\\\\\\\\\"][\\\\\\\\\\\\\"f1\\\\\\\\\\\\\"], '\n",
       "                                        '\\\\\\\\\\\\\"format\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"RAW\\\\\\\\\\\\\"}\\\\\\\\n        '\n",
       "                                        ']\\\\\\\\n    }\\\\\\\\n\\\\\\\\n    out_tuple = '\n",
       "                                        'namedtuple(\\\\\\\\\\\\\"EvaluationOutput\\\\\\\\\\\\\", '\n",
       "                                        '[\\\\\\\\\\\\\"mlpipeline_metrics\\\\\\\\\\\\\"])\\\\\\\\n    '\n",
       "                                        'return '\n",
       "                                        'out_tuple(json.dumps(metrics))\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Check \"\n",
       "                                        \"metrics', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--classification-report\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"classification_report\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--data-drift-report\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"data_drift_report\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--target-drift-report\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"target_drift_report\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"----output-paths\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        'type=str, nargs=1)\\\\\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        '[])\\\\\\\\n\\\\\\\\n_outputs = '\n",
       "                                        'check_metrics(**_parsed_args)\\\\\\\\n\\\\\\\\n_output_serializers '\n",
       "                                        '= [\\\\\\\\n    '\n",
       "                                        'str,\\\\\\\\n\\\\\\\\n]\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'os\\\\\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\\\\\n    '\n",
       "                                        'try:\\\\\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\\\\\n    '\n",
       "                                        'except OSError:\\\\\\\\n        '\n",
       "                                        'pass\\\\\\\\n    with open(output_file, '\n",
       "                                        \"'w') as f:\\\\\\\\n        \"\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"classification_report\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"data_drift_report\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"target_drift_report\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}], '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"Check metrics\\\\\", '\n",
       "                                        '\\\\\"outputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"mlpipeline_metrics\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Metrics\\\\\"}]}\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.18\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        'check_metrics(classification_report,\\\\n                  '\n",
       "                                        'data_drift_report,\\\\n                  '\n",
       "                                        'target_drift_report):\\\\n    import '\n",
       "                                        'json\\\\n    from collections import '\n",
       "                                        'namedtuple\\\\n\\\\n    with '\n",
       "                                        'open(classification_report) as '\n",
       "                                        'class_f:\\\\n         classification = '\n",
       "                                        'json.load(class_f)\\\\n\\\\n    '\n",
       "                                        'ClassificationQualityMetric = '\n",
       "                                        'next(filter(lambda m: m[\\\\\"metric\\\\\"] '\n",
       "                                        '== \\\\\"ClassificationQualityMetric\\\\\", '\n",
       "                                        'classification[\\\\\"metrics\\\\\"]))\\\\n\\\\n    '\n",
       "                                        'metrics = {\\\\n        \\\\\"metrics\\\\\": '\n",
       "                                        '[\\\\n            {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"f1\\\\\", \\\\\"numberValue\\\\\": '\n",
       "                                        'ClassificationQualityMetric[\\\\\"result\\\\\"][\\\\\"current\\\\\"][\\\\\"f1\\\\\"], '\n",
       "                                        '\\\\\"format\\\\\": \\\\\"RAW\\\\\"}\\\\n        '\n",
       "                                        ']\\\\n    }\\\\n\\\\n    out_tuple = '\n",
       "                                        'namedtuple(\\\\\"EvaluationOutput\\\\\", '\n",
       "                                        '[\\\\\"mlpipeline_metrics\\\\\"])\\\\n    '\n",
       "                                        'return '\n",
       "                                        'out_tuple(json.dumps(metrics))\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Check \"\n",
       "                                        \"metrics', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--classification-report\\\\\", '\n",
       "                                        'dest=\\\\\"classification_report\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--data-drift-report\\\\\", '\n",
       "                                        'dest=\\\\\"data_drift_report\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--target-drift-report\\\\\", '\n",
       "                                        'dest=\\\\\"target_drift_report\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"----output-paths\\\\\", '\n",
       "                                        'dest=\\\\\"_output_paths\\\\\", type=str, '\n",
       "                                        'nargs=1)\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\"_output_paths\\\\\", '\n",
       "                                        '[])\\\\n\\\\n_outputs = '\n",
       "                                        'check_metrics(**_parsed_args)\\\\n\\\\n_output_serializers '\n",
       "                                        '= [\\\\n    str,\\\\n\\\\n]\\\\n\\\\nimport '\n",
       "                                        'os\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\n    '\n",
       "                                        'try:\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\n    '\n",
       "                                        'except OSError:\\\\n        pass\\\\n    '\n",
       "                                        \"with open(output_file, 'w') as \"\n",
       "                                        'f:\\\\n        '\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\n\"],\"args\":[\"--classification-report\",\"/tmp/inputs/classification_report/data\",\"--data-drift-report\",\"/tmp/inputs/data_drift_report/data\",\"--target-drift-report\",\"/tmp/inputs/target_drift_report/data\",\"----output-paths\",\"/tmp/outputs/mlpipeline_metrics/data\"],\"env\":[{\"name\":\"COLUMNS\",\"valueFrom\":{\"configMapKeyRef\":{\"name\":\"credit-risk-columns\",\"key\":\"columns\"}}}],\"resources\":{}}},{\"name\":\"evidently-classification-report\",\"inputs\":{\"artifacts\":[{\"name\":\"load-df-from-db2-2-data_frame_pkl\",\"path\":\"/tmp/inputs/production_df/data\"}]},\"outputs\":{\"artifacts\":[{\"name\":\"mlpipeline-ui-metadata\",\"path\":\"/tmp/outputs/mlpipeline_ui_metadata/data\"},{\"name\":\"evidently-classification-report-output_json\",\"path\":\"/tmp/outputs/output_json/data\"},{\"name\":\"evidently-classification-report-output_report\",\"path\":\"/tmp/outputs/output_report/data\"}]},\"metadata\":{\"annotations\":{\"pipelines.kubeflow.org/arguments.parameters\":\"{\\\\\"pos_class\\\\\": '\n",
       "                                        '\\\\\"Risk\\\\\", \\\\\"predictions\\\\\": '\n",
       "                                        '\\\\\"PredictedRisk\\\\\", \\\\\"target\\\\\": '\n",
       "                                        '\\\\\"Risk\\\\\"}\",\"pipelines.kubeflow.org/component_ref\":\"{}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--production-df\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"production_df\\\\\"}, {\\\\\"if\\\\\": '\n",
       "                                        '{\\\\\"cond\\\\\": {\\\\\"isPresent\\\\\": '\n",
       "                                        '\\\\\"target\\\\\"}, \\\\\"then\\\\\": '\n",
       "                                        '[\\\\\"--target\\\\\", {\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"target\\\\\"}]}}, {\\\\\"if\\\\\": '\n",
       "                                        '{\\\\\"cond\\\\\": {\\\\\"isPresent\\\\\": '\n",
       "                                        '\\\\\"predictions\\\\\"}, \\\\\"then\\\\\": '\n",
       "                                        '[\\\\\"--predictions\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"predictions\\\\\"}]}}, {\\\\\"if\\\\\": '\n",
       "                                        '{\\\\\"cond\\\\\": {\\\\\"isPresent\\\\\": '\n",
       "                                        '\\\\\"pos_class\\\\\"}, \\\\\"then\\\\\": '\n",
       "                                        '[\\\\\"--pos-class\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"pos_class\\\\\"}]}}, '\n",
       "                                        '\\\\\"--mlpipeline-ui-metadata\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"mlpipeline_ui_metadata\\\\\"}, '\n",
       "                                        '\\\\\"--output-report\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_report\\\\\"}, '\n",
       "                                        '\\\\\"--output-json\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_json\\\\\"}], \\\\\"command\\\\\": '\n",
       "                                        '[\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\\\\\n    return '\n",
       "                                        'file_path\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        'evidently_classification_report(production_df,\\\\\\\\n                      '\n",
       "                                        'mlpipeline_ui_metadata_path,\\\\\\\\n                      '\n",
       "                                        'output_report,\\\\\\\\n                      '\n",
       "                                        'output_json,\\\\\\\\n                      '\n",
       "                                        'target = '\n",
       "                                        \"'Risk',\\\\\\\\n                      \"\n",
       "                                        'predictions = '\n",
       "                                        \"'PredictedRisk',\\\\\\\\n                      \"\n",
       "                                        'pos_class = '\n",
       "                                        \"'Risk'\\\\\\\\n                     \"\n",
       "                                        '):\\\\\\\\n    from '\n",
       "                                        'evidently.metric_preset import '\n",
       "                                        '(\\\\\\\\n    '\n",
       "                                        'ClassificationPreset,\\\\\\\\n    '\n",
       "                                        ')\\\\\\\\n    from evidently.report '\n",
       "                                        'import Report\\\\\\\\n    from evidently '\n",
       "                                        'import ColumnMapping\\\\\\\\n    import '\n",
       "                                        'pandas as pd\\\\\\\\n    import '\n",
       "                                        'os\\\\\\\\n    from pathlib import '\n",
       "                                        'Path\\\\\\\\n    import json\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'production_dataset = '\n",
       "                                        'pd.read_pickle(production_df)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'production_dataset.dropna(subset=[target, '\n",
       "                                        'predictions], inplace=True)\\\\\\\\n    '\n",
       "                                        'column_info = '\n",
       "                                        'json.loads(os.environ[\\\\\\\\\\\\\"COLUMNS\\\\\\\\\\\\\"])\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'column_mapping = '\n",
       "                                        'ColumnMapping()\\\\\\\\n    '\n",
       "                                        \"#column_mapping.target_names = ['No \"\n",
       "                                        \"Risk', 'Risk']\\\\\\\\n    \"\n",
       "                                        \"column_mapping.target = 'Risk' \"\n",
       "                                        \"#'Actual_Int'\\\\\\\\n    \"\n",
       "                                        'column_mapping.prediction = '\n",
       "                                        \"'PredictedRisk' \"\n",
       "                                        \"#'Predicted_Int'\\\\\\\\n    \"\n",
       "                                        'column_mapping.pos_label = '\n",
       "                                        \"'Risk'\\\\\\\\n    column_mapping.task = \"\n",
       "                                        '\\\\\\\\\\\\\"classification\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'column_mapping.numerical_features = '\n",
       "                                        '[\\\\\\\\n        c\\\\\\\\n        for c in '\n",
       "                                        'column_info[\\\\\\\\\\\\\"int_columns\\\\\\\\\\\\\"]\\\\\\\\n        '\n",
       "                                        'if c != target\\\\\\\\n    ]\\\\\\\\n    '\n",
       "                                        'column_mapping.categorical_features = '\n",
       "                                        '[\\\\\\\\n        c\\\\\\\\n        for c in '\n",
       "                                        'column_info[\\\\\\\\\\\\\"label_columns\\\\\\\\\\\\\"]\\\\\\\\n        '\n",
       "                                        'if c != target\\\\\\\\n    ]\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'report = Report(\\\\\\\\n        '\n",
       "                                        'metrics=[\\\\\\\\n            '\n",
       "                                        'ClassificationPreset()\\\\\\\\n        '\n",
       "                                        ']\\\\\\\\n    )\\\\\\\\n\\\\\\\\n    '\n",
       "                                        \"#production_dataset['Actual_Int'] = \"\n",
       "                                        'production_dataset[target].apply(lambda '\n",
       "                                        'v: 1 if v == pos_class else '\n",
       "                                        '0)\\\\\\\\n    '\n",
       "                                        \"#production_dataset['Predicted_Int'] \"\n",
       "                                        '= '\n",
       "                                        'production_dataset[predictions].apply(lambda '\n",
       "                                        'v: 1 if v == pos_class else '\n",
       "                                        '0)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'report.run(\\\\\\\\n        '\n",
       "                                        'reference_data=None,\\\\\\\\n        '\n",
       "                                        'current_data=production_dataset,\\\\\\\\n        '\n",
       "                                        'column_mapping=column_mapping,\\\\\\\\n    '\n",
       "                                        ')\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'Path(output_report).parent.mkdir(parents=True, '\n",
       "                                        'exist_ok=True)\\\\\\\\n    '\n",
       "                                        'report.save_html(output_report)\\\\\\\\n    '\n",
       "                                        'html_content = open(output_report, '\n",
       "                                        '\\\\\\\\\\\\\"r\\\\\\\\\\\\\").read()\\\\\\\\n    '\n",
       "                                        'metadata = {\\\\\\\\n        '\n",
       "                                        '\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": '\n",
       "                                        '[\\\\\\\\n            '\n",
       "                                        '{\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"type\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"web-app\\\\\\\\\\\\\",\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"storage\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"inline\\\\\\\\\\\\\",\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"source\\\\\\\\\\\\\": '\n",
       "                                        'html_content,\\\\\\\\n            '\n",
       "                                        '}\\\\\\\\n        ]\\\\\\\\n    '\n",
       "                                        '}\\\\\\\\n\\\\\\\\n    with '\n",
       "                                        'open(mlpipeline_ui_metadata_path, '\n",
       "                                        '\\\\\\\\\\\\\"w\\\\\\\\\\\\\") as f:\\\\\\\\n        '\n",
       "                                        'json.dump(metadata, f)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'with open(output_json, '\n",
       "                                        '\\\\\\\\\\\\\"w\\\\\\\\\\\\\") as '\n",
       "                                        'json_f:\\\\\\\\n        '\n",
       "                                        'json_f.write(report.json())\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Evidently \"\n",
       "                                        \"classification report', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--production-df\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"production_df\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--target\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"target\\\\\\\\\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--predictions\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"predictions\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--pos-class\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"pos_class\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--mlpipeline-ui-metadata\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"mlpipeline_ui_metadata_path\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-report\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_report\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-json\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_json\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'evidently_classification_report(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"production_df\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"Risk\\\\\", \\\\\"name\\\\\": \\\\\"target\\\\\", '\n",
       "                                        '\\\\\"optional\\\\\": true, \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"PredictedRisk\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"predictions\\\\\", \\\\\"optional\\\\\": '\n",
       "                                        'true, \\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": \\\\\"Risk\\\\\", '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"pos_class\\\\\", '\n",
       "                                        '\\\\\"optional\\\\\": true, \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}], \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"Evidently classification '\n",
       "                                        'report\\\\\", \\\\\"outputs\\\\\": '\n",
       "                                        '[{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"mlpipeline_ui_metadata\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"output_report\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"output_json\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}]}\",\"pipelines.kubeflow.org/task_display_name\":\"Produce '\n",
       "                                        'classification '\n",
       "                                        'Report\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.18\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\n    import os\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\n    return '\n",
       "                                        'file_path\\\\n\\\\ndef '\n",
       "                                        'evidently_classification_report(production_df,\\\\n                      '\n",
       "                                        'mlpipeline_ui_metadata_path,\\\\n                      '\n",
       "                                        'output_report,\\\\n                      '\n",
       "                                        'output_json,\\\\n                      '\n",
       "                                        'target = '\n",
       "                                        \"'Risk',\\\\n                      \"\n",
       "                                        'predictions = '\n",
       "                                        \"'PredictedRisk',\\\\n                      \"\n",
       "                                        'pos_class = '\n",
       "                                        \"'Risk'\\\\n                     \"\n",
       "                                        '):\\\\n    from evidently.metric_preset '\n",
       "                                        'import (\\\\n    '\n",
       "                                        'ClassificationPreset,\\\\n    )\\\\n    '\n",
       "                                        'from evidently.report import '\n",
       "                                        'Report\\\\n    from evidently import '\n",
       "                                        'ColumnMapping\\\\n    import pandas as '\n",
       "                                        'pd\\\\n    import os\\\\n    from pathlib '\n",
       "                                        'import Path\\\\n    import '\n",
       "                                        'json\\\\n\\\\n    production_dataset = '\n",
       "                                        'pd.read_pickle(production_df)\\\\n\\\\n    '\n",
       "                                        'production_dataset.dropna(subset=[target, '\n",
       "                                        'predictions], inplace=True)\\\\n    '\n",
       "                                        'column_info = '\n",
       "                                        'json.loads(os.environ[\\\\\"COLUMNS\\\\\"])\\\\n\\\\n    '\n",
       "                                        'column_mapping = '\n",
       "                                        'ColumnMapping()\\\\n    '\n",
       "                                        \"#column_mapping.target_names = ['No \"\n",
       "                                        \"Risk', 'Risk']\\\\n    \"\n",
       "                                        \"column_mapping.target = 'Risk' \"\n",
       "                                        \"#'Actual_Int'\\\\n    \"\n",
       "                                        'column_mapping.prediction = '\n",
       "                                        \"'PredictedRisk' \"\n",
       "                                        \"#'Predicted_Int'\\\\n    \"\n",
       "                                        'column_mapping.pos_label = '\n",
       "                                        \"'Risk'\\\\n    column_mapping.task = \"\n",
       "                                        '\\\\\"classification\\\\\"\\\\n\\\\n    '\n",
       "                                        'column_mapping.numerical_features = '\n",
       "                                        '[\\\\n        c\\\\n        for c in '\n",
       "                                        'column_info[\\\\\"int_columns\\\\\"]\\\\n        '\n",
       "                                        'if c != target\\\\n    ]\\\\n    '\n",
       "                                        'column_mapping.categorical_features = '\n",
       "                                        '[\\\\n        c\\\\n        for c in '\n",
       "                                        'column_info[\\\\\"label_columns\\\\\"]\\\\n        '\n",
       "                                        'if c != target\\\\n    ]\\\\n\\\\n    '\n",
       "                                        'report = Report(\\\\n        '\n",
       "                                        'metrics=[\\\\n            '\n",
       "                                        'ClassificationPreset()\\\\n        '\n",
       "                                        ']\\\\n    )\\\\n\\\\n    '\n",
       "                                        \"#production_dataset['Actual_Int'] = \"\n",
       "                                        'production_dataset[target].apply(lambda '\n",
       "                                        'v: 1 if v == pos_class else 0)\\\\n    '\n",
       "                                        \"#production_dataset['Predicted_Int'] \"\n",
       "                                        '= '\n",
       "                                        'production_dataset[predictions].apply(lambda '\n",
       "                                        'v: 1 if v == pos_class else '\n",
       "                                        '0)\\\\n\\\\n    report.run(\\\\n        '\n",
       "                                        'reference_data=None,\\\\n        '\n",
       "                                        'current_data=production_dataset,\\\\n        '\n",
       "                                        'column_mapping=column_mapping,\\\\n    '\n",
       "                                        ')\\\\n\\\\n    '\n",
       "                                        'Path(output_report).parent.mkdir(parents=True, '\n",
       "                                        'exist_ok=True)\\\\n    '\n",
       "                                        'report.save_html(output_report)\\\\n    '\n",
       "                                        'html_content = open(output_report, '\n",
       "                                        '\\\\\"r\\\\\").read()\\\\n    metadata = '\n",
       "                                        '{\\\\n        \\\\\"outputs\\\\\": '\n",
       "                                        '[\\\\n            {\\\\n                '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"web-app\\\\\",\\\\n                '\n",
       "                                        '\\\\\"storage\\\\\": '\n",
       "                                        '\\\\\"inline\\\\\",\\\\n                '\n",
       "                                        '\\\\\"source\\\\\": '\n",
       "                                        'html_content,\\\\n            '\n",
       "                                        '}\\\\n        ]\\\\n    }\\\\n\\\\n    with '\n",
       "                                        'open(mlpipeline_ui_metadata_path, '\n",
       "                                        '\\\\\"w\\\\\") as f:\\\\n        '\n",
       "                                        'json.dump(metadata, f)\\\\n\\\\n    with '\n",
       "                                        'open(output_json, \\\\\"w\\\\\") as '\n",
       "                                        'json_f:\\\\n        '\n",
       "                                        'json_f.write(report.json())\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Evidently \"\n",
       "                                        \"classification report', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--production-df\\\\\", '\n",
       "                                        'dest=\\\\\"production_df\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--target\\\\\", '\n",
       "                                        'dest=\\\\\"target\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--predictions\\\\\", '\n",
       "                                        'dest=\\\\\"predictions\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--pos-class\\\\\", '\n",
       "                                        'dest=\\\\\"pos_class\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--mlpipeline-ui-metadata\\\\\", '\n",
       "                                        'dest=\\\\\"mlpipeline_ui_metadata_path\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-report\\\\\", '\n",
       "                                        'dest=\\\\\"output_report\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-json\\\\\", '\n",
       "                                        'dest=\\\\\"output_json\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'evidently_classification_report(**_parsed_args)\\\\n\"],\"args\":[\"--production-df\",\"/tmp/inputs/production_df/data\",\"--target\",\"Risk\",\"--predictions\",\"PredictedRisk\",\"--pos-class\",\"Risk\",\"--mlpipeline-ui-metadata\",\"/tmp/outputs/mlpipeline_ui_metadata/data\",\"--output-report\",\"/tmp/outputs/output_report/data\",\"--output-json\",\"/tmp/outputs/output_json/data\"],\"env\":[{\"name\":\"COLUMNS\",\"valueFrom\":{\"configMapKeyRef\":{\"name\":\"credit-risk-columns\",\"key\":\"columns\"}}}],\"resources\":{}}},{\"name\":\"evidently-report\",\"inputs\":{\"artifacts\":[{\"name\":\"load-df-from-db2-2-data_frame_pkl\",\"path\":\"/tmp/inputs/production_df/data\"},{\"name\":\"load-df-from-db2-data_frame_pkl\",\"path\":\"/tmp/inputs/reference_df/data\"}]},\"outputs\":{\"artifacts\":[{\"name\":\"mlpipeline-ui-metadata\",\"path\":\"/tmp/outputs/mlpipeline_ui_metadata/data\"},{\"name\":\"evidently-report-output_json\",\"path\":\"/tmp/outputs/output_json/data\"},{\"name\":\"evidently-report-output_report\",\"path\":\"/tmp/outputs/output_report/data\"}]},\"metadata\":{\"annotations\":{\"pipelines.kubeflow.org/arguments.parameters\":\"{\\\\\"report_type\\\\\": '\n",
       "                                        '\\\\\"drift\\\\\", \\\\\"target\\\\\": '\n",
       "                                        '\\\\\"Risk\\\\\"}\",\"pipelines.kubeflow.org/component_ref\":\"{}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--reference-df\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"reference_df\\\\\"}, '\n",
       "                                        '\\\\\"--production-df\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"production_df\\\\\"}, {\\\\\"if\\\\\": '\n",
       "                                        '{\\\\\"cond\\\\\": {\\\\\"isPresent\\\\\": '\n",
       "                                        '\\\\\"target\\\\\"}, \\\\\"then\\\\\": '\n",
       "                                        '[\\\\\"--target\\\\\", {\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"target\\\\\"}]}}, {\\\\\"if\\\\\": '\n",
       "                                        '{\\\\\"cond\\\\\": {\\\\\"isPresent\\\\\": '\n",
       "                                        '\\\\\"report_type\\\\\"}, \\\\\"then\\\\\": '\n",
       "                                        '[\\\\\"--report-type\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"report_type\\\\\"}]}}, '\n",
       "                                        '\\\\\"--mlpipeline-ui-metadata\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"mlpipeline_ui_metadata\\\\\"}, '\n",
       "                                        '\\\\\"--output-report\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_report\\\\\"}, '\n",
       "                                        '\\\\\"--output-json\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_json\\\\\"}], \\\\\"command\\\\\": '\n",
       "                                        '[\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\\\\\n    return '\n",
       "                                        'file_path\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        'evidently_report(reference_df,\\\\\\\\n                      '\n",
       "                                        'production_df,\\\\\\\\n                      '\n",
       "                                        'mlpipeline_ui_metadata_path,\\\\\\\\n                      '\n",
       "                                        'output_report,\\\\\\\\n                      '\n",
       "                                        'output_json,\\\\\\\\n                      '\n",
       "                                        'target = '\n",
       "                                        \"'Risk',\\\\\\\\n                      \"\n",
       "                                        'report_type = '\n",
       "                                        \"'drift'\\\\\\\\n                     \"\n",
       "                                        '):\\\\\\\\n    from '\n",
       "                                        'evidently.metric_preset import '\n",
       "                                        '(\\\\\\\\n    DataDriftPreset,\\\\\\\\n    '\n",
       "                                        'TargetDriftPreset,\\\\\\\\n    '\n",
       "                                        'ClassificationPreset,\\\\\\\\n    '\n",
       "                                        ')\\\\\\\\n    from evidently.report '\n",
       "                                        'import Report\\\\\\\\n    from evidently '\n",
       "                                        'import ColumnMapping\\\\\\\\n    import '\n",
       "                                        'pandas as pd\\\\\\\\n    import '\n",
       "                                        'os\\\\\\\\n    from pathlib import '\n",
       "                                        'Path\\\\\\\\n    import json\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'reference_dataset = '\n",
       "                                        'pd.read_pickle(reference_df)\\\\\\\\n    '\n",
       "                                        'production_dataset = '\n",
       "                                        'pd.read_pickle(production_df)\\\\\\\\n    '\n",
       "                                        'column_info = '\n",
       "                                        'json.loads(os.environ[\\\\\\\\\\\\\"COLUMNS\\\\\\\\\\\\\"])\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'column_mapping = '\n",
       "                                        'ColumnMapping()\\\\\\\\n    '\n",
       "                                        'column_mapping.target = '\n",
       "                                        'target\\\\\\\\n    column_mapping.task = '\n",
       "                                        '\\\\\\\\\\\\\"classification\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'column_mapping.numerical_features = '\n",
       "                                        '[\\\\\\\\n        c\\\\\\\\n        for c in '\n",
       "                                        'column_info[\\\\\\\\\\\\\"int_columns\\\\\\\\\\\\\"]\\\\\\\\n        '\n",
       "                                        'if c != target\\\\\\\\n    ]\\\\\\\\n    '\n",
       "                                        'column_mapping.categorical_features = '\n",
       "                                        '[\\\\\\\\n        c\\\\\\\\n        for c in '\n",
       "                                        'column_info[\\\\\\\\\\\\\"label_columns\\\\\\\\\\\\\"]\\\\\\\\n        '\n",
       "                                        'if c != target\\\\\\\\n    ]\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'if report_type.lower() == '\n",
       "                                        '\\\\\\\\\\\\\"drift\\\\\\\\\\\\\":\\\\\\\\n        '\n",
       "                                        'report = Report(\\\\\\\\n            '\n",
       "                                        'metrics=[\\\\\\\\n                '\n",
       "                                        'DataDriftPreset(),\\\\\\\\n            '\n",
       "                                        ']\\\\\\\\n        )\\\\\\\\n    elif '\n",
       "                                        'report_type.lower() == '\n",
       "                                        '\\\\\\\\\\\\\"target_drift\\\\\\\\\\\\\":\\\\\\\\n        '\n",
       "                                        'report = Report(\\\\\\\\n            '\n",
       "                                        'metrics=[\\\\\\\\n                '\n",
       "                                        'TargetDriftPreset(),\\\\\\\\n            '\n",
       "                                        ']\\\\\\\\n        )\\\\\\\\n    '\n",
       "                                        'else:\\\\\\\\n        raise '\n",
       "                                        'NotImplementedError()\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'report.run(\\\\\\\\n        '\n",
       "                                        'reference_data=reference_dataset,\\\\\\\\n        '\n",
       "                                        'current_data=production_dataset,\\\\\\\\n        '\n",
       "                                        'column_mapping=column_mapping,\\\\\\\\n    '\n",
       "                                        ')\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'Path(output_report).parent.mkdir(parents=True, '\n",
       "                                        'exist_ok=True)\\\\\\\\n    '\n",
       "                                        'report.save_html(output_report)\\\\\\\\n    '\n",
       "                                        'html_content = open(output_report, '\n",
       "                                        '\\\\\\\\\\\\\"r\\\\\\\\\\\\\").read()\\\\\\\\n    '\n",
       "                                        'metadata = {\\\\\\\\n        '\n",
       "                                        '\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": '\n",
       "                                        '[\\\\\\\\n            '\n",
       "                                        '{\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"type\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"web-app\\\\\\\\\\\\\",\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"storage\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"inline\\\\\\\\\\\\\",\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"source\\\\\\\\\\\\\": '\n",
       "                                        'html_content,\\\\\\\\n            '\n",
       "                                        '}\\\\\\\\n        ]\\\\\\\\n    '\n",
       "                                        '}\\\\\\\\n\\\\\\\\n    with '\n",
       "                                        'open(mlpipeline_ui_metadata_path, '\n",
       "                                        '\\\\\\\\\\\\\"w\\\\\\\\\\\\\") as f:\\\\\\\\n        '\n",
       "                                        'json.dump(metadata, f)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'with open(output_json, '\n",
       "                                        '\\\\\\\\\\\\\"w\\\\\\\\\\\\\") as '\n",
       "                                        'json_f:\\\\\\\\n        '\n",
       "                                        'json_f.write(report.json())\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Evidently \"\n",
       "                                        \"report', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--reference-df\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"reference_df\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--production-df\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"production_df\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--target\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"target\\\\\\\\\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--report-type\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"report_type\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--mlpipeline-ui-metadata\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"mlpipeline_ui_metadata_path\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-report\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_report\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-json\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_json\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'evidently_report(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"reference_df\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"production_df\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"Risk\\\\\", \\\\\"name\\\\\": \\\\\"target\\\\\", '\n",
       "                                        '\\\\\"optional\\\\\": true, \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"drift\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"report_type\\\\\", \\\\\"optional\\\\\": '\n",
       "                                        'true, \\\\\"type\\\\\": \\\\\"String\\\\\"}], '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"Evidently report\\\\\", '\n",
       "                                        '\\\\\"outputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"mlpipeline_ui_metadata\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"output_report\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"output_json\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}]}\",\"pipelines.kubeflow.org/task_display_name\":\"Produce '\n",
       "                                        'Data Drift '\n",
       "                                        'Report\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.18\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\n    import os\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\n    return '\n",
       "                                        'file_path\\\\n\\\\ndef '\n",
       "                                        'evidently_report(reference_df,\\\\n                      '\n",
       "                                        'production_df,\\\\n                      '\n",
       "                                        'mlpipeline_ui_metadata_path,\\\\n                      '\n",
       "                                        'output_report,\\\\n                      '\n",
       "                                        'output_json,\\\\n                      '\n",
       "                                        'target = '\n",
       "                                        \"'Risk',\\\\n                      \"\n",
       "                                        'report_type = '\n",
       "                                        \"'drift'\\\\n                     \"\n",
       "                                        '):\\\\n    from evidently.metric_preset '\n",
       "                                        'import (\\\\n    DataDriftPreset,\\\\n    '\n",
       "                                        'TargetDriftPreset,\\\\n    '\n",
       "                                        'ClassificationPreset,\\\\n    )\\\\n    '\n",
       "                                        'from evidently.report import '\n",
       "                                        'Report\\\\n    from evidently import '\n",
       "                                        'ColumnMapping\\\\n    import pandas as '\n",
       "                                        'pd\\\\n    import os\\\\n    from pathlib '\n",
       "                                        'import Path\\\\n    import '\n",
       "                                        'json\\\\n\\\\n    reference_dataset = '\n",
       "                                        'pd.read_pickle(reference_df)\\\\n    '\n",
       "                                        'production_dataset = '\n",
       "                                        'pd.read_pickle(production_df)\\\\n    '\n",
       "                                        'column_info = '\n",
       "                                        'json.loads(os.environ[\\\\\"COLUMNS\\\\\"])\\\\n\\\\n    '\n",
       "                                        'column_mapping = '\n",
       "                                        'ColumnMapping()\\\\n    '\n",
       "                                        'column_mapping.target = target\\\\n    '\n",
       "                                        'column_mapping.task = '\n",
       "                                        '\\\\\"classification\\\\\"\\\\n\\\\n    '\n",
       "                                        'column_mapping.numerical_features = '\n",
       "                                        '[\\\\n        c\\\\n        for c in '\n",
       "                                        'column_info[\\\\\"int_columns\\\\\"]\\\\n        '\n",
       "                                        'if c != target\\\\n    ]\\\\n    '\n",
       "                                        'column_mapping.categorical_features = '\n",
       "                                        '[\\\\n        c\\\\n        for c in '\n",
       "                                        'column_info[\\\\\"label_columns\\\\\"]\\\\n        '\n",
       "                                        'if c != target\\\\n    ]\\\\n\\\\n    if '\n",
       "                                        'report_type.lower() == '\n",
       "                                        '\\\\\"drift\\\\\":\\\\n        report = '\n",
       "                                        'Report(\\\\n            '\n",
       "                                        'metrics=[\\\\n                '\n",
       "                                        'DataDriftPreset(),\\\\n            '\n",
       "                                        ']\\\\n        )\\\\n    elif '\n",
       "                                        'report_type.lower() == '\n",
       "                                        '\\\\\"target_drift\\\\\":\\\\n        report '\n",
       "                                        '= Report(\\\\n            '\n",
       "                                        'metrics=[\\\\n                '\n",
       "                                        'TargetDriftPreset(),\\\\n            '\n",
       "                                        ']\\\\n        )\\\\n    else:\\\\n        '\n",
       "                                        'raise NotImplementedError()\\\\n\\\\n    '\n",
       "                                        'report.run(\\\\n        '\n",
       "                                        'reference_data=reference_dataset,\\\\n        '\n",
       "                                        'current_data=production_dataset,\\\\n        '\n",
       "                                        'column_mapping=column_mapping,\\\\n    '\n",
       "                                        ')\\\\n\\\\n    '\n",
       "                                        'Path(output_report).parent.mkdir(parents=True, '\n",
       "                                        'exist_ok=True)\\\\n    '\n",
       "                                        'report.save_html(output_report)\\\\n    '\n",
       "                                        'html_content = open(output_report, '\n",
       "                                        '\\\\\"r\\\\\").read()\\\\n    metadata = '\n",
       "                                        '{\\\\n        \\\\\"outputs\\\\\": '\n",
       "                                        '[\\\\n            {\\\\n                '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"web-app\\\\\",\\\\n                '\n",
       "                                        '\\\\\"storage\\\\\": '\n",
       "                                        '\\\\\"inline\\\\\",\\\\n                '\n",
       "                                        '\\\\\"source\\\\\": '\n",
       "                                        'html_content,\\\\n            '\n",
       "                                        '}\\\\n        ]\\\\n    }\\\\n\\\\n    with '\n",
       "                                        'open(mlpipeline_ui_metadata_path, '\n",
       "                                        '\\\\\"w\\\\\") as f:\\\\n        '\n",
       "                                        'json.dump(metadata, f)\\\\n\\\\n    with '\n",
       "                                        'open(output_json, \\\\\"w\\\\\") as '\n",
       "                                        'json_f:\\\\n        '\n",
       "                                        'json_f.write(report.json())\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Evidently \"\n",
       "                                        \"report', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--reference-df\\\\\", '\n",
       "                                        'dest=\\\\\"reference_df\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--production-df\\\\\", '\n",
       "                                        'dest=\\\\\"production_df\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--target\\\\\", '\n",
       "                                        'dest=\\\\\"target\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--report-type\\\\\", '\n",
       "                                        'dest=\\\\\"report_type\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--mlpipeline-ui-metadata\\\\\", '\n",
       "                                        'dest=\\\\\"mlpipeline_ui_metadata_path\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-report\\\\\", '\n",
       "                                        'dest=\\\\\"output_report\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-json\\\\\", '\n",
       "                                        'dest=\\\\\"output_json\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'evidently_report(**_parsed_args)\\\\n\"],\"args\":[\"--reference-df\",\"/tmp/inputs/reference_df/data\",\"--production-df\",\"/tmp/inputs/production_df/data\",\"--target\",\"Risk\",\"--report-type\",\"drift\",\"--mlpipeline-ui-metadata\",\"/tmp/outputs/mlpipeline_ui_metadata/data\",\"--output-report\",\"/tmp/outputs/output_report/data\",\"--output-json\",\"/tmp/outputs/output_json/data\"],\"env\":[{\"name\":\"COLUMNS\",\"valueFrom\":{\"configMapKeyRef\":{\"name\":\"credit-risk-columns\",\"key\":\"columns\"}}}],\"resources\":{}}},{\"name\":\"evidently-report-2\",\"inputs\":{\"artifacts\":[{\"name\":\"load-df-from-db2-2-data_frame_pkl\",\"path\":\"/tmp/inputs/production_df/data\"},{\"name\":\"load-df-from-db2-data_frame_pkl\",\"path\":\"/tmp/inputs/reference_df/data\"}]},\"outputs\":{\"artifacts\":[{\"name\":\"mlpipeline-ui-metadata\",\"path\":\"/tmp/outputs/mlpipeline_ui_metadata/data\"},{\"name\":\"evidently-report-2-output_json\",\"path\":\"/tmp/outputs/output_json/data\"},{\"name\":\"evidently-report-2-output_report\",\"path\":\"/tmp/outputs/output_report/data\"}]},\"metadata\":{\"annotations\":{\"pipelines.kubeflow.org/arguments.parameters\":\"{\\\\\"report_type\\\\\": '\n",
       "                                        '\\\\\"target_drift\\\\\", \\\\\"target\\\\\": '\n",
       "                                        '\\\\\"Risk\\\\\"}\",\"pipelines.kubeflow.org/component_ref\":\"{}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--reference-df\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"reference_df\\\\\"}, '\n",
       "                                        '\\\\\"--production-df\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"production_df\\\\\"}, {\\\\\"if\\\\\": '\n",
       "                                        '{\\\\\"cond\\\\\": {\\\\\"isPresent\\\\\": '\n",
       "                                        '\\\\\"target\\\\\"}, \\\\\"then\\\\\": '\n",
       "                                        '[\\\\\"--target\\\\\", {\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"target\\\\\"}]}}, {\\\\\"if\\\\\": '\n",
       "                                        '{\\\\\"cond\\\\\": {\\\\\"isPresent\\\\\": '\n",
       "                                        '\\\\\"report_type\\\\\"}, \\\\\"then\\\\\": '\n",
       "                                        '[\\\\\"--report-type\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"report_type\\\\\"}]}}, '\n",
       "                                        '\\\\\"--mlpipeline-ui-metadata\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"mlpipeline_ui_metadata\\\\\"}, '\n",
       "                                        '\\\\\"--output-report\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_report\\\\\"}, '\n",
       "                                        '\\\\\"--output-json\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_json\\\\\"}], \\\\\"command\\\\\": '\n",
       "                                        '[\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\\\\\n    return '\n",
       "                                        'file_path\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        'evidently_report(reference_df,\\\\\\\\n                      '\n",
       "                                        'production_df,\\\\\\\\n                      '\n",
       "                                        'mlpipeline_ui_metadata_path,\\\\\\\\n                      '\n",
       "                                        'output_report,\\\\\\\\n                      '\n",
       "                                        'output_json,\\\\\\\\n                      '\n",
       "                                        'target = '\n",
       "                                        \"'Risk',\\\\\\\\n                      \"\n",
       "                                        'report_type = '\n",
       "                                        \"'drift'\\\\\\\\n                     \"\n",
       "                                        '):\\\\\\\\n    from '\n",
       "                                        'evidently.metric_preset import '\n",
       "                                        '(\\\\\\\\n    DataDriftPreset,\\\\\\\\n    '\n",
       "                                        'TargetDriftPreset,\\\\\\\\n    '\n",
       "                                        'ClassificationPreset,\\\\\\\\n    '\n",
       "                                        ')\\\\\\\\n    from evidently.report '\n",
       "                                        'import Report\\\\\\\\n    from evidently '\n",
       "                                        'import ColumnMapping\\\\\\\\n    import '\n",
       "                                        'pandas as pd\\\\\\\\n    import '\n",
       "                                        'os\\\\\\\\n    from pathlib import '\n",
       "                                        'Path\\\\\\\\n    import json\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'reference_dataset = '\n",
       "                                        'pd.read_pickle(reference_df)\\\\\\\\n    '\n",
       "                                        'production_dataset = '\n",
       "                                        'pd.read_pickle(production_df)\\\\\\\\n    '\n",
       "                                        'column_info = '\n",
       "                                        'json.loads(os.environ[\\\\\\\\\\\\\"COLUMNS\\\\\\\\\\\\\"])\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'column_mapping = '\n",
       "                                        'ColumnMapping()\\\\\\\\n    '\n",
       "                                        'column_mapping.target = '\n",
       "                                        'target\\\\\\\\n    column_mapping.task = '\n",
       "                                        '\\\\\\\\\\\\\"classification\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'column_mapping.numerical_features = '\n",
       "                                        '[\\\\\\\\n        c\\\\\\\\n        for c in '\n",
       "                                        'column_info[\\\\\\\\\\\\\"int_columns\\\\\\\\\\\\\"]\\\\\\\\n        '\n",
       "                                        'if c != target\\\\\\\\n    ]\\\\\\\\n    '\n",
       "                                        'column_mapping.categorical_features = '\n",
       "                                        '[\\\\\\\\n        c\\\\\\\\n        for c in '\n",
       "                                        'column_info[\\\\\\\\\\\\\"label_columns\\\\\\\\\\\\\"]\\\\\\\\n        '\n",
       "                                        'if c != target\\\\\\\\n    ]\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'if report_type.lower() == '\n",
       "                                        '\\\\\\\\\\\\\"drift\\\\\\\\\\\\\":\\\\\\\\n        '\n",
       "                                        'report = Report(\\\\\\\\n            '\n",
       "                                        'metrics=[\\\\\\\\n                '\n",
       "                                        'DataDriftPreset(),\\\\\\\\n            '\n",
       "                                        ']\\\\\\\\n        )\\\\\\\\n    elif '\n",
       "                                        'report_type.lower() == '\n",
       "                                        '\\\\\\\\\\\\\"target_drift\\\\\\\\\\\\\":\\\\\\\\n        '\n",
       "                                        'report = Report(\\\\\\\\n            '\n",
       "                                        'metrics=[\\\\\\\\n                '\n",
       "                                        'TargetDriftPreset(),\\\\\\\\n            '\n",
       "                                        ']\\\\\\\\n        )\\\\\\\\n    '\n",
       "                                        'else:\\\\\\\\n        raise '\n",
       "                                        'NotImplementedError()\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'report.run(\\\\\\\\n        '\n",
       "                                        'reference_data=reference_dataset,\\\\\\\\n        '\n",
       "                                        'current_data=production_dataset,\\\\\\\\n        '\n",
       "                                        'column_mapping=column_mapping,\\\\\\\\n    '\n",
       "                                        ')\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'Path(output_report).parent.mkdir(parents=True, '\n",
       "                                        'exist_ok=True)\\\\\\\\n    '\n",
       "                                        'report.save_html(output_report)\\\\\\\\n    '\n",
       "                                        'html_content = open(output_report, '\n",
       "                                        '\\\\\\\\\\\\\"r\\\\\\\\\\\\\").read()\\\\\\\\n    '\n",
       "                                        'metadata = {\\\\\\\\n        '\n",
       "                                        '\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\": '\n",
       "                                        '[\\\\\\\\n            '\n",
       "                                        '{\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"type\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"web-app\\\\\\\\\\\\\",\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"storage\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"inline\\\\\\\\\\\\\",\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"source\\\\\\\\\\\\\": '\n",
       "                                        'html_content,\\\\\\\\n            '\n",
       "                                        '}\\\\\\\\n        ]\\\\\\\\n    '\n",
       "                                        '}\\\\\\\\n\\\\\\\\n    with '\n",
       "                                        'open(mlpipeline_ui_metadata_path, '\n",
       "                                        '\\\\\\\\\\\\\"w\\\\\\\\\\\\\") as f:\\\\\\\\n        '\n",
       "                                        'json.dump(metadata, f)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'with open(output_json, '\n",
       "                                        '\\\\\\\\\\\\\"w\\\\\\\\\\\\\") as '\n",
       "                                        'json_f:\\\\\\\\n        '\n",
       "                                        'json_f.write(report.json())\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Evidently \"\n",
       "                                        \"report', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--reference-df\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"reference_df\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--production-df\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"production_df\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--target\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"target\\\\\\\\\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--report-type\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"report_type\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--mlpipeline-ui-metadata\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"mlpipeline_ui_metadata_path\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-report\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_report\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-json\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_json\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'evidently_report(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"reference_df\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"production_df\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"Risk\\\\\", \\\\\"name\\\\\": \\\\\"target\\\\\", '\n",
       "                                        '\\\\\"optional\\\\\": true, \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"drift\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"report_type\\\\\", \\\\\"optional\\\\\": '\n",
       "                                        'true, \\\\\"type\\\\\": \\\\\"String\\\\\"}], '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"Evidently report\\\\\", '\n",
       "                                        '\\\\\"outputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"mlpipeline_ui_metadata\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"output_report\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"output_json\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}]}\",\"pipelines.kubeflow.org/task_display_name\":\"Produce '\n",
       "                                        'Target Drift '\n",
       "                                        'Report\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.18\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\n    import os\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\n    return '\n",
       "                                        'file_path\\\\n\\\\ndef '\n",
       "                                        'evidently_report(reference_df,\\\\n                      '\n",
       "                                        'production_df,\\\\n                      '\n",
       "                                        'mlpipeline_ui_metadata_path,\\\\n                      '\n",
       "                                        'output_report,\\\\n                      '\n",
       "                                        'output_json,\\\\n                      '\n",
       "                                        'target = '\n",
       "                                        \"'Risk',\\\\n                      \"\n",
       "                                        'report_type = '\n",
       "                                        \"'drift'\\\\n                     \"\n",
       "                                        '):\\\\n    from evidently.metric_preset '\n",
       "                                        'import (\\\\n    DataDriftPreset,\\\\n    '\n",
       "                                        'TargetDriftPreset,\\\\n    '\n",
       "                                        'ClassificationPreset,\\\\n    )\\\\n    '\n",
       "                                        'from evidently.report import '\n",
       "                                        'Report\\\\n    from evidently import '\n",
       "                                        'ColumnMapping\\\\n    import pandas as '\n",
       "                                        'pd\\\\n    import os\\\\n    from pathlib '\n",
       "                                        'import Path\\\\n    import '\n",
       "                                        'json\\\\n\\\\n    reference_dataset = '\n",
       "                                        'pd.read_pickle(reference_df)\\\\n    '\n",
       "                                        'production_dataset = '\n",
       "                                        'pd.read_pickle(production_df)\\\\n    '\n",
       "                                        'column_info = '\n",
       "                                        'json.loads(os.environ[\\\\\"COLUMNS\\\\\"])\\\\n\\\\n    '\n",
       "                                        'column_mapping = '\n",
       "                                        'ColumnMapping()\\\\n    '\n",
       "                                        'column_mapping.target = target\\\\n    '\n",
       "                                        'column_mapping.task = '\n",
       "                                        '\\\\\"classification\\\\\"\\\\n\\\\n    '\n",
       "                                        'column_mapping.numerical_features = '\n",
       "                                        '[\\\\n        c\\\\n        for c in '\n",
       "                                        'column_info[\\\\\"int_columns\\\\\"]\\\\n        '\n",
       "                                        'if c != target\\\\n    ]\\\\n    '\n",
       "                                        'column_mapping.categorical_features = '\n",
       "                                        '[\\\\n        c\\\\n        for c in '\n",
       "                                        'column_info[\\\\\"label_columns\\\\\"]\\\\n        '\n",
       "                                        'if c != target\\\\n    ]\\\\n\\\\n    if '\n",
       "                                        'report_type.lower() == '\n",
       "                                        '\\\\\"drift\\\\\":\\\\n        report = '\n",
       "                                        'Report(\\\\n            '\n",
       "                                        'metrics=[\\\\n                '\n",
       "                                        'DataDriftPreset(),\\\\n            '\n",
       "                                        ']\\\\n        )\\\\n    elif '\n",
       "                                        'report_type.lower() == '\n",
       "                                        '\\\\\"target_drift\\\\\":\\\\n        report '\n",
       "                                        '= Report(\\\\n            '\n",
       "                                        'metrics=[\\\\n                '\n",
       "                                        'TargetDriftPreset(),\\\\n            '\n",
       "                                        ']\\\\n        )\\\\n    else:\\\\n        '\n",
       "                                        'raise NotImplementedError()\\\\n\\\\n    '\n",
       "                                        'report.run(\\\\n        '\n",
       "                                        'reference_data=reference_dataset,\\\\n        '\n",
       "                                        'current_data=production_dataset,\\\\n        '\n",
       "                                        'column_mapping=column_mapping,\\\\n    '\n",
       "                                        ')\\\\n\\\\n    '\n",
       "                                        'Path(output_report).parent.mkdir(parents=True, '\n",
       "                                        'exist_ok=True)\\\\n    '\n",
       "                                        'report.save_html(output_report)\\\\n    '\n",
       "                                        'html_content = open(output_report, '\n",
       "                                        '\\\\\"r\\\\\").read()\\\\n    metadata = '\n",
       "                                        '{\\\\n        \\\\\"outputs\\\\\": '\n",
       "                                        '[\\\\n            {\\\\n                '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"web-app\\\\\",\\\\n                '\n",
       "                                        '\\\\\"storage\\\\\": '\n",
       "                                        '\\\\\"inline\\\\\",\\\\n                '\n",
       "                                        '\\\\\"source\\\\\": '\n",
       "                                        'html_content,\\\\n            '\n",
       "                                        '}\\\\n        ]\\\\n    }\\\\n\\\\n    with '\n",
       "                                        'open(mlpipeline_ui_metadata_path, '\n",
       "                                        '\\\\\"w\\\\\") as f:\\\\n        '\n",
       "                                        'json.dump(metadata, f)\\\\n\\\\n    with '\n",
       "                                        'open(output_json, \\\\\"w\\\\\") as '\n",
       "                                        'json_f:\\\\n        '\n",
       "                                        'json_f.write(report.json())\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Evidently \"\n",
       "                                        \"report', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--reference-df\\\\\", '\n",
       "                                        'dest=\\\\\"reference_df\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--production-df\\\\\", '\n",
       "                                        'dest=\\\\\"production_df\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--target\\\\\", '\n",
       "                                        'dest=\\\\\"target\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--report-type\\\\\", '\n",
       "                                        'dest=\\\\\"report_type\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--mlpipeline-ui-metadata\\\\\", '\n",
       "                                        'dest=\\\\\"mlpipeline_ui_metadata_path\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-report\\\\\", '\n",
       "                                        'dest=\\\\\"output_report\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-json\\\\\", '\n",
       "                                        'dest=\\\\\"output_json\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'evidently_report(**_parsed_args)\\\\n\"],\"args\":[\"--reference-df\",\"/tmp/inputs/reference_df/data\",\"--production-df\",\"/tmp/inputs/production_df/data\",\"--target\",\"Risk\",\"--report-type\",\"target_drift\",\"--mlpipeline-ui-metadata\",\"/tmp/outputs/mlpipeline_ui_metadata/data\",\"--output-report\",\"/tmp/outputs/output_report/data\",\"--output-json\",\"/tmp/outputs/output_json/data\"],\"env\":[{\"name\":\"COLUMNS\",\"valueFrom\":{\"configMapKeyRef\":{\"name\":\"credit-risk-columns\",\"key\":\"columns\"}}}],\"resources\":{}}},{\"name\":\"load-df-from-db2\",\"inputs\":{},\"outputs\":{\"artifacts\":[{\"name\":\"load-df-from-db2-data_frame_pkl\",\"path\":\"/tmp/outputs/data_frame_pkl/data\"}]},\"metadata\":{\"annotations\":{\"pipelines.kubeflow.org/arguments.parameters\":\"{\\\\\"predictions_column\\\\\": '\n",
       "                                        '\\\\\"\\\\\", \\\\\"table_name\\\\\": '\n",
       "                                        '\\\\\"TRAIN\\\\\", \\\\\"target_column\\\\\": '\n",
       "                                        '\\\\\"Risk\\\\\"}\",\"pipelines.kubeflow.org/component_ref\":\"{}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--table-name\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": \\\\\"table_name\\\\\"}, '\n",
       "                                        '{\\\\\"if\\\\\": {\\\\\"cond\\\\\": '\n",
       "                                        '{\\\\\"isPresent\\\\\": '\n",
       "                                        '\\\\\"target_column\\\\\"}, \\\\\"then\\\\\": '\n",
       "                                        '[\\\\\"--target-column\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"target_column\\\\\"}]}}, {\\\\\"if\\\\\": '\n",
       "                                        '{\\\\\"cond\\\\\": {\\\\\"isPresent\\\\\": '\n",
       "                                        '\\\\\"predictions_column\\\\\"}, '\n",
       "                                        '\\\\\"then\\\\\": '\n",
       "                                        '[\\\\\"--predictions-column\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"predictions_column\\\\\"}]}}, '\n",
       "                                        '\\\\\"--data-frame-pkl\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"data_frame_pkl\\\\\"}], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\\\\\n    return '\n",
       "                                        'file_path\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        'load_df_from_db2(table_name,\\\\\\\\n                     '\n",
       "                                        'data_frame_pkl,\\\\\\\\n                     '\n",
       "                                        'target_column = '\n",
       "                                        \"'Risk',\\\\\\\\n                     \"\n",
       "                                        \"predictions_column = ''):\\\\\\\\n    \"\n",
       "                                        'import warnings\\\\\\\\n    import '\n",
       "                                        'ibm_db\\\\\\\\n    import '\n",
       "                                        'ibm_db_dbi\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        'import json\\\\\\\\n    import pandas as '\n",
       "                                        'pd\\\\\\\\n    import pickle\\\\\\\\n    from '\n",
       "                                        'typing import Dict, Any\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'def assign_categories_to_df(df, '\n",
       "                                        'column_info):\\\\\\\\n        for '\n",
       "                                        'col_name, levels in '\n",
       "                                        'column_info[\\\\\\\\\\\\\"label_columns\\\\\\\\\\\\\"].items():\\\\\\\\n            '\n",
       "                                        'if col_name in '\n",
       "                                        'df.columns:\\\\\\\\n                ctype '\n",
       "                                        '= '\n",
       "                                        'pd.CategoricalDtype(categories=levels, '\n",
       "                                        'ordered=False)\\\\\\\\n                '\n",
       "                                        'df[col_name] = '\n",
       "                                        'df[col_name].astype(ctype)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'def df_from_sql(\\\\\\\\n        '\n",
       "                                        'name,\\\\\\\\n        conn,\\\\\\\\n        '\n",
       "                                        'column_info,\\\\\\\\n        target_col = '\n",
       "                                        \"'Risk',\\\\\\\\n        predictions_col = \"\n",
       "                                        \"''\\\\\\\\n    ):\\\\\\\\n        \"\n",
       "                                        'sql_safe_name = '\n",
       "                                        'name.replace(\\'\\\\\\\\\\\\\"\\', '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'column_list = '\n",
       "                                        'column_info[\\\\\\\\\\\\\"columns\\\\\\\\\\\\\"] + '\n",
       "                                        '([] if not predictions_col else '\n",
       "                                        '[predictions_col])\\\\\\\\n        '\n",
       "                                        'rStmtColsSql = '\n",
       "                                        '\\\\\\\\\\\\\",\\\\\\\\\\\\\".join([f\\'\\\\\\\\\\\\\"{col}\\\\\\\\\\\\\"\\' '\n",
       "                                        'for col in column_list])\\\\\\\\n        '\n",
       "                                        \"rSql = f'SELECT {rStmtColsSql} FROM \"\n",
       "                                        '\\\\\\\\\\\\\"{sql_safe_name}\\\\\\\\\\\\\"\\'\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'read_conn = '\n",
       "                                        'ibm_db_dbi.Connection(conn)\\\\\\\\n        '\n",
       "                                        'with '\n",
       "                                        'warnings.catch_warnings():\\\\\\\\n            '\n",
       "                                        'warnings.filterwarnings(\\\\\\\\\\\\\"ignore\\\\\\\\\\\\\", '\n",
       "                                        'message=\\\\\\\\\\\\\"pandas only support '\n",
       "                                        'SQLAlchemy\\\\\\\\\\\\\")\\\\\\\\n            df '\n",
       "                                        '= pd.read_sql(rSql, '\n",
       "                                        'read_conn)\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'assign_categories_to_df(df, '\n",
       "                                        'column_info)\\\\\\\\n        if '\n",
       "                                        'predictions_col:\\\\\\\\n            '\n",
       "                                        'df[predictions_col] = '\n",
       "                                        'df[predictions_col].astype(df[target_col].dtype)\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'return df\\\\\\\\n\\\\\\\\n    conn_str = '\n",
       "                                        '(\\\\\\\\n    \\\\\\\\\\\\\"DRIVER={IBM DB2 ODBC '\n",
       "                                        'DRIVER};\\\\\\\\\\\\\"\\\\\\\\n    '\n",
       "                                        'f\\\\\\\\\\\\\"DATABASE=BLUDB;HOSTNAME={os.environ[\\'db2_host\\']};PORT={os.environ[\\'db2_port\\']};PROTOCOL=TCPIP;UID={os.environ[\\'db2_user\\']};Pwd={os.environ[\\'db2_pwd\\']};SECURITY=SSL;\\\\\\\\\\\\\"\\\\\\\\n    '\n",
       "                                        ')\\\\\\\\n\\\\\\\\n    conn = '\n",
       "                                        'ibm_db.connect(conn_str, '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'column_info = '\n",
       "                                        'json.loads(os.environ[\\\\\\\\\\\\\"COLUMNS\\\\\\\\\\\\\"])\\\\\\\\n    '\n",
       "                                        'df = df_from_sql(table_name, conn, '\n",
       "                                        'column_info, target_column, '\n",
       "                                        'predictions_column)\\\\\\\\n    '\n",
       "                                        'df.to_pickle(data_frame_pkl)\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Load df \"\n",
       "                                        \"from db2', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--table-name\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"table_name\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--target-column\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"target_column\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--predictions-column\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"predictions_column\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--data-frame-pkl\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"data_frame_pkl\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'load_df_from_db2(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"table_name\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"Risk\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"target_column\\\\\", \\\\\"optional\\\\\": '\n",
       "                                        'true, \\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": \\\\\"\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"predictions_column\\\\\", '\n",
       "                                        '\\\\\"optional\\\\\": true, \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}], \\\\\"name\\\\\": \\\\\"Load '\n",
       "                                        'df from db2\\\\\", \\\\\"outputs\\\\\": '\n",
       "                                        '[{\\\\\"name\\\\\": \\\\\"data_frame_pkl\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}]}\",\"pipelines.kubeflow.org/task_display_name\":\"Load_Reference_Data_From_DB2\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.18\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\n    import os\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\n    return '\n",
       "                                        'file_path\\\\n\\\\ndef '\n",
       "                                        'load_df_from_db2(table_name,\\\\n                     '\n",
       "                                        'data_frame_pkl,\\\\n                     '\n",
       "                                        'target_column = '\n",
       "                                        \"'Risk',\\\\n                     \"\n",
       "                                        \"predictions_column = ''):\\\\n    \"\n",
       "                                        'import warnings\\\\n    import '\n",
       "                                        'ibm_db\\\\n    import ibm_db_dbi\\\\n    '\n",
       "                                        'import os\\\\n    import json\\\\n    '\n",
       "                                        'import pandas as pd\\\\n    import '\n",
       "                                        'pickle\\\\n    from typing import Dict, '\n",
       "                                        'Any\\\\n\\\\n    def '\n",
       "                                        'assign_categories_to_df(df, '\n",
       "                                        'column_info):\\\\n        for col_name, '\n",
       "                                        'levels in '\n",
       "                                        'column_info[\\\\\"label_columns\\\\\"].items():\\\\n            '\n",
       "                                        'if col_name in '\n",
       "                                        'df.columns:\\\\n                ctype = '\n",
       "                                        'pd.CategoricalDtype(categories=levels, '\n",
       "                                        'ordered=False)\\\\n                '\n",
       "                                        'df[col_name] = '\n",
       "                                        'df[col_name].astype(ctype)\\\\n\\\\n    '\n",
       "                                        'def df_from_sql(\\\\n        '\n",
       "                                        'name,\\\\n        conn,\\\\n        '\n",
       "                                        'column_info,\\\\n        target_col = '\n",
       "                                        \"'Risk',\\\\n        predictions_col = \"\n",
       "                                        \"''\\\\n    ):\\\\n        sql_safe_name = \"\n",
       "                                        'name.replace(\\'\\\\\"\\', '\n",
       "                                        '\\\\\"\\\\\")\\\\n\\\\n        column_list = '\n",
       "                                        'column_info[\\\\\"columns\\\\\"] + ([] if '\n",
       "                                        'not predictions_col else '\n",
       "                                        '[predictions_col])\\\\n        '\n",
       "                                        'rStmtColsSql = '\n",
       "                                        '\\\\\",\\\\\".join([f\\'\\\\\"{col}\\\\\"\\' for '\n",
       "                                        'col in column_list])\\\\n        rSql = '\n",
       "                                        \"f'SELECT {rStmtColsSql} FROM \"\n",
       "                                        '\\\\\"{sql_safe_name}\\\\\"\\'\\\\n\\\\n        '\n",
       "                                        'read_conn = '\n",
       "                                        'ibm_db_dbi.Connection(conn)\\\\n        '\n",
       "                                        'with '\n",
       "                                        'warnings.catch_warnings():\\\\n            '\n",
       "                                        'warnings.filterwarnings(\\\\\"ignore\\\\\", '\n",
       "                                        'message=\\\\\"pandas only support '\n",
       "                                        'SQLAlchemy\\\\\")\\\\n            df = '\n",
       "                                        'pd.read_sql(rSql, '\n",
       "                                        'read_conn)\\\\n\\\\n        '\n",
       "                                        'assign_categories_to_df(df, '\n",
       "                                        'column_info)\\\\n        if '\n",
       "                                        'predictions_col:\\\\n            '\n",
       "                                        'df[predictions_col] = '\n",
       "                                        'df[predictions_col].astype(df[target_col].dtype)\\\\n\\\\n        '\n",
       "                                        'return df\\\\n\\\\n    conn_str = (\\\\n    '\n",
       "                                        '\\\\\"DRIVER={IBM DB2 ODBC '\n",
       "                                        'DRIVER};\\\\\"\\\\n    '\n",
       "                                        'f\\\\\"DATABASE=BLUDB;HOSTNAME={os.environ[\\'db2_host\\']};PORT={os.environ[\\'db2_port\\']};PROTOCOL=TCPIP;UID={os.environ[\\'db2_user\\']};Pwd={os.environ[\\'db2_pwd\\']};SECURITY=SSL;\\\\\"\\\\n    '\n",
       "                                        ')\\\\n\\\\n    conn = '\n",
       "                                        'ibm_db.connect(conn_str, \\\\\"\\\\\", '\n",
       "                                        '\\\\\"\\\\\")\\\\n\\\\n    column_info = '\n",
       "                                        'json.loads(os.environ[\\\\\"COLUMNS\\\\\"])\\\\n    '\n",
       "                                        'df = df_from_sql(table_name, conn, '\n",
       "                                        'column_info, target_column, '\n",
       "                                        'predictions_column)\\\\n    '\n",
       "                                        'df.to_pickle(data_frame_pkl)\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Load df \"\n",
       "                                        \"from db2', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--table-name\\\\\", '\n",
       "                                        'dest=\\\\\"table_name\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--target-column\\\\\", '\n",
       "                                        'dest=\\\\\"target_column\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--predictions-column\\\\\", '\n",
       "                                        'dest=\\\\\"predictions_column\\\\\", '\n",
       "                                        'type=str, required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--data-frame-pkl\\\\\", '\n",
       "                                        'dest=\\\\\"data_frame_pkl\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'load_df_from_db2(**_parsed_args)\\\\n\"],\"args\":[\"--table-name\",\"TRAIN\",\"--target-column\",\"Risk\",\"--predictions-column\",\"\",\"--data-frame-pkl\",\"/tmp/outputs/data_frame_pkl/data\"],\"env\":[{\"name\":\"db2_host\",\"valueFrom\":{\"secretKeyRef\":{\"name\":\"db2-credentials\",\"key\":\"host\"}}},{\"name\":\"db2_user\",\"valueFrom\":{\"secretKeyRef\":{\"name\":\"db2-credentials\",\"key\":\"username\"}}},{\"name\":\"db2_pwd\",\"valueFrom\":{\"secretKeyRef\":{\"name\":\"db2-credentials\",\"key\":\"password\"}}},{\"name\":\"db2_port\",\"valueFrom\":{\"secretKeyRef\":{\"name\":\"db2-credentials\",\"key\":\"port\"}}},{\"name\":\"COLUMNS\",\"valueFrom\":{\"configMapKeyRef\":{\"name\":\"credit-risk-columns\",\"key\":\"columns\"}}}],\"resources\":{}}},{\"name\":\"load-df-from-db2-2\",\"inputs\":{},\"outputs\":{\"artifacts\":[{\"name\":\"load-df-from-db2-2-data_frame_pkl\",\"path\":\"/tmp/outputs/data_frame_pkl/data\"}]},\"metadata\":{\"annotations\":{\"pipelines.kubeflow.org/arguments.parameters\":\"{\\\\\"predictions_column\\\\\": '\n",
       "                                        '\\\\\"PredictedRisk\\\\\", '\n",
       "                                        '\\\\\"table_name\\\\\": \\\\\"CLIENT_DATA\\\\\", '\n",
       "                                        '\\\\\"target_column\\\\\": '\n",
       "                                        '\\\\\"Risk\\\\\"}\",\"pipelines.kubeflow.org/component_ref\":\"{}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--table-name\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": \\\\\"table_name\\\\\"}, '\n",
       "                                        '{\\\\\"if\\\\\": {\\\\\"cond\\\\\": '\n",
       "                                        '{\\\\\"isPresent\\\\\": '\n",
       "                                        '\\\\\"target_column\\\\\"}, \\\\\"then\\\\\": '\n",
       "                                        '[\\\\\"--target-column\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"target_column\\\\\"}]}}, {\\\\\"if\\\\\": '\n",
       "                                        '{\\\\\"cond\\\\\": {\\\\\"isPresent\\\\\": '\n",
       "                                        '\\\\\"predictions_column\\\\\"}, '\n",
       "                                        '\\\\\"then\\\\\": '\n",
       "                                        '[\\\\\"--predictions-column\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"predictions_column\\\\\"}]}}, '\n",
       "                                        '\\\\\"--data-frame-pkl\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"data_frame_pkl\\\\\"}], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\\\\\n    return '\n",
       "                                        'file_path\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        'load_df_from_db2(table_name,\\\\\\\\n                     '\n",
       "                                        'data_frame_pkl,\\\\\\\\n                     '\n",
       "                                        'target_column = '\n",
       "                                        \"'Risk',\\\\\\\\n                     \"\n",
       "                                        \"predictions_column = ''):\\\\\\\\n    \"\n",
       "                                        'import warnings\\\\\\\\n    import '\n",
       "                                        'ibm_db\\\\\\\\n    import '\n",
       "                                        'ibm_db_dbi\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        'import json\\\\\\\\n    import pandas as '\n",
       "                                        'pd\\\\\\\\n    import pickle\\\\\\\\n    from '\n",
       "                                        'typing import Dict, Any\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'def assign_categories_to_df(df, '\n",
       "                                        'column_info):\\\\\\\\n        for '\n",
       "                                        'col_name, levels in '\n",
       "                                        'column_info[\\\\\\\\\\\\\"label_columns\\\\\\\\\\\\\"].items():\\\\\\\\n            '\n",
       "                                        'if col_name in '\n",
       "                                        'df.columns:\\\\\\\\n                ctype '\n",
       "                                        '= '\n",
       "                                        'pd.CategoricalDtype(categories=levels, '\n",
       "                                        'ordered=False)\\\\\\\\n                '\n",
       "                                        'df[col_name] = '\n",
       "                                        'df[col_name].astype(ctype)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'def df_from_sql(\\\\\\\\n        '\n",
       "                                        'name,\\\\\\\\n        conn,\\\\\\\\n        '\n",
       "                                        'column_info,\\\\\\\\n        target_col = '\n",
       "                                        \"'Risk',\\\\\\\\n        predictions_col = \"\n",
       "                                        \"''\\\\\\\\n    ):\\\\\\\\n        \"\n",
       "                                        'sql_safe_name = '\n",
       "                                        'name.replace(\\'\\\\\\\\\\\\\"\\', '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'column_list = '\n",
       "                                        'column_info[\\\\\\\\\\\\\"columns\\\\\\\\\\\\\"] + '\n",
       "                                        '([] if not predictions_col else '\n",
       "                                        '[predictions_col])\\\\\\\\n        '\n",
       "                                        'rStmtColsSql = '\n",
       "                                        '\\\\\\\\\\\\\",\\\\\\\\\\\\\".join([f\\'\\\\\\\\\\\\\"{col}\\\\\\\\\\\\\"\\' '\n",
       "                                        'for col in column_list])\\\\\\\\n        '\n",
       "                                        \"rSql = f'SELECT {rStmtColsSql} FROM \"\n",
       "                                        '\\\\\\\\\\\\\"{sql_safe_name}\\\\\\\\\\\\\"\\'\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'read_conn = '\n",
       "                                        'ibm_db_dbi.Connection(conn)\\\\\\\\n        '\n",
       "                                        'with '\n",
       "                                        'warnings.catch_warnings():\\\\\\\\n            '\n",
       "                                        'warnings.filterwarnings(\\\\\\\\\\\\\"ignore\\\\\\\\\\\\\", '\n",
       "                                        'message=\\\\\\\\\\\\\"pandas only support '\n",
       "                                        'SQLAlchemy\\\\\\\\\\\\\")\\\\\\\\n            df '\n",
       "                                        '= pd.read_sql(rSql, '\n",
       "                                        'read_conn)\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'assign_categories_to_df(df, '\n",
       "                                        'column_info)\\\\\\\\n        if '\n",
       "                                        'predictions_col:\\\\\\\\n            '\n",
       "                                        'df[predictions_col] = '\n",
       "                                        'df[predictions_col].astype(df[target_col].dtype)\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'return df\\\\\\\\n\\\\\\\\n    conn_str = '\n",
       "                                        '(\\\\\\\\n    \\\\\\\\\\\\\"DRIVER={IBM DB2 ODBC '\n",
       "                                        'DRIVER};\\\\\\\\\\\\\"\\\\\\\\n    '\n",
       "                                        'f\\\\\\\\\\\\\"DATABASE=BLUDB;HOSTNAME={os.environ[\\'db2_host\\']};PORT={os.environ[\\'db2_port\\']};PROTOCOL=TCPIP;UID={os.environ[\\'db2_user\\']};Pwd={os.environ[\\'db2_pwd\\']};SECURITY=SSL;\\\\\\\\\\\\\"\\\\\\\\n    '\n",
       "                                        ')\\\\\\\\n\\\\\\\\n    conn = '\n",
       "                                        'ibm_db.connect(conn_str, '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'column_info = '\n",
       "                                        'json.loads(os.environ[\\\\\\\\\\\\\"COLUMNS\\\\\\\\\\\\\"])\\\\\\\\n    '\n",
       "                                        'df = df_from_sql(table_name, conn, '\n",
       "                                        'column_info, target_column, '\n",
       "                                        'predictions_column)\\\\\\\\n    '\n",
       "                                        'df.to_pickle(data_frame_pkl)\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Load df \"\n",
       "                                        \"from db2', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--table-name\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"table_name\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--target-column\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"target_column\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--predictions-column\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"predictions_column\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--data-frame-pkl\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"data_frame_pkl\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'load_df_from_db2(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"table_name\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"default\\\\\": '\n",
       "                                        '\\\\\"Risk\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"target_column\\\\\", \\\\\"optional\\\\\": '\n",
       "                                        'true, \\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"default\\\\\": \\\\\"\\\\\", \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"predictions_column\\\\\", '\n",
       "                                        '\\\\\"optional\\\\\": true, \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}], \\\\\"name\\\\\": \\\\\"Load '\n",
       "                                        'df from db2\\\\\", \\\\\"outputs\\\\\": '\n",
       "                                        '[{\\\\\"name\\\\\": \\\\\"data_frame_pkl\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}]}\",\"pipelines.kubeflow.org/task_display_name\":\"Load_Production_Data_From_DB2\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.18\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"quay.io/ntlawrence/demo-workflow@sha256:e0b071e361a147d1cc957b96a19ae6144d792ff994ac8daf0ba887a5bd3652f5\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\n    import os\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\n    return '\n",
       "                                        'file_path\\\\n\\\\ndef '\n",
       "                                        'load_df_from_db2(table_name,\\\\n                     '\n",
       "                                        'data_frame_pkl,\\\\n                     '\n",
       "                                        'target_column = '\n",
       "                                        \"'Risk',\\\\n                     \"\n",
       "                                        \"predictions_column = ''):\\\\n    \"\n",
       "                                        'import warnings\\\\n    import '\n",
       "                                        'ibm_db\\\\n    import ibm_db_dbi\\\\n    '\n",
       "                                        'import os\\\\n    import json\\\\n    '\n",
       "                                        'import pandas as pd\\\\n    import '\n",
       "                                        'pickle\\\\n    from typing import Dict, '\n",
       "                                        'Any\\\\n\\\\n    def '\n",
       "                                        'assign_categories_to_df(df, '\n",
       "                                        'column_info):\\\\n        for col_name, '\n",
       "                                        'levels in '\n",
       "                                        'column_info[\\\\\"label_columns\\\\\"].items():\\\\n            '\n",
       "                                        'if col_name in '\n",
       "                                        'df.columns:\\\\n                ctype = '\n",
       "                                        'pd.CategoricalDtype(categories=levels, '\n",
       "                                        'ordered=False)\\\\n                '\n",
       "                                        'df[col_name] = '\n",
       "                                        'df[col_name].astype(ctype)\\\\n\\\\n    '\n",
       "                                        'def df_from_sql(\\\\n        '\n",
       "                                        'name,\\\\n        conn,\\\\n        '\n",
       "                                        'column_info,\\\\n        target_col = '\n",
       "                                        \"'Risk',\\\\n        predictions_col = \"\n",
       "                                        \"''\\\\n    ):\\\\n        sql_safe_name = \"\n",
       "                                        'name.replace(\\'\\\\\"\\', '\n",
       "                                        '\\\\\"\\\\\")\\\\n\\\\n        column_list = '\n",
       "                                        'column_info[\\\\\"columns\\\\\"] + ([] if '\n",
       "                                        'not predictions_col else '\n",
       "                                        '[predictions_col])\\\\n        '\n",
       "                                        'rStmtColsSql = '\n",
       "                                        '\\\\\",\\\\\".join([f\\'\\\\\"{col}\\\\\"\\' for '\n",
       "                                        'col in column_list])\\\\n        rSql = '\n",
       "                                        \"f'SELECT {rStmtColsSql} FROM \"\n",
       "                                        '\\\\\"{sql_safe_name}\\\\\"\\'\\\\n\\\\n        '\n",
       "                                        'read_conn = '\n",
       "                                        'ibm_db_dbi.Connection(conn)\\\\n        '\n",
       "                                        'with '\n",
       "                                        'warnings.catch_warnings():\\\\n            '\n",
       "                                        'warnings.filterwarnings(\\\\\"ignore\\\\\", '\n",
       "                                        'message=\\\\\"pandas only support '\n",
       "                                        'SQLAlchemy\\\\\")\\\\n            df = '\n",
       "                                        'pd.read_sql(rSql, '\n",
       "                                        'read_conn)\\\\n\\\\n        '\n",
       "                                        'assign_categories_to_df(df, '\n",
       "                                        'column_info)\\\\n        if '\n",
       "                                        'predictions_col:\\\\n            '\n",
       "                                        'df[predictions_col] = '\n",
       "                                        'df[predictions_col].astype(df[target_col].dtype)\\\\n\\\\n        '\n",
       "                                        'return df\\\\n\\\\n    conn_str = (\\\\n    '\n",
       "                                        '\\\\\"DRIVER={IBM DB2 ODBC '\n",
       "                                        'DRIVER};\\\\\"\\\\n    '\n",
       "                                        'f\\\\\"DATABASE=BLUDB;HOSTNAME={os.environ[\\'db2_host\\']};PORT={os.environ[\\'db2_port\\']};PROTOCOL=TCPIP;UID={os.environ[\\'db2_user\\']};Pwd={os.environ[\\'db2_pwd\\']};SECURITY=SSL;\\\\\"\\\\n    '\n",
       "                                        ')\\\\n\\\\n    conn = '\n",
       "                                        'ibm_db.connect(conn_str, \\\\\"\\\\\", '\n",
       "                                        '\\\\\"\\\\\")\\\\n\\\\n    column_info = '\n",
       "                                        'json.loads(os.environ[\\\\\"COLUMNS\\\\\"])\\\\n    '\n",
       "                                        'df = df_from_sql(table_name, conn, '\n",
       "                                        'column_info, target_column, '\n",
       "                                        'predictions_column)\\\\n    '\n",
       "                                        'df.to_pickle(data_frame_pkl)\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Load df \"\n",
       "                                        \"from db2', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--table-name\\\\\", '\n",
       "                                        'dest=\\\\\"table_name\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--target-column\\\\\", '\n",
       "                                        'dest=\\\\\"target_column\\\\\", type=str, '\n",
       "                                        'required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--predictions-column\\\\\", '\n",
       "                                        'dest=\\\\\"predictions_column\\\\\", '\n",
       "                                        'type=str, required=False, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--data-frame-pkl\\\\\", '\n",
       "                                        'dest=\\\\\"data_frame_pkl\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'load_df_from_db2(**_parsed_args)\\\\n\"],\"args\":[\"--table-name\",\"CLIENT_DATA\",\"--target-column\",\"Risk\",\"--predictions-column\",\"PredictedRisk\",\"--data-frame-pkl\",\"/tmp/outputs/data_frame_pkl/data\"],\"env\":[{\"name\":\"db2_host\",\"valueFrom\":{\"secretKeyRef\":{\"name\":\"db2-credentials\",\"key\":\"host\"}}},{\"name\":\"db2_user\",\"valueFrom\":{\"secretKeyRef\":{\"name\":\"db2-credentials\",\"key\":\"username\"}}},{\"name\":\"db2_pwd\",\"valueFrom\":{\"secretKeyRef\":{\"name\":\"db2-credentials\",\"key\":\"password\"}}},{\"name\":\"db2_port\",\"valueFrom\":{\"secretKeyRef\":{\"name\":\"db2-credentials\",\"key\":\"port\"}}},{\"name\":\"COLUMNS\",\"valueFrom\":{\"configMapKeyRef\":{\"name\":\"credit-risk-columns\",\"key\":\"columns\"}}}],\"resources\":{}}},{\"name\":\"monitor-credit-risk-ai\",\"inputs\":{},\"outputs\":{},\"metadata\":{},\"dag\":{\"tasks\":[{\"name\":\"check-metrics\",\"template\":\"check-metrics\",\"arguments\":{\"artifacts\":[{\"name\":\"evidently-classification-report-output_json\",\"from\":\"{{tasks.evidently-classification-report.outputs.artifacts.evidently-classification-report-output_json}}\"},{\"name\":\"evidently-report-2-output_json\",\"from\":\"{{tasks.evidently-report-2.outputs.artifacts.evidently-report-2-output_json}}\"},{\"name\":\"evidently-report-output_json\",\"from\":\"{{tasks.evidently-report.outputs.artifacts.evidently-report-output_json}}\"}]},\"dependencies\":[\"evidently-classification-report\",\"evidently-report\",\"evidently-report-2\"]},{\"name\":\"evidently-classification-report\",\"template\":\"evidently-classification-report\",\"arguments\":{\"artifacts\":[{\"name\":\"load-df-from-db2-2-data_frame_pkl\",\"from\":\"{{tasks.load-df-from-db2-2.outputs.artifacts.load-df-from-db2-2-data_frame_pkl}}\"}]},\"dependencies\":[\"load-df-from-db2-2\"]},{\"name\":\"evidently-report\",\"template\":\"evidently-report\",\"arguments\":{\"artifacts\":[{\"name\":\"load-df-from-db2-2-data_frame_pkl\",\"from\":\"{{tasks.load-df-from-db2-2.outputs.artifacts.load-df-from-db2-2-data_frame_pkl}}\"},{\"name\":\"load-df-from-db2-data_frame_pkl\",\"from\":\"{{tasks.load-df-from-db2.outputs.artifacts.load-df-from-db2-data_frame_pkl}}\"}]},\"dependencies\":[\"load-df-from-db2\",\"load-df-from-db2-2\"]},{\"name\":\"evidently-report-2\",\"template\":\"evidently-report-2\",\"arguments\":{\"artifacts\":[{\"name\":\"load-df-from-db2-2-data_frame_pkl\",\"from\":\"{{tasks.load-df-from-db2-2.outputs.artifacts.load-df-from-db2-2-data_frame_pkl}}\"},{\"name\":\"load-df-from-db2-data_frame_pkl\",\"from\":\"{{tasks.load-df-from-db2.outputs.artifacts.load-df-from-db2-data_frame_pkl}}\"}]},\"dependencies\":[\"load-df-from-db2\",\"load-df-from-db2-2\"]},{\"name\":\"load-df-from-db2\",\"template\":\"load-df-from-db2\",\"arguments\":{}},{\"name\":\"load-df-from-db2-2\",\"template\":\"load-df-from-db2-2\",\"arguments\":{}}]}}],\"entrypoint\":\"monitor-credit-risk-ai\",\"arguments\":{},\"serviceAccountName\":\"pipeline-runner\"},\"status\":{\"startedAt\":null,\"finishedAt\":null}}'},\n",
       " 'resource_references': [{'key': {'id': '686142bb-a8c0-4b89-b9f0-29d7e8e25508',\n",
       "                                  'type': 'EXPERIMENT'},\n",
       "                          'name': 'monitor-production-credit',\n",
       "                          'relationship': 'OWNER'},\n",
       "                         {'key': {'id': 'e7aa99a1-7b71-463c-a4c4-a411b3d09597',\n",
       "                                  'type': 'PIPELINE_VERSION'},\n",
       "                          'name': 'Monitor_Credit_Risk_AI',\n",
       "                          'relationship': 'CREATOR'}],\n",
       " 'service_account': 'default-editor',\n",
       " 'status': 'NO_STATUS',\n",
       " 'trigger': {'cron_schedule': {'cron': '0 0/5 * ? * MON-FRI',\n",
       "                               'end_time': None,\n",
       "                               'start_time': None},\n",
       "             'periodic_schedule': None},\n",
       " 'updated_at': datetime.datetime(2023, 10, 20, 21, 18, 22, tzinfo=tzlocal())}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/kubeflow/pipelines/blob/1.7.1/sdk/python/kfp/_client.py\n",
    "# https://pkg.go.dev/github.com/robfig/cron#hdr-CRON_Expression_Format\n",
    "_ = client.create_recurring_run(experiment_id=get_experiment_id(\"monitor-production-credit\"),\n",
    "                                job_name=\"monitor_credit_risk_api_performance\",\n",
    "                                description=\"Tests for data drift and f1 performance\",\n",
    "                                cron_expression=\"0 0 0-23 ? JAN-DEC MON-FRI\",\n",
    "                                pipeline_id=uploaded_pipeline.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "829b7962-9443-4b0b-a215-cc74e44897d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No resources found in ntl-us-ibm-com namespace.\n"
     ]
    }
   ],
   "source": [
    "!oc get scheduledworkflows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "691af232-1b07-45e5-bdc2-88f46e65bf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/7090ad89-50be-4d0f-80aa-bbb94652ad0b\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run = client.run_pipeline(\n",
    "#    experiment_id=get_experiment_id(\"monitor-credit-risk\"),\n",
    "#    job_name=\"monitor-credit-risk\",\n",
    "#    pipeline_id=uploaded_pipeline.id,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53049749-6c0b-4b2c-9a93-c1298316f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TWENTY_MIN = 20 * 60\n",
    "#result = client.wait_for_run_completion(run.id, timeout=TWENTY_MIN)\n",
    "#{\n",
    "#    \"status\": result.run.status,\n",
    "#    \"error\": result.run.error,\n",
    "#    \"time\": str(result.run.finished_at - result.run.created_at),\n",
    "#    \"metrics\": result.run.metrics,\n",
    "#}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7bbb19-5329-47b5-a35e-7b86332bb0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
